#!/usr/bin/env python3
"""
SRT GO v2.2.1 çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨
Unified Test Runner for SRT GO v2.2.1

åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦é¡åˆ¥ä¸¦ç”¢ç”Ÿçµ±ä¸€å ±å‘Š
Execute all test categories and generate unified reports.
"""

import sys
import os
import time
import subprocess
import json
from pathlib import Path
from typing import Dict, List, Any
import argparse

# Add project paths
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class SRTGOTestRunner:
    """SRT GO çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨"""
    
    def __init__(self):
        self.test_root = Path(__file__).parent
        self.results = {}
        self.start_time = None
        self.total_time = 0
        
    def run_test_category(self, category: str, test_path: str, args: List[str] = None) -> Dict[str, Any]:
        """åŸ·è¡Œç‰¹å®šæ¸¬è©¦é¡åˆ¥"""
        print(f"\\n{'='*60}")
        print(f"[TEST] åŸ·è¡Œ {category} æ¸¬è©¦")
        print(f"[PATH] è·¯å¾‘: {test_path}")
        print(f"{'='*60}")
        
        if args is None:
            args = []
            
        full_path = self.test_root / test_path
        if not full_path.exists():
            return {
                "category": category,
                "success": False,
                "error": f"æ¸¬è©¦è·¯å¾‘ä¸å­˜åœ¨: {full_path}",
                "duration": 0,
                "test_count": 0
            }
        
        start_time = time.time()
        
        try:
            # æ ¹æ“šæª”æ¡ˆé¡å‹é¸æ“‡åŸ·è¡Œæ–¹å¼
            if test_path.endswith('.py'):
                # ç›´æ¥åŸ·è¡ŒPythonè…³æœ¬
                cmd = [sys.executable, str(full_path)] + args
            else:
                # ä½¿ç”¨pyteståŸ·è¡Œç›®éŒ„
                cmd = [sys.executable, '-m', 'pytest', str(full_path), '-v', '--tb=short'] + args
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                encoding='utf-8',
                cwd=str(self.test_root)
            )
            
            duration = time.time() - start_time
            success = result.returncode == 0
            
            # è§£ææ¸¬è©¦çµæœ
            test_count = self._extract_test_count(result.stdout)
            
            print(f"[TIME] åŸ·è¡Œæ™‚é–“: {duration:.2f}ç§’")
            print(f"[STAT] æ¸¬è©¦æ•¸é‡: {test_count}")
            print(f"{'[OK] æˆåŠŸ' if success else '[FAIL] å¤±æ•—'}")
            
            if not success and result.stderr:
                print(f"éŒ¯èª¤è¼¸å‡º: {result.stderr[:500]}...")
            
            return {
                "category": category,
                "success": success,
                "duration": duration,
                "test_count": test_count,
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr
            }
            
        except Exception as e:
            duration = time.time() - start_time
            print(f"[ERROR] åŸ·è¡Œå¤±æ•—: {e}")
            
            return {
                "category": category,
                "success": False,
                "error": str(e),
                "duration": duration,
                "test_count": 0
            }
    
    def _extract_test_count(self, output: str) -> int:
        """å¾è¼¸å‡ºä¸­æå–æ¸¬è©¦æ•¸é‡"""
        try:
            # æŸ¥æ‰¾pytestè¼¸å‡ºä¸­çš„æ¸¬è©¦çµ±è¨ˆ
            lines = output.split('\\n')
            for line in lines:
                if 'passed' in line or 'failed' in line:
                    # å˜—è©¦è§£æ "X passed, Y failed" æ ¼å¼
                    words = line.split()
                    for i, word in enumerate(words):
                        if word.isdigit():
                            return int(word)
        except:
            pass
        return 0
    
    def run_all_tests(self, categories: List[str] = None):
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("[*] SRT GO v2.2.1 çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨")
        print("="*60)
        
        self.start_time = time.time()
        
        # æ¸¬è©¦é…ç½® - æŒ‰åŠŸèƒ½åˆ†é¡
        test_configs = {
            # 1. å–®å…ƒæ¸¬è©¦
            "å–®å…ƒæ¸¬è©¦ - éŸ³é »è™•ç†å™¨": {
                "path": "unit/test_audio_processor.py",
                "args": ["-v"]
            },
            "å–®å…ƒæ¸¬è©¦ - éŸ³é »è™•ç†å™¨ç°¡åŒ–ç‰ˆ": {
                "path": "unit/test_audio_processor_simple.py", 
                "args": ["-v"]
            },
            
            # 2. æ•´åˆæ¸¬è©¦
            "æ•´åˆæ¸¬è©¦ - å®Œæ•´å·¥ä½œæµç¨‹": {
                "path": "integration/test_complete_workflow.py",
                "args": ["-v"]
            },
            "æ•´åˆæ¸¬è©¦ - æ¨™æº–é™¤éŒ¯": {
                "path": "debug_test_integration.py",
                "args": []
            },
            "æ•´åˆæ¸¬è©¦ - ä½VADé™¤éŒ¯": {
                "path": "debug_test_integration_low_vad.py",
                "args": []
            },
            
            # 3. æ•ˆèƒ½æ¸¬è©¦
            "æ•ˆèƒ½æ¸¬è©¦ - å¿«é€ŸRTFæ¸¬è©¦": {
                "path": "performance/quick_rtf_test.py",
                "args": []
            },
            "æ•ˆèƒ½æ¸¬è©¦ - RTFåŸºæº–æ¸¬è©¦": {
                "path": "performance/test_rtf_benchmarks.py",
                "args": ["-v"]
            },
            "æ•ˆèƒ½æ¸¬è©¦ - RTFç›£æ§ç³»çµ±": {
                "path": "performance/rtf_monitoring_system.py",
                "args": []
            },
            "æ•ˆèƒ½æ¸¬è©¦ - ç¶œåˆæ•ˆèƒ½å¥—ä»¶": {
                "path": "performance/comprehensive_performance_suite.py",
                "args": []
            },
            
            # 4. E2Eæ¸¬è©¦  
            "E2Eæ¸¬è©¦ - è‡ªå‹•åŒ–æ¸¬è©¦å¥—ä»¶": {
                "path": "e2e/test_automation_suite.py",
                "args": []
            },
        }
        
        # å¦‚æœæŒ‡å®šäº†ç‰¹å®šé¡åˆ¥ï¼ŒåªåŸ·è¡Œé‚£äº›
        if categories:
            test_configs = {k: v for k, v in test_configs.items() if any(cat in k for cat in categories)}
        
        # åŸ·è¡Œæ¸¬è©¦
        for category, config in test_configs.items():
            if categories and not any(cat in category for cat in categories):
                continue
                
            result = self.run_test_category(category, config["path"], config.get("args", []))
            self.results[category] = result
        
        self.total_time = time.time() - self.start_time
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_report()
        
        # è¿”å›ç¸½é«”æˆåŠŸç‹€æ…‹
        return self.is_overall_success()
    
    def generate_report(self):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        print("\\n" + "="*60)
        print("[SUMMARY] æ¸¬è©¦çµæœçµ±è¨ˆ")
        print("="*60)
        
        successful = [r for r in self.results.values() if r["success"]]
        failed = [r for r in self.results.values() if not r["success"]]
        total_tests = sum(r["test_count"] for r in self.results.values())
        
        print(f"ç¸½åŸ·è¡Œæ™‚é–“: {self.total_time:.2f}ç§’")
        print(f"æ¸¬è©¦é¡åˆ¥æ•¸é‡: {len(self.results)}")
        print(f"æˆåŠŸé¡åˆ¥: {len(successful)}")
        print(f"å¤±æ•—é¡åˆ¥: {len(failed)}")
        print(f"ç¸½æ¸¬è©¦æ•¸é‡: {total_tests}")
        print(f"æˆåŠŸç‡: {len(successful)/len(self.results)*100:.1f}%" if self.results else "0%")
        
        if successful:
            print("\\n[SUCCESS] æˆåŠŸçš„æ¸¬è©¦é¡åˆ¥:")
            for result in successful:
                print(f"  â€¢ {result['category']} ({result['test_count']}å€‹æ¸¬è©¦, {result['duration']:.1f}ç§’)")
        
        if failed:
            print("\\n[FAILED] å¤±æ•—çš„æ¸¬è©¦é¡åˆ¥:")  
            for result in failed:
                error_msg = result.get('error', 'æœªçŸ¥éŒ¯èª¤')
                print(f"  â€¢ {result['category']}: {error_msg}")
        
        # æ•ˆèƒ½çµ±è¨ˆ
        print("\\n[PERF] æ•ˆèƒ½çµ±è¨ˆ:")
        perf_results = [r for r in self.results.values() if "æ•ˆèƒ½æ¸¬è©¦" in r["category"] and r["success"]]
        if perf_results:
            avg_duration = sum(r["duration"] for r in perf_results) / len(perf_results)
            print(f"  å¹³å‡æ•ˆèƒ½æ¸¬è©¦æ™‚é–“: {avg_duration:.2f}ç§’")
        
        # ç”ŸæˆJSONå ±å‘Š
        self.save_json_report()
        
        print("\\n" + "="*60)
        if self.is_overall_success():
            print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦åŸ·è¡Œå®Œæˆ - æ•´é«”ç‹€æ…‹: æˆåŠŸ")
        else:
            print("âš ï¸  æ¸¬è©¦åŸ·è¡Œå®Œæˆ - ç™¼ç¾å•é¡Œéœ€è¦è™•ç†")
        print("="*60)
    
    def save_json_report(self):
        """å„²å­˜JSONæ ¼å¼å ±å‘Š"""
        report_data = {
            "test_run_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_duration": self.total_time,
            "total_categories": len(self.results),
            "successful_categories": len([r for r in self.results.values() if r["success"]]),
            "failed_categories": len([r for r in self.results.values() if not r["success"]]),
            "total_tests": sum(r["test_count"] for r in self.results.values()),
            "overall_success": self.is_overall_success(),
            "results": self.results
        }
        
        report_file = self.test_root / "UNIFIED_TEST_REPORT.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\\nğŸ“„ è©³ç´°å ±å‘Šå·²å„²å­˜: {report_file}")
    
    def is_overall_success(self) -> bool:
        """åˆ¤æ–·æ•´é«”æ¸¬è©¦æ˜¯å¦æˆåŠŸ"""
        if not self.results:
            return False
        return all(r["success"] for r in self.results.values())


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="SRT GO v2.2.1 çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨")
    parser.add_argument(
        "--categories", "-c", 
        nargs='+',
        help="æŒ‡å®šè¦åŸ·è¡Œçš„æ¸¬è©¦é¡åˆ¥ (ä¾‹å¦‚: --categories å–®å…ƒæ¸¬è©¦ æ•ˆèƒ½æ¸¬è©¦)"
    )
    parser.add_argument(
        "--list", "-l",
        action="store_true", 
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¸¬è©¦é¡åˆ¥"
    )
    parser.add_argument(
        "--quick-mode",
        action="store_true",
        help="å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼ˆè·³éè€—æ™‚æ¸¬è©¦ï¼‰"
    )
    parser.add_argument(
        "--intensive-mode", 
        action="store_true",
        help="å¯†é›†æ¸¬è©¦æ¨¡å¼ï¼ˆåŒ…å«æ‰€æœ‰æ¸¬è©¦ï¼‰"
    )
    parser.add_argument(
        "--component-test",
        action="store_true", 
        help="çµ„ä»¶æ¸¬è©¦æ¨¡å¼"
    )
    parser.add_argument(
        "--pre-build-check",
        action="store_true",
        help="é æ§‹å»ºæª¢æŸ¥æ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    runner = SRTGOTestRunner()
    
    if args.list:
        print("å¯ç”¨çš„æ¸¬è©¦é¡åˆ¥:")
        categories = [
            "å–®å…ƒæ¸¬è©¦", "æ•´åˆæ¸¬è©¦", "æ•ˆèƒ½æ¸¬è©¦", "E2Eæ¸¬è©¦"
        ]
        for i, category in enumerate(categories, 1):
            print(f"  {i}. {category}")
        return
    
    try:
        # æ ¹æ“šæ¨¡å¼èª¿æ•´æ¸¬è©¦è¡Œç‚º
        if args.quick_mode:
            print("[MODE] å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ - è·³éè€—æ™‚æ¸¬è©¦")
        elif args.intensive_mode:
            print("[MODE] å¯†é›†æ¸¬è©¦æ¨¡å¼ - åŒ…å«æ‰€æœ‰æ¸¬è©¦")
        elif args.component_test:
            print("[MODE] çµ„ä»¶æ¸¬è©¦æ¨¡å¼")
        elif args.pre_build_check:
            print("[MODE] é æ§‹å»ºæª¢æŸ¥æ¨¡å¼")
        
        success = runner.run_all_tests(args.categories)
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\\n\\n[STOP] æ¸¬è©¦åŸ·è¡Œè¢«ä½¿ç”¨è€…ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\\n\\n[ERROR] æ¸¬è©¦åŸ·è¡Œå™¨ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()