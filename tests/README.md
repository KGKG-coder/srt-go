# SRT GO v2.2.1 æ¸¬è©¦æ¶æ§‹ | Testing Framework

## ğŸ¯ æ¦‚è¿° | Overview

SRT GO v2.2.1 å•†ç”¨ç´šæ¸¬è©¦æ¶æ§‹ï¼Œæä¾›å®Œæ•´çš„è‡ªå‹•åŒ–æ¸¬è©¦è§£æ±ºæ–¹æ¡ˆï¼Œæ¶µè“‹å¾å–®å…ƒæ¸¬è©¦åˆ°ç«¯åˆ°ç«¯æ¸¬è©¦çš„å®Œæ•´éˆæ¢ã€‚

**å®Œæ•´æ¸¬è©¦çµ±æ•´è¨ˆåŠƒå·²å¯¦æ–½ âœ…**
- ğŸ“Š **25+ æ¸¬è©¦æª”æ¡ˆ**çµ±ä¸€ç®¡ç†
- ğŸ¤– **13 å€‹ GitHub Actions å·¥ä½œæµç¨‹**è‡ªå‹•åŒ–åŸ·è¡Œ  
- âš¡ **RTF æ•ˆèƒ½ç›£æ§ç³»çµ±**å³æ™‚è¿½è¹¤
- ğŸ§ª **çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨**ä¸€éµé‹è¡Œæ‰€æœ‰æ¸¬è©¦

## ğŸš€ å¿«é€Ÿé–‹å§‹ | Quick Start

### çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨ (æ¨è–¦)
```bash
# åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
cd tests
python run_all_tests.py

# æŒ‰é¡åˆ¥åŸ·è¡Œæ¸¬è©¦
python run_all_tests.py --categories å–®å…ƒæ¸¬è©¦
python run_all_tests.py --categories æ•ˆèƒ½æ¸¬è©¦
python run_all_tests.py --categories E2Eæ¸¬è©¦

# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨é¡åˆ¥
python run_all_tests.py --list
```

## ğŸ“‚ æ¸¬è©¦æ¶æ§‹ | Test Structure

```
tests/
â”œâ”€â”€ ğŸ“‹ TEST_CONSOLIDATION_PLAN.md     # å®Œæ•´æ¸¬è©¦çµ±æ•´è¨ˆåŠƒ
â”œâ”€â”€ ğŸ“‹ TEST_INDEX.md                  # æ¸¬è©¦ç´¢å¼•èˆ‡å°èˆª
â”œâ”€â”€ ğŸš€ run_all_tests.py              # çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨
â”œâ”€â”€ âš™ï¸  conftest.py                   # çµ±ä¸€æ¸¬è©¦é…ç½®
â”œâ”€â”€ ğŸ“Š UNIFIED_TEST_REPORT.json      # çµ±ä¸€æ¸¬è©¦å ±å‘Š
â”‚
â”œâ”€â”€ unit/                             # ğŸ”§ å–®å…ƒæ¸¬è©¦
â”œâ”€â”€ integration/                      # ğŸ”— æ•´åˆæ¸¬è©¦  
â”œâ”€â”€ performance/                      # âš¡ æ•ˆèƒ½æ¸¬è©¦
â”œâ”€â”€ e2e/                             # ğŸ¯ ç«¯åˆ°ç«¯æ¸¬è©¦
â”œâ”€â”€ fixtures/                        # ğŸ—‚ï¸ æ¸¬è©¦å¤¾å…·
â””â”€â”€ utils/                           # ğŸ› ï¸ æ¸¬è©¦å·¥å…·
```

## ğŸ“š è©³ç´°æ–‡æª” | Detailed Documentation

- ğŸ“‹ **[TEST_CONSOLIDATION_PLAN.md](TEST_CONSOLIDATION_PLAN.md)** - å®Œæ•´æ¸¬è©¦çµ±æ•´è¨ˆåŠƒ
- ğŸ“‹ **[TEST_INDEX.md](TEST_INDEX.md)** - æ¸¬è©¦ç´¢å¼•èˆ‡å¿«é€Ÿå°èˆª

## ğŸ“Š æ¸¬è©¦è¦†è“‹èˆ‡æ•ˆèƒ½åŸºæº– | Coverage & Baselines

### RTFæ•ˆèƒ½ç›®æ¨™ | RTF Performance Targets
- ğŸ† **Excellent**: RTF â‰¤ 0.2 (å³æ™‚è™•ç†èƒ½åŠ›)
- âœ… **Good**: RTF â‰¤ 0.5 (æ‰¹æ¬¡è™•ç†é©ç”¨)
- âš ï¸ **Acceptable**: RTF â‰¤ 1.0 (åŸºæœ¬éœ€æ±‚)
- âŒ **Needs Improvement**: RTF > 1.0

### æ¸¬è©¦è¦†è“‹ç›®æ¨™ | Coverage Targets  
- **å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡**: â‰¥ 90%
- **æ•´åˆæ¸¬è©¦æˆåŠŸç‡**: â‰¥ 95%
- **E2Eæ¸¬è©¦æˆåŠŸç‡**: â‰¥ 90%
- **è¨˜æ†¶é«”ä½¿ç”¨**: < 2GB å³°å€¼

### Individual Test Categories

#### 1. Performance Tests
```bash
cd tests/performance
python comprehensive_performance_suite.py --standard
python monitor_processing_performance.py
```

#### 2. Integration Tests  
```bash
cd tests/integration
python debug_test_integration.py
python debug_test_integration_low_vad.py
```

#### 3. E2E Tests
```bash
cd tests/e2e
python test_automation_suite.py --full-suite
```

## ğŸ“Š Test Coverage

### Components Tested
- **FP16/INT8 Model Management**: GPU/CPU adaptive selection
- **Adaptive Voice Detection v2.0**: 25D feature analysis
- **Smart Backend Selector**: Python environment fallback
- **Performance Monitor**: Real-time RTF calculation
- **Multi-language Processing**: Auto-detect + Traditional Chinese
- **UI Integration**: Electron + React workflow

### Test Scenarios
1. **Basic Audio Processing**: Short clips (11.3s)
2. **Medical Dialogue**: Professional content (40.3s)
3. **Multi-language**: Chinese to Traditional conversion
4. **Format Support**: SRT, VTT, TXT, JSON outputs
5. **Performance Benchmarks**: RTF < 0.8 validation
6. **Error Handling**: Graceful degradation testing

## ğŸ¯ Quality Metrics

### Target Performance
- **RTF (Real-Time Factor)**
  - GPU Mode: < 0.15 (å„ªç§€ç´š)
  - CPU Mode: < 0.8 (æ¨™æº–ç´š)
- **Accuracy**: 95%+ recognition rate
- **Test Success**: 100% E2E pass rate

### Performance Tiers
1. **å„ªç§€ç´š (Excellent)**: RTF < 0.15
2. **è‰¯å¥½ç´š (Good)**: RTF < 0.3  
3. **æ¨™æº–ç´š (Standard)**: RTF < 0.5
4. **å¯æ¥å—ç´š (Acceptable)**: RTF < 0.8
5. **éœ€å„ªåŒ–ç´š (Needs Optimization)**: RTF > 0.8

## ğŸ”§ Test Configuration

### Environment Variables
```yaml
PYTHON_VERSION: '3.11'
NODE_VERSION: '18'
ELECTRON_CACHE: .cache/electron
HUGGINGFACE_HUB_CACHE: .cache/huggingface
```

### Test Data
- **Test Files**: Located in `srt_whisper_lite/electron-react-app/test_VIDEO/`
- **Sample Data**: 370 audio files (5s to 73.8h coverage)
- **Formats**: MP4, MP3, WAV for comprehensive testing

## ğŸ“ˆ CI/CD Integration

### GitHub Actions Workflows
1. **ci-cd-pipeline.yml**: Complete 7-stage validation
2. **quick-test.yml**: Fast development testing
3. **performance-monitoring.yml**: Daily performance tracking
4. **manual-testing.yml**: Component-specific testing

### Quality Gates
- Unit tests must pass before integration
- Performance regression detection (>20% slower fails)
- Security scan required for releases
- 100% E2E success rate for deployment

## ğŸ› ï¸ Development Testing

### Local Development
```bash
# Quick validation
cd tests/performance
python quick_rtf_test.py --basic-only

# Component testing
cd srt_whisper_lite/electron-react-app
python python/electron_backend.py --files "[\"test_VIDEO/hutest.mp4\"]" --settings "{\"model\":\"medium\"}"

# Build verification
npm run build:with-models
npm run dist:nsis
```

### Mock vs Real Testing
- **CI Environment**: Uses mock backend for speed
- **Local Development**: Real AI processing validation
- **Performance Tests**: Always use real models for accuracy

## ğŸ“š Test Documentation

### Test Reports
- **Performance Reports**: `tests/performance/results/`
- **E2E Results**: `tests/e2e/results/`
- **CI Artifacts**: Available in GitHub Actions runs

### Debugging
- **Logs**: Check `electron_backend.log` for processing details
- **Test Output**: Individual test directories in `/temp/`
- **Validation**: JSON reports with detailed validation steps

## ğŸ” Troubleshooting

### Common Issues
1. **Model Download Failures**
   - Check network connectivity
   - Verify HuggingFace access
   - Clear cache: `rm -rf ~/.cache/huggingface/`

2. **Path Resolution**
   - Use absolute paths in test configurations
   - Verify test file locations
   - Check working directory settings

3. **Performance Variations**
   - Hardware differences affect RTF values
   - GPU availability impacts test results
   - System load can affect performance metrics

### Debug Commands
```bash
# Check Python environment
python -c "import sys; print(sys.version, sys.executable)"

# Verify AI dependencies
python -c "import faster_whisper, torch; print('âœ… AI modules OK')"

# Test model loading
python -c "
import sys; sys.path.append('srt_whisper_lite/electron-react-app/python')
from large_v3_fp16_performance_manager import LargeV3FP16PerformanceManager
manager = LargeV3FP16PerformanceManager()
print('âœ… Model manager OK')
"
```

---

**ğŸ“§ Support**: For testing issues, create GitHub issue with:
- Test name and scenario
- Error logs and stack traces
- System configuration details
- Steps to reproduce

**ğŸ”„ Continuous Improvement**: Test suite evolves with each release to maintain quality standards and performance targets.