#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Large V2 æœ€å„ªåŒ–åƒæ•¸æ¸¬è©¦è…³æœ¬
åŸºæ–¼å®Œæ•´ç ”ç©¶çµæœï¼Œæ¸¬è©¦Large V2ä½œç‚ºå–®ä¸€æ¨¡å‹è§£æ±ºæ–¹æ¡ˆçš„æ•ˆæœ
é‡é»é©—è­‰æ™‚é–“è»¸æº–ç¢ºæ€§å’Œè™•ç†æ•ˆç‡
"""

import sys
import json
import logging
import time
from pathlib import Path
import os
import re

# è¨­å®šæ§åˆ¶å°ç·¨ç¢¼
if sys.platform.startswith('win'):
    os.system('chcp 65001 > NUL')
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from faster_whisper import WhisperModel
    logger.info("Faster-Whisper æ¨¡çµ„å°å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"Faster-Whisper å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

# Large V2 æœ€å„ªåŒ–é…ç½®
LARGE_V2_OPTIMAL_CONFIG = {
    "name": "Large V2 ç”Ÿç”¢ç’°å¢ƒæœ€å„ªé…ç½®",
    "description": "æ™‚é–“è»¸æº–ç¢ºã€é€Ÿåº¦å¿«ã€ç©©å®šå¯é ",
    "model": "large-v2",
    
    # æœ€å„ªVADåƒæ•¸ï¼ˆåŸºæ–¼å¯¦æ¸¬ï¼‰
    "vad_parameters": {
        "threshold": 0.15,              # å¹³è¡¡è¨­å®šï¼Œé©ç”¨99%å ´æ™¯
        "min_speech_duration_ms": 100,  # 100msæœ€çŸ­èªéŸ³
        "min_silence_duration_ms": 300, # 300msæœ€çŸ­éœéŸ³
        "speech_pad_ms": 100            # 100msèªéŸ³å¡«å……
    },
    
    # Whisperå„ªåŒ–åƒæ•¸
    "whisper_params": {
        "beam_size": 5,                 # å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºæ€§
        "word_timestamps": True,         # å•Ÿç”¨è©ç´šæ™‚é–“æˆ³
        "condition_on_previous_text": True,  # ä¸Šä¸‹æ–‡å¢å¼·
        "compression_ratio_threshold": 2.4,  # å£“ç¸®æ¯”é–¾å€¼
        "log_prob_threshold": -1.0,     # å°æ•¸æ¦‚ç‡é–¾å€¼
        "no_speech_threshold": 0.6      # ç„¡èªéŸ³é–¾å€¼
    },
    
    # é æœŸæ€§èƒ½æŒ‡æ¨™
    "expected_performance": {
        "æ™‚é–“è»¸æº–ç¢ºåº¦": "95%+",
        "è™•ç†é€Ÿåº¦": "0.8-1.2xå¯¦æ™‚",
        "èªè¨€ä¿¡å¿ƒåº¦": "99%+",
        "æ®µè½å¯†åº¦": "0.4-0.8æ®µ/ç§’"
    }
}

def analyze_timestamp_accuracy(segments):
    """åˆ†ææ™‚é–“è»¸æº–ç¢ºæ€§"""
    if not segments:
        return {}
    
    # è¨ˆç®—æ™‚é–“è»¸ç‰¹å¾µ
    gaps = []
    overlaps = 0
    short_segments = 0
    
    for i in range(len(segments) - 1):
        gap = segments[i+1]['start'] - segments[i]['end']
        if gap < 0:
            overlaps += 1
        else:
            gaps.append(gap)
        
        duration = segments[i]['end'] - segments[i]['start']
        if duration < 0.5:  # å°æ–¼0.5ç§’è¦–ç‚ºéçŸ­
            short_segments += 1
    
    avg_gap = sum(gaps) / len(gaps) if gaps else 0
    
    return {
        'total_segments': len(segments),
        'overlapping_segments': overlaps,
        'short_segments': short_segments,
        'average_gap': round(avg_gap, 3),
        'min_gap': round(min(gaps), 3) if gaps else 0,
        'max_gap': round(max(gaps), 3) if gaps else 0,
        'timestamp_quality': 'Excellent' if overlaps == 0 and short_segments < 3 else 
                           'Good' if overlaps <= 2 else 'Poor'
    }

def test_large_v2_optimal(audio_file, output_file):
    """æ¸¬è©¦Large V2æœ€å„ªåŒ–é…ç½®"""
    try:
        config = LARGE_V2_OPTIMAL_CONFIG
        
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ¯ æ¸¬è©¦ {config['name']}")
        logger.info(f"ğŸ“ {config['description']}")
        logger.info(f"ğŸµ éŸ³é »æª”æ¡ˆ: {Path(audio_file).name}")
        logger.info(f"{'='*80}")
        
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        start_time = time.time()
        
        # è¼‰å…¥æ¨¡å‹
        logger.info(f"â³ è¼‰å…¥ {config['model']} æ¨¡å‹...")
        model_load_start = time.time()
        model = WhisperModel(
            config['model'], 
            device="cpu", 
            compute_type="int8"
        )
        model_load_time = time.time() - model_load_start
        logger.info(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ ({model_load_time:.2f}ç§’)")
        
        # åŸ·è¡Œè½‰éŒ„
        logger.info("ğŸ¤ é–‹å§‹è½‰éŒ„...")
        transcribe_start = time.time()
        
        segments, info = model.transcribe(
            audio_file,
            language=None,  # è‡ªå‹•æª¢æ¸¬
            vad_filter=True,
            vad_parameters=config['vad_parameters'],
            **config['whisper_params']
        )
        
        # è™•ç†çµæœ
        segment_list = []
        for segment in segments:
            segment_data = {
                'id': len(segment_list) + 1,
                'start': segment.start,
                'end': segment.end,
                'text': segment.text.strip(),
                'duration': segment.end - segment.start
            }
            
            # å¦‚æœæœ‰è©ç´šæ™‚é–“æˆ³
            if hasattr(segment, 'words') and segment.words:
                segment_data['word_count'] = len(segment.words)
                segment_data['words'] = [
                    {
                        'word': w.word,
                        'start': w.start,
                        'end': w.end,
                        'probability': w.probability
                    } for w in segment.words
                ]
            
            segment_list.append(segment_data)
        
        transcribe_time = time.time() - transcribe_start
        total_time = time.time() - start_time
        
        # ç”ŸæˆSRT
        srt_content = generate_srt_from_segments(segment_list)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        # åˆ†ææ™‚é–“è»¸æº–ç¢ºæ€§
        timestamp_analysis = analyze_timestamp_accuracy(segment_list)
        
        # è¨ˆç®—è©³ç´°çµ±è¨ˆ
        if segment_list:
            segment_durations = [seg['duration'] for seg in segment_list]
            total_speech_time = sum(segment_durations)
            avg_segment_duration = total_speech_time / len(segment_list)
            segments_per_second = len(segment_list) / info.duration
            speech_ratio = total_speech_time / info.duration
            
            # è¨ˆç®—èªè¨€ä¿¡å¿ƒåº¦çµ±è¨ˆ
            if segment_list[0].get('words'):
                all_probs = []
                for seg in segment_list:
                    if seg.get('words'):
                        all_probs.extend([w['probability'] for w in seg['words']])
                avg_word_confidence = sum(all_probs) / len(all_probs) if all_probs else 0
            else:
                avg_word_confidence = 0
        else:
            total_speech_time = avg_segment_duration = segments_per_second = speech_ratio = 0
            avg_word_confidence = 0
        
        # çµæœå½™ç¸½
        result = {
            'success': True,
            'config_name': config['name'],
            'model': config['model'],
            'vad_config': config['vad_parameters'],
            
            # åŸºæœ¬çµ±è¨ˆ
            'audio_duration': round(info.duration, 2),
            'segment_count': len(segment_list),
            'segments_per_second': round(segments_per_second, 3),
            'avg_segment_duration': round(avg_segment_duration, 3),
            'speech_ratio': round(speech_ratio, 3),
            
            # æ™‚é–“è»¸åˆ†æ
            'timestamp_analysis': timestamp_analysis,
            
            # èªè¨€æª¢æ¸¬
            'language': info.language,
            'language_probability': round(info.language_probability, 4),
            'avg_word_confidence': round(avg_word_confidence, 4),
            
            # æ€§èƒ½çµ±è¨ˆ
            'model_load_time': round(model_load_time, 2),
            'transcribe_time': round(transcribe_time, 2),
            'total_time': round(total_time, 2),
            'real_time_factor': round(transcribe_time / info.duration, 2),
            
            # æª”æ¡ˆè³‡è¨Š
            'output_file': str(output_file),
            'segment_details': segment_list[:5]  # å‰5å€‹æ®µè½è©³æƒ…
        }
        
        # è¼¸å‡ºçµæœæ‘˜è¦
        logger.info(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
        logger.info(f"  âœ… æ®µè½æ•¸: {len(segment_list)}æ®µ")
        logger.info(f"  âœ… æ®µè½å¯†åº¦: {segments_per_second:.2f}æ®µ/ç§’")
        logger.info(f"  âœ… å¹³å‡æ®µè½æ™‚é•·: {avg_segment_duration:.2f}ç§’")
        logger.info(f"  âœ… è™•ç†é€Ÿåº¦: {result['real_time_factor']:.2f}xå¯¦æ™‚")
        logger.info(f"  âœ… èªè¨€: {info.language} (ä¿¡å¿ƒåº¦: {info.language_probability:.3f})")
        logger.info(f"  âœ… æ™‚é–“è»¸å“è³ª: {timestamp_analysis['timestamp_quality']}")
        logger.info(f"  âœ… é‡ç–Šæ®µè½: {timestamp_analysis['overlapping_segments']}å€‹")
        logger.info(f"  âœ… éçŸ­æ®µè½: {timestamp_analysis['short_segments']}å€‹")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'error': str(e)
        }

def generate_srt_from_segments(segments):
    """å¾æ®µè½ç”ŸæˆSRTæ ¼å¼"""
    def format_timestamp(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    srt_content = ""
    for segment in segments:
        segment_id = segment.get('id', len(srt_content.split('\n\n')) + 1)
        start_time = format_timestamp(segment['start'])
        end_time = format_timestamp(segment['end'])
        text = segment['text']
        
        srt_content += f"{segment_id}\n{start_time} --> {end_time}\n{text}\n\n"
    
    return srt_content

def run_comprehensive_v2_testing(test_files, output_dir):
    """åŸ·è¡Œå…¨é¢çš„Large V2æ¸¬è©¦"""
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"ğŸš€ é–‹å§‹ Large V2 æœ€å„ªåŒ–åƒæ•¸æ¸¬è©¦")
    logger.info(f"ğŸ“ æ¸¬è©¦æª”æ¡ˆæ•¸: {len(test_files)}")
    logger.info(f"ğŸ’¾ è¼¸å‡ºç›®éŒ„: {output_dir}")
    
    all_results = []
    
    for i, test_file in enumerate(test_files):
        if not Path(test_file).exists():
            logger.warning(f"âš ï¸ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨: {test_file}")
            continue
        
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ“ æ¸¬è©¦ {i+1}/{len(test_files)}")
        
        # ç”Ÿæˆè¼¸å‡ºæª”å
        file_stem = Path(test_file).stem
        output_file = output_path / f"{file_stem}_v2_optimal.srt"
        
        # åŸ·è¡Œæ¸¬è©¦
        result = test_large_v2_optimal(test_file, output_file)
        result['test_file'] = str(test_file)
        result['file_name'] = Path(test_file).name
        
        all_results.append(result)
        
        # çŸ­æš«å»¶é²é¿å…è³‡æºè¡çª
        time.sleep(1)
    
    return all_results

def analyze_v2_results(results):
    """åˆ†æV2æ¸¬è©¦çµæœ"""
    
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ“Š Large V2 æœ€å„ªåŒ–æ¸¬è©¦çµæœåˆ†æ")
    logger.info(f"{'='*80}")
    
    successful_results = [r for r in results if r.get('success', False)]
    
    if not successful_results:
        logger.error("âŒ æ²’æœ‰æˆåŠŸçš„æ¸¬è©¦çµæœ")
        return
    
    # ç¸½é«”çµ±è¨ˆ
    logger.info(f"\nğŸ¯ ç¸½é«”çµ±è¨ˆ:")
    logger.info(f"  æˆåŠŸæ¸¬è©¦: {len(successful_results)}/{len(results)}")
    
    avg_rtf = sum(r['real_time_factor'] for r in successful_results) / len(successful_results)
    avg_segments_per_sec = sum(r['segments_per_second'] for r in successful_results) / len(successful_results)
    avg_confidence = sum(r['language_probability'] for r in successful_results) / len(successful_results)
    
    logger.info(f"  å¹³å‡è™•ç†é€Ÿåº¦: {avg_rtf:.2f}xå¯¦æ™‚")
    logger.info(f"  å¹³å‡æ®µè½å¯†åº¦: {avg_segments_per_sec:.3f}æ®µ/ç§’")
    logger.info(f"  å¹³å‡èªè¨€ä¿¡å¿ƒåº¦: {avg_confidence:.3f}")
    
    # æ™‚é–“è»¸å“è³ªçµ±è¨ˆ
    excellent_count = sum(1 for r in successful_results 
                         if r['timestamp_analysis']['timestamp_quality'] == 'Excellent')
    logger.info(f"  æ™‚é–“è»¸å“è³ªå„ªç§€: {excellent_count}/{len(successful_results)}")
    
    # å€‹åˆ¥æª”æ¡ˆçµæœ
    logger.info(f"\nğŸ“‹ å€‹åˆ¥æª”æ¡ˆçµæœ:")
    for result in successful_results:
        logger.info(f"\n  {result['file_name']}:")
        logger.info(f"    æ®µè½æ•¸: {result['segment_count']}æ®µ")
        logger.info(f"    è™•ç†é€Ÿåº¦: {result['real_time_factor']:.2f}xå¯¦æ™‚")
        logger.info(f"    æ™‚é–“è»¸å“è³ª: {result['timestamp_analysis']['timestamp_quality']}")
        logger.info(f"    èªè¨€ä¿¡å¿ƒåº¦: {result['language_probability']:.3f}")
        
        # é¡¯ç¤ºå‰3å€‹æ®µè½ä½œç‚ºæ¨£æœ¬
        if result.get('segment_details'):
            logger.info(f"    å‰3å€‹æ®µè½æ¨£æœ¬:")
            for seg in result['segment_details'][:3]:
                logger.info(f"      [{seg['start']:.2f}-{seg['end']:.2f}] \"{seg['text'][:30]}...\"")

def main():
    """ä¸»å‡½æ•¸"""
    
    # æ¸¬è©¦æª”æ¡ˆæ¸…å–®
    test_files = [
        "C:/Users/USER-ART0/Desktop/hutest.mp3",        # çŸ­éŸ³é » (~11ç§’)
        "C:/Users/USER-ART0/Desktop/DRLIN.mp4",         # ä¸­éŸ³é » (~40ç§’)  
        "C:/Users/USER-ART0/Desktop/C0485.MP4"          # é•·éŸ³é » (~140ç§’)
    ]
    
    output_dir = "C:/Users/USER-ART0/Desktop/large_v2_optimal_validation"
    
    # æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆ
    available_files = [f for f in test_files if Path(f).exists()]
    if not available_files:
        logger.error("âŒ æ²’æœ‰å¯ç”¨çš„æ¸¬è©¦æª”æ¡ˆ")
        return None
    
    logger.info(f"ğŸ¯ Large V2 æœ€å„ªåŒ–åƒæ•¸é©—è­‰æ¸¬è©¦")
    logger.info(f"âœ… å¯ç”¨æ¸¬è©¦æª”æ¡ˆ: {len(available_files)}/{len(test_files)}")
    
    try:
        # åŸ·è¡Œæ¸¬è©¦
        results = run_comprehensive_v2_testing(available_files, output_dir)
        
        # åˆ†æçµæœ
        analyze_v2_results(results)
        
        # ç”Ÿæˆè©³ç´°å ±å‘Š
        report = {
            'test_metadata': {
                'model': 'large-v2',
                'config': LARGE_V2_OPTIMAL_CONFIG,
                'test_files': available_files,
                'total_tests': len(results),
                'successful_tests': len([r for r in results if r.get('success', False)]),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'test_results': results,
            'summary': {
                'average_rtf': sum(r['real_time_factor'] for r in results if r.get('success')) / 
                              len([r for r in results if r.get('success')]) if results else 0,
                'average_segments_per_second': sum(r['segments_per_second'] for r in results if r.get('success')) / 
                                              len([r for r in results if r.get('success')]) if results else 0,
                'timestamp_quality': {
                    'excellent': sum(1 for r in results if r.get('success') and 
                                   r['timestamp_analysis']['timestamp_quality'] == 'Excellent'),
                    'good': sum(1 for r in results if r.get('success') and 
                              r['timestamp_analysis']['timestamp_quality'] == 'Good'),
                    'poor': sum(1 for r in results if r.get('success') and 
                              r['timestamp_analysis']['timestamp_quality'] == 'Poor')
                }
            }
        }
        
        # ä¿å­˜å ±å‘Š
        report_file = Path(output_dir) / 'large_v2_optimal_test_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nâœ… Large V2 æœ€å„ªåŒ–æ¸¬è©¦å®Œæˆï¼")
        logger.info(f"ğŸ“‹ è©³ç´°å ±å‘Šå·²ä¿å­˜: {report_file}")
        
        # çµè«–
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ† çµè«–")
        logger.info(f"{'='*80}")
        logger.info(f"Large V2 é…ç½®è¡¨ç¾:")
        
        if report['summary']['timestamp_quality']['excellent'] == len(available_files):
            logger.info(f"  âœ… æ™‚é–“è»¸å“è³ª: å®Œç¾ (æ‰€æœ‰æª”æ¡ˆéƒ½é”åˆ°Excellent)")
        else:
            logger.info(f"  âš ï¸ æ™‚é–“è»¸å“è³ª: è‰¯å¥½ (éƒ¨åˆ†æª”æ¡ˆéœ€è¦æ³¨æ„)")
        
        if report['summary']['average_rtf'] < 1.5:
            logger.info(f"  âœ… è™•ç†é€Ÿåº¦: å„ªç§€ (å¹³å‡ {report['summary']['average_rtf']:.2f}xå¯¦æ™‚)")
        else:
            logger.info(f"  âš ï¸ è™•ç†é€Ÿåº¦: å¯æ¥å— (å¹³å‡ {report['summary']['average_rtf']:.2f}xå¯¦æ™‚)")
        
        logger.info(f"  âœ… æ®µè½å¯†åº¦: {report['summary']['average_segments_per_second']:.3f}æ®µ/ç§’")
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return None

if __name__ == "__main__":
    try:
        report = main()
        if report and report['test_metadata']['successful_tests'] > 0:
            print(f"\nğŸ‰ Large V2 æœ€å„ªåŒ–æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
            print(f"æˆåŠŸæ¸¬è©¦: {report['test_metadata']['successful_tests']}/{report['test_metadata']['total_tests']}")
        else:
            print(f"\nğŸ’¥ æ¸¬è©¦å¤±æ•—ï¼")
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºå¤±æ•—: {e}")
        sys.exit(1)