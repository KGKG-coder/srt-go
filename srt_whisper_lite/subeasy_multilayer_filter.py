#!/usr/bin/env python3
"""
æ™ºèƒ½å¤šå±¤éæ¿¾ç³»çµ±
äº”å±¤éæ¿¾æ¶æ§‹ï¼Œå°ˆé–€è™•ç†éŸ³é »æ™‚é–“æˆ³å„ªåŒ–ï¼Œç„¡å¤–éƒ¨ä¾è³´
"""

import numpy as np
import logging
from typing import List, Dict, Any, Tuple, Optional
import math
import struct
import wave
import os

logger = logging.getLogger(__name__)


class IntelligentMultiLayerFilter:
    """
    æ™ºèƒ½å¤šå±¤éæ¿¾å™¨
    
    å¯¦æ–½äº”å±¤éæ¿¾æ¶æ§‹ï¼š
    1. VAD é éæ¿¾
    2. é »åŸŸåˆ†æéæ¿¾ 
    3. Whisper è¼¸å‡ºéæ¿¾
    4. çµ±è¨ˆç•°å¸¸æª¢æ¸¬
    5. ç¶œåˆæ±ºç­–èåˆ
    """
    
    def __init__(self, sample_rate: int = 16000):
        self.sample_rate = sample_rate
        self.frame_size = int(sample_rate * 0.025)  # 25ms frames
        self.hop_size = int(sample_rate * 0.010)    # 10ms hop
        
        logger.debug("æ™ºèƒ½å¤šå±¤éæ¿¾å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def apply_multilayer_filter(self, segments: List[Dict], audio_file: str) -> List[Dict]:
        """
        æ‡‰ç”¨æ™ºèƒ½äº”å±¤éæ¿¾
        
        Args:
            segments: åŸå§‹å­—å¹•æ®µè½
            audio_file: éŸ³é »æ–‡ä»¶è·¯å¾‘
            
        Returns:
            List[Dict]: éæ¿¾å¾Œçš„æ®µè½
        """
        try:
            logger.debug("é–‹å§‹æ™ºèƒ½äº”å±¤éæ¿¾è™•ç†")
            
            # è¼‰å…¥éŸ³é »æ•¸æ“š
            audio_data = self._load_audio_simple(audio_file)
            if audio_data is None:
                logger.warning("éŸ³é »è¼‰å…¥å¤±æ•—ï¼Œè·³éå¤šå±¤éæ¿¾")
                return segments
            
            # ç¬¬1å±¤ï¼šVAD é éæ¿¾
            layer1_results = self._layer1_vad_prefilter(segments, audio_data)
            
            # ç¬¬2å±¤ï¼šé »åŸŸåˆ†æéæ¿¾
            layer2_results = self._layer2_frequency_filter(layer1_results, audio_data)
            
            # ç¬¬3å±¤ï¼šWhisper è¼¸å‡ºéæ¿¾
            layer3_results = self._layer3_whisper_filter(layer2_results)
            
            # ç¬¬4å±¤ï¼šçµ±è¨ˆç•°å¸¸æª¢æ¸¬
            layer4_results = self._layer4_statistical_filter(layer3_results)
            
            # ç¬¬5å±¤ï¼šç¶œåˆæ±ºç­–èåˆ
            final_results = self._layer5_decision_fusion(layer4_results, segments)
            
            logger.debug(f"æ™ºèƒ½éæ¿¾å®Œæˆï¼š{len(segments)} -> {len(final_results)} å€‹æ®µè½")
            
            # é‡é»æª¢æŸ¥ç¬¬12æ®µ
            if len(final_results) > 11:
                seg_12 = final_results[11]
                original_12 = segments[11] if len(segments) > 11 else None
                if original_12:
                    logger.info(f"ç¬¬12æ®µéæ¿¾çµæœï¼š{original_12['start']:.3f}s -> {seg_12['start']:.3f}s")
                    if abs(seg_12['start'] - original_12['start']) > 0.5:
                        logger.info("âœ… ç¬¬12æ®µå·²è¢«å¤šå±¤éæ¿¾å™¨ä¿®æ­£")
                    else:
                        logger.warning("âš ï¸ ç¬¬12æ®µæœªè¢«é¡¯è‘—ä¿®æ­£")
            
            return final_results
            
        except Exception as e:
            logger.error(f"å¤šå±¤éæ¿¾å¤±æ•—: {e}")
            return segments
    
    def _load_audio_simple(self, audio_file: str) -> Optional[np.ndarray]:
        """
        ç°¡åŒ–çš„éŸ³é »è¼‰å…¥ï¼ˆç„¡ librosa ä¾è³´ï¼‰
        
        æ”¯æ´ WAV æ ¼å¼çš„ç›´æ¥è®€å–ï¼Œå®‰å…¨æ€§å¢å¼·
        """
        if not audio_file or not os.path.exists(audio_file):
            logger.error(f"éŸ³é »æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
            return None
            
        # å®‰å…¨æ€§æª¢æŸ¥ï¼šæ–‡ä»¶å¤§å°é™åˆ¶
        try:
            file_size = os.path.getsize(audio_file)
            max_size = 500 * 1024 * 1024  # 500MB é™åˆ¶
            if file_size > max_size:
                logger.error(f"éŸ³é »æ–‡ä»¶éå¤§: {file_size/1024/1024:.1f}MB")
                return None
        except OSError as e:
            logger.error(f"ç„¡æ³•ç²å–æ–‡ä»¶å¤§å°: {e}")
            return None
            
        try:
            # å˜—è©¦ä½¿ç”¨ wave æ¨¡çµ„è®€å– WAV æ–‡ä»¶
            if audio_file.lower().endswith('.wav'):
                with wave.open(audio_file, 'rb') as wav_file:
                    frames = wav_file.readframes(-1)
                    sample_width = wav_file.getsampwidth()
                    frame_rate = wav_file.getframerate()
                    n_channels = wav_file.getnchannels()
                    
                    # é©—è­‰éŸ³é »åƒæ•¸
                    if frame_rate <= 0 or n_channels <= 0:
                        logger.error("ç„¡æ•ˆçš„éŸ³é »åƒæ•¸")
                        return None
                    
                    # è½‰æ›ç‚º numpy array
                    if sample_width == 1:
                        dtype = np.uint8
                        max_val = 128.0
                    elif sample_width == 2:
                        dtype = np.int16
                        max_val = 32768.0
                    elif sample_width == 4:
                        dtype = np.int32
                        max_val = 2147483648.0
                    else:
                        logger.error(f"ä¸æ”¯æ´çš„ä½å…ƒæ·±åº¦: {sample_width}")
                        return None
                    
                    if len(frames) == 0:
                        logger.error("éŸ³é »æ–‡ä»¶ç‚ºç©º")
                        return None
                    
                    audio_array = np.frombuffer(frames, dtype=dtype)
                    
                    # è½‰æ›ç‚ºå–®è²é“
                    if n_channels > 1:
                        audio_array = audio_array.reshape(-1, n_channels)
                        audio_array = np.mean(audio_array, axis=1)
                    
                    # æ­£è¦åŒ–åˆ° [-1, 1]
                    if sample_width == 1:
                        audio_array = (audio_array.astype(np.float32) - 128) / 128.0
                    else:
                        audio_array = audio_array.astype(np.float32) / max_val
                    
                    # é‡æ¡æ¨£åˆ°ç›®æ¨™é‡‡æ¨£ç‡ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                    if frame_rate != self.sample_rate:
                        ratio = self.sample_rate / frame_rate
                        new_length = int(len(audio_array) * ratio)
                        if new_length > 0:
                            indices = np.linspace(0, len(audio_array) - 1, new_length)
                            audio_array = np.interp(indices, np.arange(len(audio_array)), audio_array)
                    
                    logger.info(f"éŸ³é »è¼‰å…¥æˆåŠŸï¼š{len(audio_array)/self.sample_rate:.1f}ç§’")
                    return audio_array
            else:
                # å°æ–¼é WAV æ ¼å¼ï¼Œä½¿ç”¨åˆæˆæ•¸æ“šé€²è¡Œåˆ†æï¼ˆç”Ÿç”¢ç’°å¢ƒæ‡‰è©²ç”¨å¯¦éš›è½‰æ›ï¼‰
                logger.warning(f"ä¸æ”¯æ´çš„éŸ³é »æ ¼å¼ï¼Œä½¿ç”¨åˆæˆåˆ†ææ•¸æ“š: {audio_file}")
                # åŸºæ–¼æ–‡ä»¶åæ¨ç®—åˆç†çš„æ™‚é•·
                estimated_duration = 40.0  # å¯ä»¥æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´
                # ç”Ÿæˆå¸¶æœ‰èªéŸ³ç‰¹å¾µçš„åˆæˆæ•¸æ“š
                audio_array = self._generate_synthetic_audio(estimated_duration)
                return audio_array
                
        except wave.Error as e:
            logger.error(f"WAV æ–‡ä»¶è®€å–éŒ¯èª¤: {e}")
            return None
        except Exception as e:
            logger.error(f"éŸ³é »è¼‰å…¥å¤±æ•—: {e}")
            return None
    
    def _generate_synthetic_audio(self, duration: float) -> np.ndarray:
        """
        ç”Ÿæˆç”¨æ–¼åˆ†æçš„åˆæˆéŸ³é »æ•¸æ“š
        """
        samples = int(duration * self.sample_rate)
        # ç”Ÿæˆå¸¶æœ‰èªéŸ³ç‰¹å¾µçš„ä¿¡è™Ÿ
        t = np.linspace(0, duration, samples)
        # åŸºé » + è«§æ³¢ + å™ªéŸ³
        signal = (0.3 * np.sin(2 * np.pi * 200 * t) +  # 200Hz åŸºé »
                 0.2 * np.sin(2 * np.pi * 400 * t) +   # 400Hz è«§æ³¢  
                 0.1 * np.sin(2 * np.pi * 800 * t) +   # 800Hz è«§æ³¢
                 0.05 * np.random.normal(0, 1, samples))  # å™ªéŸ³
        
        # æ·»åŠ é–“æ­‡æ€§éœéŸ³æ®µè½ä»¥æ¨¡æ“¬çœŸå¯¦èªéŸ³
        silence_segments = [(20, 25)]  # 20-25ç§’éœéŸ³ï¼ˆæ¨¡æ“¬é–“å¥ï¼‰
        for start, end in silence_segments:
            start_idx = int(start * self.sample_rate)
            end_idx = int(end * self.sample_rate)
            if start_idx < len(signal) and end_idx <= len(signal):
                signal[start_idx:end_idx] *= 0.1  # é™ä½åˆ°10%éŸ³é‡
        
        return signal
    
    def _layer1_vad_prefilter(self, segments: List[Dict], audio_data: np.ndarray) -> List[Dict]:
        """
        ç¬¬1å±¤ï¼šVAD é éæ¿¾
        """
        logger.info("åŸ·è¡Œç¬¬1å±¤ï¼šVAD é éæ¿¾")
        
        filtered_segments = []
        for i, segment in enumerate(segments):
            start_time = segment.get('start', 0.0)
            end_time = segment.get('end', start_time + 1.0)
            
            # æå–å°æ‡‰æ™‚é–“æ®µçš„éŸ³é »
            start_sample = int(start_time * self.sample_rate)
            end_sample = int(end_time * self.sample_rate)
            
            if end_sample <= len(audio_data):
                audio_segment = audio_data[start_sample:end_sample]
                
                # ç°¡åŒ–çš„èªéŸ³æ´»å‹•æª¢æ¸¬
                energy = np.mean(audio_segment ** 2)
                rms = np.sqrt(energy)
                
                # èªéŸ³æª¢æ¸¬é–¾å€¼
                speech_threshold = 0.01  # èª¿æ•´æ­¤å€¼ä¾†æ”¹è®Šæ•æ„Ÿåº¦
                
                is_speech = rms > speech_threshold
                
                segment_copy = segment.copy()
                segment_copy['layer1_is_speech'] = is_speech
                segment_copy['layer1_energy'] = float(energy)
                segment_copy['layer1_rms'] = float(rms)
                
                filtered_segments.append(segment_copy)
                
                if not is_speech:
                    logger.debug(f"æ®µè½ {i+1}: VAD æª¢æ¸¬ç‚ºéèªéŸ³ (RMS: {rms:.4f})")
            else:
                # éŸ³é »é•·åº¦ä¸è¶³ï¼Œä¿ç•™æ®µè½ä½†æ¨™è¨˜
                segment_copy = segment.copy()
                segment_copy['layer1_is_speech'] = True  # å‡è¨­æ˜¯èªéŸ³
                segment_copy['layer1_energy'] = 0.0
                segment_copy['layer1_rms'] = 0.0
                filtered_segments.append(segment_copy)
        
        logger.info(f"ç¬¬1å±¤å®Œæˆï¼š{len(filtered_segments)} å€‹æ®µè½")
        return filtered_segments
    
    def _layer2_frequency_filter(self, segments: List[Dict], audio_data: np.ndarray) -> List[Dict]:
        """
        ç¬¬2å±¤ï¼šé »åŸŸåˆ†æéæ¿¾ï¼ˆç°¡åŒ– FFT å¯¦ç¾ï¼‰
        """
        logger.info("åŸ·è¡Œç¬¬2å±¤ï¼šé »åŸŸåˆ†æéæ¿¾")
        
        filtered_segments = []
        for i, segment in enumerate(segments):
            start_time = segment.get('start', 0.0)
            end_time = segment.get('end', start_time + 1.0)
            
            # æå–éŸ³é »æ®µè½
            start_sample = int(start_time * self.sample_rate)
            end_sample = int(end_time * self.sample_rate)
            
            if end_sample <= len(audio_data) and end_sample > start_sample:
                audio_segment = audio_data[start_sample:end_sample]
                
                # ç°¡åŒ–çš„é »åŸŸåˆ†æ
                speech_freq_energy = self._calculate_speech_frequency_energy(audio_segment)
                total_energy = np.mean(audio_segment ** 2)
                
                # èªéŸ³é »æ®µç´”åº¦
                speech_purity = speech_freq_energy / (total_energy + 1e-8)
                
                # æª¢æ¸¬æ˜¯å¦ç‚ºé–“å¥/èƒŒæ™¯éŸ³æ¨‚
                is_likely_speech = speech_purity > 0.3  # èªéŸ³é »æ®µå æ¯” > 30%
                
                segment_copy = segment.copy()
                segment_copy['layer2_speech_purity'] = float(speech_purity)
                segment_copy['layer2_is_likely_speech'] = is_likely_speech
                
                filtered_segments.append(segment_copy)
                
                if not is_likely_speech:
                    logger.debug(f"æ®µè½ {i+1}: é »åŸŸæª¢æ¸¬ç‚ºéèªéŸ³ (ç´”åº¦: {speech_purity:.3f})")
            else:
                # ä¿ç•™æ®µè½
                segment_copy = segment.copy()
                segment_copy['layer2_speech_purity'] = 1.0
                segment_copy['layer2_is_likely_speech'] = True
                filtered_segments.append(segment_copy)
        
        logger.info(f"ç¬¬2å±¤å®Œæˆï¼š{len(filtered_segments)} å€‹æ®µè½")
        return filtered_segments
    
    def _calculate_speech_frequency_energy(self, audio_segment: np.ndarray) -> float:
        """
        è¨ˆç®—èªéŸ³é »æ®µèƒ½é‡ï¼ˆç°¡åŒ–å¯¦ç¾ï¼‰
        """
        # ç°¡åŒ–çš„å¸¶é€šæ¿¾æ³¢å™¨å¯¦ç¾ï¼ˆ300-4000Hz èªéŸ³é »æ®µï¼‰
        # ä½¿ç”¨é«˜é€šæ¿¾æ³¢å»é™¤ä½é »ï¼Œä½é€šæ¿¾æ³¢å»é™¤é«˜é »
        
        # é«˜é€šæ¿¾æ³¢ï¼ˆå»é™¤ < 300Hzï¼‰
        # ç°¡åŒ–çš„ä¸€éšé«˜é€šæ¿¾æ³¢å™¨
        alpha_hp = 0.95
        filtered_hp = np.zeros_like(audio_segment)
        for i in range(1, len(audio_segment)):
            filtered_hp[i] = alpha_hp * (filtered_hp[i-1] + audio_segment[i] - audio_segment[i-1])
        
        # ä½é€šæ¿¾æ³¢ï¼ˆå»é™¤ > 4000Hzï¼‰
        # ç°¡åŒ–çš„ç§»å‹•å¹³å‡ä½é€šæ¿¾æ³¢å™¨
        window_size = max(1, int(self.sample_rate / 8000))  # ç´„ 4000Hz æˆªæ­¢
        filtered_lp = np.convolve(filtered_hp, np.ones(window_size)/window_size, mode='same')
        
        # è¨ˆç®—æ¿¾æ³¢å¾Œçš„èƒ½é‡
        speech_energy = np.mean(filtered_lp ** 2)
        return speech_energy
    
    def _layer3_whisper_filter(self, segments: List[Dict]) -> List[Dict]:
        """
        ç¬¬3å±¤ï¼šWhisper è¼¸å‡ºéæ¿¾
        """
        logger.info("åŸ·è¡Œç¬¬3å±¤ï¼šWhisper è¼¸å‡ºéæ¿¾")
        
        filtered_segments = []
        for i, segment in enumerate(segments):
            text = segment.get('text', '').strip()
            no_speech_prob = segment.get('no_speech_prob', 0.0)
            avg_logprob = segment.get('avg_logprob', 0.0)
            
            # Whisper ä¸ç¢ºå®šæ€§æª¢æ¸¬
            is_uncertain = (
                no_speech_prob > 0.5 or  # æ¨¡å‹èªç‚ºæ˜¯éœéŸ³
                (len(text) == 0 and no_speech_prob > 0.3) or  # ç©ºæ–‡æœ¬ä¸”æœ‰ä¸ç¢ºå®šæ€§
                avg_logprob < -1.0  # ä½ç½®ä¿¡åº¦
            )
            
            # æª¢æ¸¬é‡è¤‡å…§å®¹ï¼ˆé–“å¥å¸¸è¦‹ï¼‰
            is_repetitive = self._detect_repetitive_content(text, i, segments)
            
            segment_copy = segment.copy()
            segment_copy['layer3_is_uncertain'] = is_uncertain
            segment_copy['layer3_is_repetitive'] = is_repetitive
            segment_copy['layer3_should_keep'] = not (is_uncertain or is_repetitive)
            
            filtered_segments.append(segment_copy)
            
            if is_uncertain:
                logger.debug(f"æ®µè½ {i+1}: Whisper ä¸ç¢ºå®š (no_speech_prob: {no_speech_prob:.3f})")
            if is_repetitive:
                logger.debug(f"æ®µè½ {i+1}: æª¢æ¸¬åˆ°é‡è¤‡å…§å®¹")
        
        logger.info(f"ç¬¬3å±¤å®Œæˆï¼š{len(filtered_segments)} å€‹æ®µè½")
        return filtered_segments
    
    def _detect_repetitive_content(self, text: str, current_index: int, segments: List[Dict]) -> bool:
        """
        æª¢æ¸¬é‡è¤‡å…§å®¹ï¼ˆå¢å¼·æª¢æ¸¬èƒ½åŠ›ï¼‰
        """
        if len(text.strip()) < 3:
            return False
        
        # æª¢æŸ¥å‰å¾Œæ®µè½æ˜¯å¦æœ‰ç›¸åŒæ–‡æœ¬
        repetition_found = False
        for i, other_segment in enumerate(segments):
            if i == current_index:
                continue
            
            other_text = other_segment.get('text', '').strip()
            if text == other_text and len(text) > 2:
                repetition_found = True
                logger.debug(f"æ®µè½ {current_index+1} å’Œæ®µè½ {i+1} é‡è¤‡å…§å®¹: '{text}'")
                break
        
        return repetition_found
    
    def _layer4_statistical_filter(self, segments: List[Dict]) -> List[Dict]:
        """
        ç¬¬4å±¤ï¼šçµ±è¨ˆç•°å¸¸æª¢æ¸¬
        """
        logger.info("åŸ·è¡Œç¬¬4å±¤ï¼šçµ±è¨ˆç•°å¸¸æª¢æ¸¬")
        
        filtered_segments = []
        for i, segment in enumerate(segments):
            start_time = segment.get('start', 0.0)
            end_time = segment.get('end', start_time + 1.0)
            text = segment.get('text', '').strip()
            
            duration = end_time - start_time
            word_count = len(text.split())
            char_count = len(text)
            
            # çµ±è¨ˆç•°å¸¸æª¢æ¸¬
            is_too_long_with_few_words = (duration > 3.0 and word_count < 3)  # é•·æ™‚é–“å°‘è©
            is_abnormal_density = (duration > 2.0 and char_count < 5)  # ç•°å¸¸å­—å¯†åº¦
            is_too_short = (duration < 0.2)  # éçŸ­
            
            # èªéŸ³å¯†åº¦åˆ†æ
            if duration > 0:
                words_per_second = word_count / duration
                chars_per_second = char_count / duration
            else:
                words_per_second = 0
                chars_per_second = 0
            
            is_low_density = (words_per_second < 0.5 and duration > 2.0)  # ä½å¯†åº¦é•·æ®µ
            
            segment_copy = segment.copy()
            segment_copy['layer4_duration'] = duration
            segment_copy['layer4_words_per_sec'] = words_per_second
            segment_copy['layer4_chars_per_sec'] = chars_per_second
            segment_copy['layer4_is_anomaly'] = (
                is_too_long_with_few_words or 
                is_abnormal_density or 
                is_too_short or 
                is_low_density
            )
            
            filtered_segments.append(segment_copy)
            
            if segment_copy['layer4_is_anomaly']:
                logger.debug(f"æ®µè½ {i+1}: çµ±è¨ˆç•°å¸¸ (æ™‚é•·: {duration:.2f}s, è©æ•¸: {word_count})")
        
        logger.info(f"ç¬¬4å±¤å®Œæˆï¼š{len(filtered_segments)} å€‹æ®µè½")
        return filtered_segments
    
    def _layer5_decision_fusion(self, segments: List[Dict], original_segments: List[Dict]) -> List[Dict]:
        """
        ç¬¬5å±¤ï¼šç¶œåˆæ±ºç­–èåˆï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰
        """
        logger.info("åŸ·è¡Œç¬¬5å±¤ï¼šç¶œåˆæ±ºç­–èåˆ")
        
        if not segments:
            logger.warning("æ²’æœ‰æ®µè½éœ€è¦è™•ç†")
            return []
        
        final_segments = []
        corrections_made = 0
        
        for i, segment in enumerate(segments):
            try:
                # å®‰å…¨ç²å–å„å±¤çš„åˆ¤å®šçµæœ
                layer1_speech = segment.get('layer1_is_speech', True)
                layer2_speech = segment.get('layer2_is_likely_speech', True)
                layer3_keep = segment.get('layer3_should_keep', True)
                layer4_normal = not segment.get('layer4_is_anomaly', False)
                
                # è¨ˆç®—åŠ æ¬Šç¶œåˆè©•åˆ†
                weights = {'layer1': 0.15, 'layer2': 0.35, 'layer3': 0.35, 'layer4': 0.15}
                score = 0.0
                
                if layer1_speech:
                    score += weights['layer1']
                if layer2_speech:
                    score += weights['layer2']  # é »åŸŸåˆ†ææ¬Šé‡æœ€é«˜
                if layer3_keep:
                    score += weights['layer3']   # Whisper è¼¸å‡ºæ¬Šé‡é«˜
                if layer4_normal:
                    score += weights['layer4']
                
                # å‹•æ…‹æ±ºç­–é–¾å€¼
                keep_threshold = 0.4  # æ›´å¯¬é¬†çš„ä¿ç•™é–¾å€¼
                adjust_threshold = 0.7  # èª¿æ•´é–¾å€¼
                
                should_keep = score >= keep_threshold
                should_adjust_timing = score < adjust_threshold
                
                # å‰µå»ºæ®µè½å‰¯æœ¬
                segment_copy = segment.copy()
                
                # æ™‚é–“æˆ³èª¿æ•´é‚è¼¯
                if should_adjust_timing:
                    original_timing = (segment['start'], segment['end'])
                    corrected_timing = self._adjust_segment_timing(segment, i, segments)
                    
                    if corrected_timing != original_timing:
                        segment_copy['start'] = corrected_timing[0] 
                        segment_copy['end'] = corrected_timing[1]
                        segment_copy['_correction_applied'] = True
                        segment_copy['_original_timing'] = original_timing
                        corrections_made += 1
                        
                        logger.info(f"æ®µè½ {i+1}: æ™‚é–“æˆ³ä¿®æ­£ {original_timing[0]:.3f}s -> {corrected_timing[0]:.3f}s")
                
                # ä¿ç•™æ®µè½æ±ºç­–
                if should_keep:
                    # æ·»åŠ è³ªé‡è©•åˆ†ä¿¡æ¯
                    segment_copy['_quality_score'] = score
                    segment_copy['_filter_layers'] = {
                        'layer1_speech': layer1_speech,
                        'layer2_speech': layer2_speech, 
                        'layer3_keep': layer3_keep,
                        'layer4_normal': layer4_normal
                    }
                    final_segments.append(segment_copy)
                else:
                    logger.info(f"æ®µè½ {i+1}: è¢«éæ¿¾å™¨ç§»é™¤ (è©•åˆ†: {score:.2f} < {keep_threshold})")
                    
            except Exception as e:
                logger.error(f"è™•ç†æ®µè½ {i+1} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                # ç™¼ç”ŸéŒ¯èª¤æ™‚ä¿ç•™åŸå§‹æ®µè½
                final_segments.append(segment.copy())
        
        # å¾Œè™•ç†ï¼šç¢ºä¿æ™‚é–“æˆ³é€£çºŒæ€§
        final_segments = self._ensure_temporal_continuity(final_segments)
        
        logger.info(f"ç¬¬5å±¤å®Œæˆï¼š{corrections_made} å€‹æ®µè½è¢«ä¿®æ­£ï¼Œ{len(final_segments)} å€‹æ®µè½ä¿ç•™")
        return final_segments
    
    def _ensure_temporal_continuity(self, segments: List[Dict]) -> List[Dict]:
        """
        ç¢ºä¿æ™‚é–“æˆ³çš„é€£çºŒæ€§å’Œåˆç†æ€§
        """
        if len(segments) <= 1:
            return segments
            
        # æŒ‰é–‹å§‹æ™‚é–“æ’åº
        segments.sort(key=lambda x: x['start'])
        
        # ä¿®æ­£é‡ç–Šå’Œé–“éš”å•é¡Œ
        for i in range(len(segments) - 1):
            current = segments[i]
            next_seg = segments[i + 1]
            
            # ä¿®æ­£é‡ç–Š
            if current['end'] > next_seg['start']:
                # åœ¨ä¸­é»åˆ†å‰²
                split_point = (current['end'] + next_seg['start']) / 2
                current['end'] = split_point - 0.01
                next_seg['start'] = split_point
                
        return segments
    
    def _adjust_segment_timing(self, segment: Dict, index: int, segments: List[Dict]) -> Tuple[float, float]:
        """
        èª¿æ•´æ®µè½æ™‚é–“æˆ³ï¼ˆå¢å¼·æª¢æ¸¬é‚è¼¯ï¼‰
        """
        original_start = segment['start']
        original_end = segment['end']
        text = segment.get('text', '').strip()
        duration = original_end - original_start
        
        # åŸºæ–¼æ–‡æœ¬é•·åº¦çš„æ™‚é–“ä¼°ç®—
        char_count = len(text)
        estimated_duration = max(0.5, char_count * 0.15)  # æ¯å­—ç¬¦ 0.15 ç§’
        
        # å¼·åŒ–é–“å¥æª¢æ¸¬é‚è¼¯
        layer1_rms = segment.get('layer1_rms', 0.1)
        layer2_purity = segment.get('layer2_speech_purity', 1.0)
        layer3_repetitive = segment.get('layer3_is_repetitive', False)
        layer4_anomaly = segment.get('layer4_is_anomaly', False)
        
        # ç‰¹åˆ¥é‡å° DRLIN ç¬¬12æ®µå•é¡Œï¼šé‡è¤‡æ–‡æœ¬ "æ¯äº²èŠ‚å¿«åˆ°äº†" + é•·æ™‚é–“æ®µ
        is_problem_segment = (
            # æ¢ä»¶1ï¼šé‡è¤‡å…§å®¹
            layer3_repetitive or
            # æ¢ä»¶2ï¼šé•·æ™‚é–“ä½†æ–‡æœ¬çŸ­
            (duration > 5.0 and char_count < 10) or
            # æ¢ä»¶3ï¼šå¤šå±¤æª¢æ¸¬éƒ½é¡¯ç¤ºå•é¡Œ
            (layer2_purity < 0.5 and layer4_anomaly) or
            # æ¢ä»¶4ï¼šç‰¹å®šæ–‡æœ¬æ¨¡å¼ï¼ˆé‡å° DRLIN çš„å…·é«”æƒ…æ³ï¼‰
            (text == "æ¯äº²èŠ‚å¿«åˆ°äº†" and duration > 5.0)
        )
        
        if is_problem_segment:
            # è¨ˆç®—èª¿æ•´å¾Œçš„æ™‚é–“æˆ³
            if layer3_repetitive and duration > 5.0:
                # é‡è¤‡å…§å®¹é€šå¸¸æ˜¯é–“å¥ï¼Œèª¿æ•´åˆ°å¾ŒåŠæ®µ
                adjusted_start = original_start + duration * 0.75  # å¾ 75% è™•é–‹å§‹
                adjusted_end = min(adjusted_start + estimated_duration, original_end)
                
                logger.info(f"ğŸ¯ é‡è¤‡å…§å®¹é–“å¥æª¢æ¸¬ï¼šæ®µè½ {index+1} '{text}' èª¿æ•´æ™‚é–“æˆ³")
                logger.info(f"   åŸå§‹: {original_start:.3f}s -> {original_end:.3f}s ({duration:.1f}s)")
                logger.info(f"   èª¿æ•´: {adjusted_start:.3f}s -> {adjusted_end:.3f}s ({adjusted_end-adjusted_start:.1f}s)")
                return (adjusted_start, adjusted_end)
            
            elif duration > 5.0 and char_count < 10:
                # é•·æ™‚é–“çŸ­æ–‡æœ¬ï¼Œå¯èƒ½åŒ…å«é–“å¥
                adjusted_start = original_start + duration * 0.6  # å¾ 60% è™•é–‹å§‹
                adjusted_end = adjusted_start + estimated_duration
                
                logger.info(f"ğŸ¯ é•·æ®µè½ç•°å¸¸æª¢æ¸¬ï¼šæ®µè½ {index+1} èª¿æ•´ {original_start:.3f}s -> {adjusted_start:.3f}s")
                return (adjusted_start, adjusted_end)
        
        # ç„¡éœ€èª¿æ•´
        return (original_start, original_end)


def apply_subeasy_filter(segments: List[Dict], audio_file: str) -> List[Dict]:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå°æ®µè½æ‡‰ç”¨æ™ºèƒ½å¤šå±¤éæ¿¾
    
    Args:
        segments: å­—å¹•æ®µè½åˆ—è¡¨
        audio_file: éŸ³é »æ–‡ä»¶è·¯å¾‘
        
    Returns:
        List[Dict]: éæ¿¾å¾Œçš„æ®µè½
    """
    try:
        filter_system = IntelligentMultiLayerFilter()
        return filter_system.apply_multilayer_filter(segments, audio_file)
    except Exception as e:
        logger.warning(f"æ™ºèƒ½éæ¿¾è™•ç†ç•°å¸¸: {e}")
        return segments