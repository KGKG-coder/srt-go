#!/usr/bin/env python3
"""
SRT Whisper Lite CLI Wrapper
æ¥µè–„å‘½ä»¤è¡ŒåŒ…è£ - é‡ç”¨ç¾æœ‰ electron_backend.py é‚è¼¯
ä¾›è‡ªå‹•åŒ–/CI/è…³æœ¬ä½¿ç”¨
"""

import sys
import argparse
import json
from pathlib import Path

# æ·»åŠ  electron-react-app/python åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent / "electron-react-app" / "python"))

try:
    from official_model_manager import OfficialModelManager
    from simplified_subtitle_core import SimplifiedSubtitleCore
    from electron_backend import process_files_internal
except ImportError as e:
    print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
    print("è«‹ç¢ºèªåœ¨ srt_whisper_lite ç›®éŒ„ä¸­åŸ·è¡Œæ­¤è…³æœ¬")
    sys.exit(1)

def ensure_model():
    """ç¢ºä¿æ¨¡å‹æº–å‚™å°±ç·’"""
    print("ğŸ”„ æª¢æŸ¥æ¨¡å‹ç‹€æ…‹...")
    
    model_manager = OfficialModelManager()
    info = model_manager.get_model_info()
    
    print(f"æ¨¡å‹: {info['name']}")
    print(f"ç‹€æ…‹: {info['status_text']}")
    
    if not info['available']:
        print("ğŸ“¥ é–‹å§‹ä¸‹è¼‰æ¨¡å‹...")
        
        def progress_callback(percent, stage, message):
            print(f"  [{stage}] {percent:.1%} - {message}")
        
        success, result = model_manager.download_model(progress_callback)
        if success:
            print(f"âœ… æ¨¡å‹æº–å‚™å®Œæˆ: {result}")
            return True
        else:
            print(f"âŒ æ¨¡å‹æº–å‚™å¤±æ•—: {result}")
            return False
    else:
        print(f"âœ… æ¨¡å‹å·²å°±ç·’: {info['path']}")
        print(f"   å¤§å°: {info['actual_size']}")
        return True

def transcribe_files(input_files, **kwargs):
    """è½‰éŒ„æ–‡ä»¶"""
    if not ensure_model():
        return False
    
    # æ§‹é€ è¨­ç½®
    settings = {
        'model': 'large',  # å›ºå®šä½¿ç”¨ large
        'language': kwargs.get('language', 'auto'),
        'outputLanguage': kwargs.get('output_language', 'same'),
        'outputFormat': kwargs.get('format', 'srt'),
        'customDir': kwargs.get('output_dir', ''),
        'enableCorrections': True,
        'enable_gpu': kwargs.get('enable_gpu', True)
    }
    
    # æ–‡ä»¶æ¸…å–®
    files = []
    for input_file in input_files:
        file_path = Path(input_file)
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return False
        
        files.append({
            'path': str(file_path.absolute()),
            'name': file_path.name,
            'size': file_path.stat().st_size
        })
    
    # ä½¿ç”¨ç¾æœ‰çš„å¾Œç«¯é‚è¼¯
    try:
        print(f"ğŸ”„ é–‹å§‹è™•ç† {len(files)} å€‹æ–‡ä»¶...")
        
        result = process_files_internal(files, settings, [])
        
        if result.get('success', False):
            print(f"âœ… æˆåŠŸç”Ÿæˆ {result.get('successful', 0)} å€‹å­—å¹•æ–‡ä»¶")
            if 'results' in result:
                for r in result['results']:
                    if r.get('success'):
                        print(f"   {r['input']} â†’ {r['output']}")
            return True
        else:
            print(f"âŒ è™•ç†å¤±æ•—: {result.get('message', 'æœªçŸ¥éŒ¯èª¤')}")
            return False
            
    except Exception as e:
        print(f"âŒ è™•ç†ç•°å¸¸: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(
        description='SRT Whisper Lite CLI - æ¥µè–„å‘½ä»¤è¡ŒåŒ…è£',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python engine_main.py ensure-model
  python engine_main.py transcribe input.mp4
  python engine_main.py transcribe input.mp4 --language zh --format srt
  python engine_main.py transcribe *.mp4 --output-dir ./subtitles
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ensure-model å­å‘½ä»¤
    subparsers.add_parser('ensure-model', help='ç¢ºä¿æ¨¡å‹æº–å‚™å°±ç·’')
    
    # transcribe å­å‘½ä»¤
    transcribe_parser = subparsers.add_parser('transcribe', help='è½‰éŒ„éŸ³è¨Š/è¦–é »æ–‡ä»¶')
    transcribe_parser.add_argument('input', nargs='+', help='è¼¸å…¥æ–‡ä»¶è·¯å¾‘')
    transcribe_parser.add_argument('--language', '-l', 
                                 choices=['auto', 'zh', 'en', 'ja', 'ko'],
                                 default='auto', help='è¼¸å…¥èªè¨€ (é»˜èª: auto)')
    transcribe_parser.add_argument('--output-language', '--output-lang',
                                 choices=['same', 'zh-TW', 'zh-CN'],
                                 default='same', help='è¼¸å‡ºèªè¨€ (é»˜èª: same)')
    transcribe_parser.add_argument('--format', '-f',
                                 choices=['srt', 'vtt', 'txt'],
                                 default='srt', help='è¼¸å‡ºæ ¼å¼ (é»˜èª: srt)')
    transcribe_parser.add_argument('--output-dir', '-o',
                                 default='', help='è¼¸å‡ºç›®éŒ„ (é»˜èª: èˆ‡è¼¸å…¥æ–‡ä»¶åŒç›®éŒ„)')
    transcribe_parser.add_argument('--no-gpu', action='store_true',
                                 help='ç¦ç”¨ GPU åŠ é€Ÿ')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    if args.command == 'ensure-model':
        success = ensure_model()
        sys.exit(0 if success else 1)
    
    elif args.command == 'transcribe':
        success = transcribe_files(
            args.input,
            language=args.language,
            output_language=args.output_language,
            format=args.format,
            output_dir=args.output_dir,
            enable_gpu=not args.no_gpu
        )
        sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()