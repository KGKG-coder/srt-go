#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Medium æ¨¡å‹æ¥µé™å„ªåŒ–æ¸¬è©¦
åŸºæ–¼95.4%åŸºç¤ï¼Œæ¢ç´¢æ¥µç«¯åƒæ•¸çµ„åˆä»¥é”åˆ°98%+åŒ¹é…åº¦
"""

import sys
import json
import logging
import time
from pathlib import Path
import os

# è¨­å®šæ§åˆ¶å°ç·¨ç¢¼
if sys.platform.startswith('win'):
    os.system('chcp 65001 > NUL')
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from faster_whisper import WhisperModel
    logger.info("Faster-Whisper æ¨¡çµ„å°å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"Faster-Whisper å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

# æ¥µé™å„ªåŒ–é…ç½® - ç›®æ¨™çªç ´98%
EXTREME_MEDIUM_CONFIGS = [
    {
        "name": "Medium æ¥µé™åˆ†å‰²",
        "description": "æœ€æ¥µç«¯çš„ç´°åˆ†åƒæ•¸ï¼Œè¿½æ±‚100%åŒ¹é…",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.01,              # æ¥µæ¥µä½é–¾å€¼
            "min_speech_duration_ms": 30,   # 30msæ¥µçŸ­èªéŸ³
            "min_silence_duration_ms": 50,  # 50msæ¥µçŸ­éœéŸ³
            "speech_pad_ms": 25             # 25msæœ€å°å¡«å……
        },
        "whisper_params": {
            "beam_size": 1,                 # æœ€å°beamï¼ˆæœ€æ•æ„Ÿï¼‰
            "word_timestamps": True,
            "condition_on_previous_text": False,
            "compression_ratio_threshold": 1.5,  # æ¥µä½åˆä½µé–¾å€¼
            "log_prob_threshold": -2.0,     # æ¥µå¯¬é¬†æ¦‚ç‡
            "no_speech_threshold": 0.2      # æ¥µæ•æ„ŸèªéŸ³æª¢æ¸¬
        }
    },
    {
        "name": "Medium èªæ°£è©å°ˆå®¶",
        "description": "å°ˆé–€æ•æ‰çŸ­èªæ°£è©å’Œæ„Ÿå˜†è©",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.03,              # æ¥µä½ä½†ç¨å¾®ç©©å®š
            "min_speech_duration_ms": 40,   # 40msçŸ­èªéŸ³
            "min_silence_duration_ms": 80,  # 80msçŸ­éœéŸ³
            "speech_pad_ms": 40             # 40mså¡«å……
        },
        "whisper_params": {
            "beam_size": 2,                 # è¶…å°beam
            "word_timestamps": True,
            "condition_on_previous_text": False,
            "compression_ratio_threshold": 1.6,
            "log_prob_threshold": -1.8,
            "no_speech_threshold": 0.3,
            "repetition_penalty": 1.0,     # é˜²æ­¢é‡è¤‡
            "length_penalty": 0.8           # åå¥½çŸ­å¥
        }
    },
    {
        "name": "Medium è©ç´šç²¾æº–",
        "description": "åŸºæ–¼è©ç´šæ™‚é–“æˆ³çš„ç²¾æº–åˆ†å‰²",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.08,              # ç¨é«˜ç©©å®šæ€§
            "min_speech_duration_ms": 60,   # ç¨é•·ä¿è­‰å“è³ª
            "min_silence_duration_ms": 120, # ç¨é•·ä¿è­‰åˆ†å‰²
            "speech_pad_ms": 30             # å°å¡«å……ç²¾æº–é‚Šç•Œ
        },
        "whisper_params": {
            "beam_size": 3,
            "word_timestamps": True,
            "condition_on_previous_text": False,
            "compression_ratio_threshold": 1.7,
            "log_prob_threshold": -1.6,
            "no_speech_threshold": 0.35,
            "repetition_penalty": 1.1,
            "length_penalty": 0.9,
            "suppress_blank": True          # æŠ‘åˆ¶ç©ºç™½
        }
    },
    {
        "name": "Medium æ··åˆç­–ç•¥",
        "description": "çµåˆè¶…æ•æ„Ÿèˆ‡è©ç´šç²¾æº–çš„æ··åˆç­–ç•¥",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.06,              # æ··åˆé–¾å€¼
            "min_speech_duration_ms": 45,   # æ··åˆæ™‚é•·
            "min_silence_duration_ms": 90,  # æ··åˆéœéŸ³
            "speech_pad_ms": 35             # æ··åˆå¡«å……
        },
        "whisper_params": {
            "beam_size": 2,
            "word_timestamps": True,
            "condition_on_previous_text": False,
            "compression_ratio_threshold": 1.65,
            "log_prob_threshold": -1.7,
            "no_speech_threshold": 0.32,
            "repetition_penalty": 1.05,
            "length_penalty": 0.85
        }
    },
    {
        "name": "Medium æ™‚é–“æˆ³å°ˆå®¶",
        "description": "å°ˆæ³¨æ–¼æ™‚é–“æˆ³ç²¾åº¦çš„æ¥µç«¯å„ªåŒ–",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.04,              # è¶…ä½é–¾å€¼
            "min_speech_duration_ms": 35,   # è¶…çŸ­èªéŸ³
            "min_silence_duration_ms": 70,  # è¶…çŸ­éœéŸ³
            "speech_pad_ms": 20             # æ¥µå°å¡«å……
        },
        "whisper_params": {
            "beam_size": 1,
            "word_timestamps": True,
            "condition_on_previous_text": False,
            "compression_ratio_threshold": 1.4,  # æ¥µä½é–¾å€¼
            "log_prob_threshold": -2.2,     # æ¥µå¯¬é¬†
            "no_speech_threshold": 0.25,    # æ¥µæ•æ„Ÿ
            "temperature": 0.0              # ç¢ºå®šæ€§è¼¸å‡º
        }
    },
    {
        "name": "Medium æ·±åº¦ç´°åˆ†",
        "description": "åŸºæ–¼95.4%é…ç½®çš„æ·±åº¦å„ªåŒ–ç‰ˆæœ¬",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.02,              # æ¯”0.05æ›´æ¥µç«¯
            "min_speech_duration_ms": 25,   # æ¯”50msæ›´çŸ­
            "min_silence_duration_ms": 60,  # æ¯”100msæ›´çŸ­
            "speech_pad_ms": 30             # æ¯”50msæ›´ç²¾æº–
        },
        "whisper_params": {
            "beam_size": 1,                 # æ¯”3æ›´æ•æ„Ÿ
            "word_timestamps": True,
            "condition_on_previous_text": False,
            "compression_ratio_threshold": 1.3,  # æ¯”1.8æ›´ä½
            "log_prob_threshold": -2.5,     # æ¯”-1.5æ›´å¯¬é¬†
            "no_speech_threshold": 0.15     # æ¯”0.4æ›´æ•æ„Ÿ
        }
    }
]

def analyze_segment_similarity_advanced(generated_segments, reference_file, max_segments=34):
    """é«˜ç´šç›¸ä¼¼åº¦åˆ†æï¼Œæ›´ç²¾ç¢ºçš„åŒ¹é…åº¦è¨ˆç®—"""
    
    try:
        with open(reference_file, 'r', encoding='utf-8') as f:
            ref_content = f.read()
        
        import re
        ref_segments = []
        lines = ref_content.strip().split('\n')
        current_seg = {}
        
        for line in lines:
            line = line.strip()
            if re.match(r'^\d+$', line):
                seg_id = int(line)
                if seg_id > max_segments:
                    break
                if current_seg:
                    ref_segments.append(current_seg)
                current_seg = {'id': seg_id}
            elif '-->' in line:
                start_str, end_str = line.split(' --> ')
                def parse_time(time_str):
                    h, m, s = time_str.split(':')
                    s, ms = s.split(',')
                    return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000.0
                current_seg['start'] = parse_time(start_str)
                current_seg['end'] = parse_time(end_str)
            elif line and 'start' in current_seg and 'text' not in current_seg:
                current_seg['text'] = line
        
        if current_seg and current_seg['id'] <= max_segments:
            ref_segments.append(current_seg)
        
        # åˆ†æç›¸ä¼¼åº¦ - æ›´ç²¾ç¢ºçš„ç®—æ³•
        ref_total_time = ref_segments[-1]['end'] if ref_segments else 0
        gen_relevant_segments = [seg for seg in generated_segments if seg['start'] <= ref_total_time]
        
        # 1. æ®µè½æ•¸åŒ¹é…åº¦ (40%)
        segment_ratio = len(gen_relevant_segments) / len(ref_segments) if ref_segments else 0
        segment_score = 100 - min(100, abs(1 - segment_ratio) * 100)
        
        # 2. æ™‚é•·åˆ†å¸ƒåŒ¹é…åº¦ (30%)
        ref_durations = [seg['end'] - seg['start'] for seg in ref_segments]
        gen_durations = [seg['duration'] for seg in gen_relevant_segments]
        
        ref_avg_dur = sum(ref_durations) / len(ref_durations) if ref_durations else 0
        gen_avg_dur = sum(gen_durations) / len(gen_durations) if gen_durations else 0
        duration_diff = abs(ref_avg_dur - gen_avg_dur)
        duration_score = max(0, 100 - (duration_diff * 100))
        
        # 3. çŸ­æ®µè½æ•æ‰åŒ¹é…åº¦ (20%)
        ref_short = sum(1 for d in ref_durations if d < 1.0)
        gen_short = sum(1 for d in gen_durations if d < 1.0)
        short_ratio = gen_short / ref_short if ref_short > 0 else 1.0
        short_score = 100 - min(100, abs(1 - short_ratio) * 50)
        
        # 4. èªæ°£è©å°ˆæ¥­åŒ¹é…åº¦ (10%)
        particles = ['å¥½', 'æ©', 'å—¯', 'å“‡', 'å•Š', 'å–”', 'å˜¿', 'æ¬¸']
        ref_particles = sum(1 for seg in ref_segments if len(seg['text'].strip()) <= 3 and 
                           any(p in seg['text'] for p in particles))
        gen_particles = sum(1 for seg in gen_relevant_segments if len(seg['text'].strip()) <= 3 and 
                           any(p in seg['text'] for p in particles))
        
        particle_ratio = gen_particles / ref_particles if ref_particles > 0 else 1.0
        particle_score = 100 - min(100, abs(1 - particle_ratio) * 30)
        
        # 5. æ™‚é–“æˆ³ç²¾åº¦ (æ¬Šé‡è¨ˆç®—)
        # æª¢æŸ¥å‰10æ®µçš„æ™‚é–“æˆ³ç²¾åº¦
        timestamp_accuracy = 100
        for i in range(min(10, len(ref_segments), len(gen_relevant_segments))):
            ref_start_diff = abs(ref_segments[i]['start'] - gen_relevant_segments[i]['start'])
            if ref_start_diff > 0.5:  # è¶…é500mså·®ç•°
                timestamp_accuracy -= 5
        
        # ç¶œåˆè©•åˆ†
        overall_score = (
            segment_score * 0.40 + 
            duration_score * 0.30 + 
            short_score * 0.20 + 
            particle_score * 0.10
        )
        
        # æ™‚é–“æˆ³ç²¾åº¦åŠ æˆ/æ‰£åˆ†
        final_score = overall_score * (timestamp_accuracy / 100)
        
        detailed_metrics = {
            'reference_segments': len(ref_segments),
            'generated_segments': len(gen_relevant_segments),
            'segment_ratio': round(segment_ratio, 3),
            'segment_score': round(segment_score, 1),
            'duration_score': round(duration_score, 1),
            'short_score': round(short_score, 1),
            'particle_score': round(particle_score, 1),
            'timestamp_accuracy': round(timestamp_accuracy, 1),
            'match_score': round(final_score, 1),
            'avg_ref_duration': round(ref_avg_dur, 3),
            'avg_gen_duration': round(gen_avg_dur, 3),
            'ref_particles': ref_particles,
            'gen_particles': gen_particles,
            'time_coverage': round(ref_total_time, 3)
        }
        
        return detailed_metrics
        
    except Exception as e:
        logger.error(f"é«˜ç´šåƒè€ƒæª”æ¡ˆåˆ†æå¤±æ•—: {e}")
        return {}

def test_extreme_config(audio_file, output_file, config):
    """æ¸¬è©¦æ¥µç«¯é…ç½®"""
    try:
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸš€ æ¸¬è©¦ {config['name']}")
        logger.info(f"ğŸ“ {config['description']}")
        logger.info(f"ğŸµ éŸ³é »æª”æ¡ˆ: {Path(audio_file).name}")
        logger.info(f"{'='*80}")
        
        start_time = time.time()
        
        # è¼‰å…¥æ¨¡å‹
        logger.info(f"â³ è¼‰å…¥ {config['model']} æ¨¡å‹...")
        model_load_start = time.time()
        model = WhisperModel(
            config['model'], 
            device="cpu", 
            compute_type="int8"
        )
        model_load_time = time.time() - model_load_start
        logger.info(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ ({model_load_time:.2f}ç§’)")
        
        # åŸ·è¡Œè½‰éŒ„
        logger.info("ğŸ¤ é–‹å§‹è½‰éŒ„...")
        transcribe_start = time.time()
        
        segments, info = model.transcribe(
            audio_file,
            language=None,
            vad_filter=True,
            vad_parameters=config['vad_parameters'],
            **config['whisper_params']
        )
        
        # è™•ç†çµæœ
        segment_list = []
        for segment in segments:
            segment_data = {
                'id': len(segment_list) + 1,
                'start': segment.start,
                'end': segment.end,
                'text': segment.text.strip(),
                'duration': segment.end - segment.start
            }
            
            if hasattr(segment, 'words') and segment.words:
                segment_data['word_count'] = len(segment.words)
                segment_data['words'] = [
                    {
                        'word': w.word,
                        'start': w.start,
                        'end': w.end,
                        'probability': w.probability
                    } for w in segment.words
                ]
            
            segment_list.append(segment_data)
        
        transcribe_time = time.time() - transcribe_start
        total_time = time.time() - start_time
        
        # ç”ŸæˆSRT
        srt_content = generate_srt_from_segments(segment_list)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        # é«˜ç´šç›¸ä¼¼åº¦åˆ†æ
        similarity = analyze_segment_similarity_advanced(segment_list, "C:/Users/USER-ART0/Desktop/test1.srt")
        
        # åŸºæœ¬çµ±è¨ˆ
        if segment_list:
            total_speech_time = sum(seg['duration'] for seg in segment_list)
            avg_segment_duration = total_speech_time / len(segment_list)
            segments_per_second = len(segment_list) / info.duration
        else:
            total_speech_time = avg_segment_duration = segments_per_second = 0
        
        result = {
            'success': True,
            'config_name': config['name'],
            'model': config['model'],
            'vad_config': config['vad_parameters'],
            'whisper_config': config['whisper_params'],
            
            'audio_duration': round(info.duration, 2),
            'segment_count': len(segment_list),
            'segments_per_second': round(segments_per_second, 3),
            'avg_segment_duration': round(avg_segment_duration, 3),
            
            'similarity_analysis': similarity,
            
            'language': info.language,
            'language_probability': round(info.language_probability, 4),
            
            'model_load_time': round(model_load_time, 2),
            'transcribe_time': round(transcribe_time, 2),
            'real_time_factor': round(transcribe_time / info.duration, 2),
            
            'output_file': str(output_file)
        }
        
        # çµæœæ‘˜è¦
        logger.info(f"\nğŸ“Š æ¥µç«¯é…ç½®æ¸¬è©¦çµæœ:")
        logger.info(f"  ğŸ¯ æ®µè½æ•¸: {len(segment_list)}æ®µ")
        logger.info(f"  âš¡ æ®µè½å¯†åº¦: {segments_per_second:.3f}æ®µ/ç§’")
        logger.info(f"  â±ï¸ å¹³å‡æ™‚é•·: {avg_segment_duration:.3f}ç§’")
        logger.info(f"  ğŸš€ è™•ç†é€Ÿåº¦: {result['real_time_factor']:.2f}xå¯¦æ™‚")
        logger.info(f"  ğŸ—£ï¸ èªè¨€: {info.language} (ä¿¡å¿ƒåº¦: {info.language_probability:.3f})")
        
        if similarity:
            logger.info(f"  ğŸ“ˆ åŒ¹é…åº¦: {similarity.get('match_score', 0):.1f}%")
            logger.info(f"    - æ®µè½åŒ¹é…: {similarity.get('segment_score', 0):.1f}%")
            logger.info(f"    - æ™‚é•·åŒ¹é…: {similarity.get('duration_score', 0):.1f}%")
            logger.info(f"    - çŸ­æ®µæ•æ‰: {similarity.get('short_score', 0):.1f}%")
            logger.info(f"    - èªæ°£è©åŒ¹é…: {similarity.get('particle_score', 0):.1f}%")
            logger.info(f"    - æ™‚é–“æˆ³ç²¾åº¦: {similarity.get('timestamp_accuracy', 0):.1f}%")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ¥µç«¯é…ç½®æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'config_name': config['name'],
            'error': str(e)
        }

def generate_srt_from_segments(segments):
    """å¾æ®µè½ç”ŸæˆSRTæ ¼å¼"""
    def format_timestamp(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    srt_content = ""
    for segment in segments:
        segment_id = segment.get('id', len(srt_content.split('\n\n')) + 1)
        start_time = format_timestamp(segment['start'])
        end_time = format_timestamp(segment['end'])
        text = segment['text']
        
        srt_content += f"{segment_id}\n{start_time} --> {end_time}\n{text}\n\n"
    
    return srt_content

def main():
    """ä¸»å‡½æ•¸"""
    
    test_file = "C:/Users/USER-ART0/Desktop/C0485.MP4"
    output_dir = Path("C:/Users/USER-ART0/Desktop/medium_extreme_tests")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if not Path(test_file).exists():
        logger.error(f"âŒ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨: {test_file}")
        return None
    
    logger.info(f"ğŸš€ Medium æ¥µé™å„ªåŒ–æ¸¬è©¦")
    logger.info(f"ğŸ“ æ¸¬è©¦æª”æ¡ˆ: {Path(test_file).name}")
    logger.info(f"ğŸ’¾ è¼¸å‡ºç›®éŒ„: {output_dir}")
    logger.info(f"ğŸ¯ ç›®æ¨™: çªç ´95.4%ï¼Œé”åˆ°98%+åŒ¹é…åº¦")
    logger.info(f"ğŸ“‹ æ¥µé™é…ç½®æ•¸é‡: {len(EXTREME_MEDIUM_CONFIGS)}")
    
    all_results = []
    
    for i, config in enumerate(EXTREME_MEDIUM_CONFIGS):
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ“ æ¥µé™æ¸¬è©¦ {i+1}/{len(EXTREME_MEDIUM_CONFIGS)}")
        
        config_name_safe = config['name'].replace(' ', '_').replace('ï¼š', '_')
        output_file = output_dir / f"C0485_{config_name_safe}.srt"
        
        result = test_extreme_config(test_file, output_file, config)
        result['test_file'] = str(test_file)
        result['config_index'] = i + 1
        
        all_results.append(result)
        
        # å¦‚æœé”åˆ°98%ä»¥ä¸Šï¼Œç‰¹åˆ¥æ¨™è¨»
        if result.get('success') and result.get('similarity_analysis', {}).get('match_score', 0) >= 98:
            logger.info(f"ğŸ† ç™¼ç¾çªç ´æ€§é…ç½®ï¼åŒ¹é…åº¦: {result['similarity_analysis']['match_score']:.1f}%")
        
        time.sleep(1)
    
    # æœ€çµ‚åˆ†æ
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ† Medium æ¥µé™å„ªåŒ–æ¸¬è©¦çµæœåˆ†æ")
    logger.info(f"{'='*80}")
    
    successful_results = [r for r in all_results if r.get('success', False)]
    
    if successful_results:
        # æŒ‰åŒ¹é…åº¦æ’åº
        successful_results.sort(key=lambda x: x.get('similarity_analysis', {}).get('match_score', 0), reverse=True)
        
        logger.info(f"\nğŸ¥‡ æ¥µé™é…ç½®æ’è¡Œæ¦œ:")
        for i, result in enumerate(successful_results):
            match_score = result.get('similarity_analysis', {}).get('match_score', 0)
            symbol = "ğŸ”¥" if match_score >= 98 else "â­" if match_score >= 96 else "âœ“"
            logger.info(f"  {symbol} {i+1}. {result['config_name']}: {match_score:.1f}%")
            logger.info(f"      æ®µè½æ•¸: {result['segment_count']}, è™•ç†é€Ÿåº¦: {result['real_time_factor']:.2f}x")
        
        # å† è»é…ç½®è©³ç´°åˆ†æ
        champion = successful_results[0]
        logger.info(f"\nğŸ† å† è»é…ç½®åˆ†æ: {champion['config_name']}")
        sim = champion.get('similarity_analysis', {})
        if sim:
            logger.info(f"  ğŸ“Š è©³ç´°å¾—åˆ†:")
            logger.info(f"    - ç¸½åŒ¹é…åº¦: {sim.get('match_score', 0):.1f}%")
            logger.info(f"    - æ®µè½åŒ¹é…: {sim.get('segment_score', 0):.1f}% (æ¬Šé‡40%)")
            logger.info(f"    - æ™‚é•·åŒ¹é…: {sim.get('duration_score', 0):.1f}% (æ¬Šé‡30%)")
            logger.info(f"    - çŸ­æ®µæ•æ‰: {sim.get('short_score', 0):.1f}% (æ¬Šé‡20%)")
            logger.info(f"    - èªæ°£è©åŒ¹é…: {sim.get('particle_score', 0):.1f}% (æ¬Šé‡10%)")
            logger.info(f"    - æ™‚é–“æˆ³ç²¾åº¦: {sim.get('timestamp_accuracy', 0):.1f}%")
            
            logger.info(f"  ğŸ“ˆ æ•¸æ“šå°æ¯”:")
            logger.info(f"    - åƒè€ƒæ®µè½: {sim.get('reference_segments', 0)} vs ç”Ÿæˆ: {sim.get('generated_segments', 0)}")
            logger.info(f"    - æ®µè½æ¯”ä¾‹: {sim.get('segment_ratio', 0):.3f}")
            logger.info(f"    - å¹³å‡æ™‚é•·: åƒè€ƒ{sim.get('avg_ref_duration', 0):.3f}s vs ç”Ÿæˆ{sim.get('avg_gen_duration', 0):.3f}s")
    
    # ä¿å­˜æ¥µé™æ¸¬è©¦å ±å‘Š
    report = {
        'test_metadata': {
            'test_type': 'extreme_optimization',
            'test_file': test_file,
            'baseline_score': 95.4,
            'target_score': 98.0,
            'total_configs': len(EXTREME_MEDIUM_CONFIGS),
            'successful_configs': len(successful_results),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        },
        'test_results': all_results,
        'champion_config': successful_results[0] if successful_results else None,
        'breakthrough_configs': [r for r in successful_results 
                               if r.get('similarity_analysis', {}).get('match_score', 0) >= 98]
    }
    
    report_file = output_dir / 'medium_extreme_optimization_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\nâœ… Medium æ¥µé™å„ªåŒ–æ¸¬è©¦å®Œæˆï¼")
    logger.info(f"ğŸ“‹ è©³ç´°å ±å‘Š: {report_file}")
    
    # æœ€çµ‚çµè«–
    if successful_results:
        best_score = successful_results[0].get('similarity_analysis', {}).get('match_score', 0)
        if best_score >= 98:
            logger.info(f"ğŸ‰ çªç ´æˆåŠŸï¼æœ€ä½³åŒ¹é…åº¦: {best_score:.1f}%")
        elif best_score > 95.4:
            logger.info(f"ğŸ“ˆ å„ªåŒ–æˆåŠŸï¼æå‡è‡³: {best_score:.1f}% (åŸºç·š: 95.4%)")
        else:
            logger.info(f"ğŸ“Š æ¸¬è©¦å®Œæˆï¼Œæœ€ä½³: {best_score:.1f}% (ä»éœ€å„ªåŒ–)")
    
    return report

if __name__ == "__main__":
    try:
        report = main()
        if report and report['test_metadata']['successful_configs'] > 0:
            best = report['champion_config']
            best_score = best.get('similarity_analysis', {}).get('match_score', 0) if best else 0
            breakthrough_count = len(report.get('breakthrough_configs', []))
            
            print(f"\nğŸ¯ Medium æ¥µé™å„ªåŒ–æ¸¬è©¦å®Œæˆï¼")
            print(f"æˆåŠŸé…ç½®: {report['test_metadata']['successful_configs']}/{report['test_metadata']['total_configs']}")
            print(f"æœ€ä½³åŒ¹é…åº¦: {best_score:.1f}%")
            if breakthrough_count > 0:
                print(f"ğŸ”¥ çªç ´æ€§é…ç½®: {breakthrough_count}å€‹ (â‰¥98%)")
        else:
            print(f"\nğŸ’¥ æ¥µé™æ¸¬è©¦å¤±æ•—ï¼")
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºå¤±æ•—: {e}")
        sys.exit(1)