/**
 * å‰µå»ºé ç½®æ¨¡å‹æ‰“åŒ…ç³»çµ±
 * è§£æ±ºæ¨¡å‹ä¸‹è¼‰å•é¡Œï¼Œæ”¯æ´é›¢ç·šä½¿ç”¨
 */

const fs = require('fs');
const path = require('path');

console.log('ğŸ¯ è¨­è¨ˆé ç½®æ¨¡å‹æ‰“åŒ…ç³»çµ±...\n');

// 1. å‰µå»ºæ¨¡å‹ç®¡ç†å™¨
const modelManagerCode = `#!/usr/bin/env python3
"""
æ¨¡å‹ç®¡ç†å™¨ - è™•ç†é ç½®æ¨¡å‹çš„å®‰è£å’Œç®¡ç†
"""

import os
import sys
import json
import shutil
import zipfile
import logging
from pathlib import Path
import urllib.request

logger = logging.getLogger(__name__)

class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        # æ¨¡å‹å­˜æ”¾ç›®éŒ„
        self.models_dir = Path(__file__).parent / "models"
        self.cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
        
        # æ”¯æ´çš„æ¨¡å‹è³‡è¨Š
        self.model_info = {
            "tiny": {
                "size_mb": 39,
                "description": "æœ€å°æ¨¡å‹ï¼Œå¿«é€Ÿä½†ç²¾åº¦è¼ƒä½",
                "package_name": "whisper-tiny-model.zip"
            },
            "base": {
                "size_mb": 74, 
                "description": "åŸºç¤æ¨¡å‹ï¼Œé€Ÿåº¦èˆ‡ç²¾åº¦å¹³è¡¡",
                "package_name": "whisper-base-model.zip"
            },
            "medium": {
                "size_mb": 244,
                "description": "ä¸­ç­‰æ¨¡å‹ï¼Œæ¨è–¦æ—¥å¸¸ä½¿ç”¨",
                "package_name": "whisper-medium-model.zip"
            },
            "large": {
                "size_mb": 769,
                "description": "å¤§å‹æ¨¡å‹ï¼Œæœ€é«˜ç²¾åº¦",
                "package_name": "whisper-large-model.zip"
            }
        }
        
    def check_local_model(self, model_name):
        """æª¢æŸ¥æœ¬åœ°æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
        # æª¢æŸ¥æ‡‰ç”¨ç¨‹å¼å…§å»ºæ¨¡å‹
        bundled_model = self.models_dir / f"{model_name}"
        if bundled_model.exists():
            return True, "bundled", str(bundled_model)
            
        # æª¢æŸ¥ HuggingFace ç·©å­˜
        if self.cache_dir.exists():
            for item in self.cache_dir.iterdir():
                if f"whisper-{model_name}" in item.name.lower():
                    return True, "cached", str(item)
                    
        return False, "not_found", None
        
    def install_bundled_model(self, model_name, progress_callback=None):
        """å®‰è£å…§å»ºçš„é ç½®æ¨¡å‹"""
        try:
            if progress_callback:
                progress_callback(0, f"æº–å‚™å®‰è£ {model_name} æ¨¡å‹...")
                
            # æª¢æŸ¥é ç½®æ¨¡å‹åŒ…
            model_package = self.models_dir / self.model_info[model_name]["package_name"]
            if not model_package.exists():
                logger.warning(f"é ç½®æ¨¡å‹åŒ…ä¸å­˜åœ¨: {model_package}")
                return False, "package_not_found"
                
            # å‰µå»ºç›®æ¨™ç›®éŒ„
            self.cache_dir.mkdir(parents=True, exist_ok=True)
            target_dir = self.cache_dir / f"models--openai--whisper-{model_name}"
            
            if progress_callback:
                progress_callback(20, "æ­£åœ¨è§£å£“æ¨¡å‹æ–‡ä»¶...")
                
            # è§£å£“æ¨¡å‹åŒ…
            with zipfile.ZipFile(model_package, 'r') as zip_ref:
                zip_ref.extractall(target_dir)
                
            if progress_callback:
                progress_callback(80, "æ­£åœ¨é©—è­‰æ¨¡å‹å®Œæ•´æ€§...")
                
            # é©—è­‰æ¨¡å‹æ–‡ä»¶
            required_files = ["config.json", "model.bin", "tokenizer.json"]
            for file_name in required_files:
                if not (target_dir / file_name).exists():
                    logger.error(f"æ¨¡å‹æ–‡ä»¶ç¼ºå¤±: {file_name}")
                    return False, "incomplete_model"
                    
            if progress_callback:
                progress_callback(100, f"{model_name} æ¨¡å‹å®‰è£å®Œæˆ")
                
            logger.info(f"é ç½®æ¨¡å‹å®‰è£æˆåŠŸ: {model_name}")
            return True, str(target_dir)
            
        except Exception as e:
            logger.error(f"é ç½®æ¨¡å‹å®‰è£å¤±æ•—: {e}")
            return False, str(e)
            
    def download_model_if_needed(self, model_name, force_download=False, progress_callback=None):
        """æ™ºèƒ½æ¨¡å‹ç²å–ï¼šå„ªå…ˆä½¿ç”¨é ç½®ï¼Œå…¶æ¬¡ä¸‹è¼‰"""
        try:
            # æª¢æŸ¥æœ¬åœ°æ¨¡å‹
            exists, source, path = self.check_local_model(model_name)
            
            if exists and not force_download:
                logger.info(f"ç™¼ç¾æœ¬åœ°æ¨¡å‹: {model_name} ({source})")
                if progress_callback:
                    progress_callback(100, f"ä½¿ç”¨æœ¬åœ° {model_name} æ¨¡å‹")
                return True, path, source
                
            # å¦‚æœæœ‰é ç½®æ¨¡å‹åŒ…ï¼Œå„ªå…ˆå®‰è£
            model_package = self.models_dir / self.model_info[model_name]["package_name"]
            if model_package.exists():
                logger.info(f"ç™¼ç¾é ç½®æ¨¡å‹åŒ…ï¼Œé–‹å§‹å®‰è£: {model_name}")
                if progress_callback:
                    progress_callback(10, "ç™¼ç¾é ç½®æ¨¡å‹åŒ…ï¼Œé–‹å§‹å®‰è£...")
                    
                success, result = self.install_bundled_model(model_name, progress_callback)
                if success:
                    return True, result, "bundled_installed"
                else:
                    logger.warning(f"é ç½®æ¨¡å‹å®‰è£å¤±æ•—ï¼Œå˜—è©¦ç¶²è·¯ä¸‹è¼‰: {result}")
                    
            # å˜—è©¦ç¶²è·¯ä¸‹è¼‰
            if self._check_internet_connection():
                if progress_callback:
                    progress_callback(5, "æ­£åœ¨å¾ç¶²è·¯ä¸‹è¼‰æ¨¡å‹...")
                    
                return self._download_from_huggingface(model_name, progress_callback)
            else:
                logger.error("ç„¡ç¶²è·¯é€£æ¥ä¸”ç„¡å¯ç”¨çš„é ç½®æ¨¡å‹")
                return False, "no_network_no_bundled", "network_error"
                
        except Exception as e:
            logger.error(f"æ¨¡å‹ç²å–å¤±æ•—: {e}")
            return False, str(e), "error"
            
    def _check_internet_connection(self):
        """æª¢æŸ¥ç¶²è·¯é€£æ¥"""
        try:
            urllib.request.urlopen('https://huggingface.co', timeout=10)
            return True
        except:
            return False
            
    def _download_from_huggingface(self, model_name, progress_callback=None):
        """å¾ HuggingFace ä¸‹è¼‰æ¨¡å‹"""
        try:
            # é€™è£¡æœƒè§¸ç™¼ faster-whisper çš„è‡ªå‹•ä¸‹è¼‰æ©Ÿåˆ¶
            # å¯¦éš›ä¸‹è¼‰ç”± faster-whisper è™•ç†
            if progress_callback:
                progress_callback(50, f"æ­£åœ¨ä¸‹è¼‰ {model_name} æ¨¡å‹...")
                
            # è¿”å›çµ¦ faster-whisper è™•ç†
            return True, "download_in_progress", "huggingface"
            
        except Exception as e:
            return False, str(e), "download_error"
            
    def get_model_status(self):
        """ç²å–æ‰€æœ‰æ¨¡å‹çš„ç‹€æ…‹"""
        status = {}
        
        for model_name in self.model_info.keys():
            exists, source, path = self.check_local_model(model_name)
            package_exists = (self.models_dir / self.model_info[model_name]["package_name"]).exists()
            
            status[model_name] = {
                "available_locally": exists,
                "source": source if exists else "not_available", 
                "path": path,
                "bundled_package_available": package_exists,
                "size_mb": self.model_info[model_name]["size_mb"],
                "description": self.model_info[model_name]["description"]
            }
            
        return status
        
    def create_model_package(self, model_name, output_dir=None):
        """å‰µå»ºæ¨¡å‹å®‰è£åŒ…ï¼ˆé–‹ç™¼ç”¨ï¼‰"""
        try:
            if not output_dir:
                output_dir = self.models_dir
                
            # æŸ¥æ‰¾æ¨¡å‹åœ¨ HuggingFace ç·©å­˜ä¸­çš„ä½ç½®
            exists, source, model_path = self.check_local_model(model_name)
            
            if not exists or source != "cached":
                logger.error(f"æ¨¡å‹ {model_name} ä¸åœ¨ HuggingFace ç·©å­˜ä¸­")
                return False
                
            # å‰µå»ºå£“ç¸®åŒ…
            package_name = self.model_info[model_name]["package_name"]
            package_path = Path(output_dir) / package_name
            
            logger.info(f"å‰µå»ºæ¨¡å‹åŒ…: {package_path}")
            
            with zipfile.ZipFile(package_path, 'w', zipfile.ZIP_DEFLATED) as zip_ref:
                model_dir = Path(model_path)
                for file_path in model_dir.rglob('*'):
                    if file_path.is_file():
                        arcname = file_path.relative_to(model_dir)
                        zip_ref.write(file_path, arcname)
                        
            logger.info(f"æ¨¡å‹åŒ…å‰µå»ºå®Œæˆ: {package_path}")
            return True
            
        except Exception as e:
            logger.error(f"å‰µå»ºæ¨¡å‹åŒ…å¤±æ•—: {e}")
            return False


def test_model_manager():
    """æ¸¬è©¦æ¨¡å‹ç®¡ç†å™¨"""
    manager = ModelManager()
    
    print("=== æ¨¡å‹ç‹€æ…‹æª¢æŸ¥ ===")
    status = manager.get_model_status()
    for model, info in status.items():
        print(f"{model}: æœ¬åœ°={info['available_locally']}, é ç½®åŒ…={info['bundled_package_available']}")
        
    print("\\n=== æ¸¬è©¦æ¨¡å‹ç²å– ===")
    def progress_callback(percent, message):
        print(f"[{percent:3d}%] {message}")
        
    success, path, source = manager.download_model_if_needed("base", progress_callback=progress_callback)
    print(f"çµæœ: success={success}, path={path}, source={source}")


if __name__ == "__main__":
    test_model_manager()
`;

fs.writeFileSync(
    path.join(__dirname, '..', 'model_manager.py'),
    modelManagerCode,
    'utf8'
);

// 2. ä¿®æ”¹ simplified_subtitle_core.py ä»¥ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨
const coreModification = `
# åœ¨ simplified_subtitle_core.py ä¸­æ·»åŠ æ¨¡å‹ç®¡ç†å™¨é›†æˆ

def initialize(self, progress_callback: Optional[Callable] = None) -> bool:
    """åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨ï¼‰"""
    try:
        if progress_callback:
            if progress_callback(2, "æ­£åœ¨æª¢æŸ¥æ¨¡å‹...") == False:
                return False
        
        # ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨
        from model_manager import ModelManager
        model_manager = ModelManager()
        
        # æ™ºèƒ½ç²å–æ¨¡å‹
        success, model_path, source = model_manager.download_model_if_needed(
            self.model_size, 
            progress_callback=progress_callback
        )
        
        if not success:
            logger.error(f"æ¨¡å‹ç²å–å¤±æ•—: {model_path}")
            if progress_callback:
                progress_callback(0, f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {model_path}")
            return False
            
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {self.model_size} (ä¾†æº: {source})")
        
        if progress_callback:
            if progress_callback(15, f"æº–å‚™è¼‰å…¥ {source} æ¨¡å‹...") == False:
                return False
        
        from faster_whisper import WhisperModel
        
        # æ ¹æ“šä¾†æºæ±ºå®šè¼‰å…¥æ–¹å¼
        if source == "bundled_installed":
            # ä½¿ç”¨å®‰è£çš„é ç½®æ¨¡å‹
            self.model = WhisperModel(
                model_path,  # ç›´æ¥ä½¿ç”¨è·¯å¾‘
                device=self.device,
                compute_type=self.compute_type,
                local_files_only=True,  # å¼·åˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                num_workers=2
            )
        else:
            # æ¨™æº–è¼‰å…¥æ–¹å¼
            self.model = WhisperModel(
                self.model_size,
                device=self.device,
                compute_type=self.compute_type,
                download_root=None,
                local_files_only=(source == "cached"),
                num_workers=self.config.get("model.num_workers", 4) if self.config and self.device == "cuda" else 2
            )
            
        if progress_callback:
            progress_callback(30, "AI æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        self.initialized = True
        logger.info("ç°¡åŒ–ç‰ˆå­—å¹•ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±æ•—: {e}")
        if progress_callback:
            progress_callback(0, f"åˆå§‹åŒ–å¤±æ•—: {e}")
        return False
`;

// 3. å‰µå»ºå®‰è£åŒ…æ§‹å»ºè…³æœ¬
const packageBuilderScript = `@echo off
echo ğŸš€ æ§‹å»ºåŒ…å«é ç½®æ¨¡å‹çš„å®‰è£åŒ…...
echo.

echo ğŸ“‹ ç¬¬ä¸€æ­¥ï¼šæº–å‚™æ¨¡å‹æ–‡ä»¶
echo   - ç¢ºä¿å·²åœ¨æœ‰ç¶²è·¯çš„ç’°å¢ƒä¸‹è¼‰éæ‰€éœ€æ¨¡å‹
echo   - æ¨¡å‹æœƒè‡ªå‹•å¾ HuggingFace ç·©å­˜ä¸­æå–

echo.
echo ğŸ“¦ ç¬¬äºŒæ­¥ï¼šå‰µå»ºæ¨¡å‹å®‰è£åŒ…
python -c "
from model_manager import ModelManager
import os

manager = ModelManager()
models_to_package = ['tiny', 'base', 'medium']  # ä¸åŒ…å« large (å¤ªå¤§)

# å‰µå»ºæ¨¡å‹ç›®éŒ„
os.makedirs('models', exist_ok=True)

print('æ­£åœ¨æª¢æŸ¥å’Œæ‰“åŒ…æ¨¡å‹...')
for model in models_to_package:
    print(f'è™•ç†æ¨¡å‹: {model}')
    success = manager.create_model_package(model, 'models')
    if success:
        print(f'  âœ… {model} æ¨¡å‹æ‰“åŒ…å®Œæˆ')
    else:
        print(f'  âŒ {model} æ¨¡å‹æ‰“åŒ…å¤±æ•—ï¼ˆå¯èƒ½å°šæœªä¸‹è¼‰ï¼‰')

print('\\næ¨¡å‹æ‰“åŒ…å®Œæˆï¼')
print('åŒ…å«é ç½®æ¨¡å‹çš„å®‰è£åŒ…æ§‹å»ºæº–å‚™å°±ç·’ã€‚')
"

echo.
echo ğŸ“‹ ç¬¬ä¸‰æ­¥ï¼šæ›´æ–° Electron Builder é…ç½®
echo   - å°‡ models/ ç›®éŒ„æ·»åŠ åˆ° extraFiles
echo   - ç¢ºä¿æ¨¡å‹æ–‡ä»¶åŒ…å«åœ¨å®‰è£åŒ…ä¸­

echo.
echo âœ… æº–å‚™å·¥ä½œå®Œæˆï¼
echo ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šé‹è¡Œ 'npm run build' ä¾†å‰µå»ºåŒ…å«é ç½®æ¨¡å‹çš„å®‰è£åŒ…

pause
`;

fs.writeFileSync(
    path.join(__dirname, 'build_with_models.bat'),
    packageBuilderScript
);

// 4. æ›´æ–° package.json é…ç½®
const packageJsonPath = path.join(__dirname, 'package.json');
let packageJson = JSON.parse(fs.readFileSync(packageJsonPath, 'utf8'));

// æ·»åŠ æ¨¡å‹ç›®éŒ„åˆ° extraFiles
const modelExtraFiles = {
    "from": "../models",
    "to": "resources/models",
    "filter": ["**/*"]
};

// æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡æ·»åŠ 
if (!packageJson.build.extraFiles.some(file => file.to === "resources/models")) {
    packageJson.build.extraFiles.push(modelExtraFiles);
}

// æ›´æ–°è…³æœ¬
packageJson.scripts["build:with-models"] = "node create_model_package_system.js && npm run build";
packageJson.scripts["prepare-models"] = "python ../model_manager.py";

fs.writeFileSync(packageJsonPath, JSON.stringify(packageJson, null, 2));

// 5. å‰µå»ºé¦–æ¬¡é‹è¡Œåš®å°
const firstRunGuide = `#!/usr/bin/env python3
"""
é¦–æ¬¡é‹è¡Œåš®å° - å¼•å°ç”¨æˆ¶é¸æ“‡å’Œå®‰è£æ¨¡å‹
"""

import sys
import json
import logging
from pathlib import Path
from model_manager import ModelManager

logger = logging.getLogger(__name__)

class FirstRunGuide:
    """é¦–æ¬¡é‹è¡Œåš®å°"""
    
    def __init__(self):
        self.model_manager = ModelManager()
        
    def show_model_selection_dialog(self):
        """é¡¯ç¤ºæ¨¡å‹é¸æ“‡å°è©±æ¡†ï¼ˆç”±å‰ç«¯èª¿ç”¨ï¼‰"""
        status = self.model_manager.get_model_status()
        
        # æº–å‚™é¸é …è³‡æ–™
        options = []
        for model_name, info in status.items():
            option = {
                "name": model_name,
                "size_mb": info["size_mb"],
                "description": info["description"],
                "available_locally": info["available_locally"],
                "bundled_available": info["bundled_package_available"],
                "recommended": model_name == "medium"  # æ¨è–¦ä¸­ç­‰æ¨¡å‹
            }
            options.append(option)
            
        return {
            "type": "model_selection",
            "options": options,
            "message": "é¸æ“‡è¦ä½¿ç”¨çš„ AI æ¨¡å‹",
            "details": "é¦–æ¬¡ä½¿ç”¨éœ€è¦å®‰è£ AI æ¨¡å‹ã€‚æ‚¨å¯ä»¥é¸æ“‡é ç½®æ¨¡å‹ï¼ˆå¿«é€Ÿï¼‰æˆ–ä¸‹è¼‰æœ€æ–°ç‰ˆæœ¬ï¼ˆéœ€è¦ç¶²è·¯ï¼‰ã€‚"
        }
        
    def install_selected_model(self, model_name, progress_callback=None):
        """å®‰è£é¸å®šçš„æ¨¡å‹"""
        try:
            success, path, source = self.model_manager.download_model_if_needed(
                model_name, 
                progress_callback=progress_callback
            )
            
            if success:
                return {
                    "success": True,
                    "model": model_name,
                    "source": source,
                    "path": path,
                    "message": f"{model_name} æ¨¡å‹å®‰è£å®Œæˆ"
                }
            else:
                return {
                    "success": False,
                    "model": model_name,
                    "error": path,
                    "message": f"{model_name} æ¨¡å‹å®‰è£å¤±æ•—"
                }
                
        except Exception as e:
            return {
                "success": False,
                "model": model_name,
                "error": str(e),
                "message": "æ¨¡å‹å®‰è£éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤"
            }


def main():
    """CLI æ¥å£"""
    if len(sys.argv) > 1:
        command = sys.argv[1]
        guide = FirstRunGuide()
        
        if command == "list":
            # åˆ—å‡ºæ¨¡å‹é¸é …
            result = guide.show_model_selection_dialog()
            print(json.dumps(result, ensure_ascii=False, indent=2))
            
        elif command == "install" and len(sys.argv) > 2:
            # å®‰è£æŒ‡å®šæ¨¡å‹
            model_name = sys.argv[2]
            
            def progress_callback(percent, message):
                print(f"PROGRESS:{json.dumps({'percent': percent, 'message': message}, ensure_ascii=False)}")
                
            result = guide.install_selected_model(model_name, progress_callback)
            print(f"RESULT:{json.dumps(result, ensure_ascii=False)}")
            
        else:
            print("Usage: python first_run_guide.py [list|install <model_name>]")
    else:
        # äº¤äº’æ¨¡å¼
        guide = FirstRunGuide()
        options = guide.show_model_selection_dialog()
        
        print("=== SRT GO é¦–æ¬¡é‹è¡Œåš®å° ===")
        print(options["details"])
        print()
        
        for i, option in enumerate(options["options"]):
            status = "âœ…æœ¬åœ°å¯ç”¨" if option["available_locally"] else ("ğŸ“¦æœ‰é ç½®åŒ…" if option["bundled_available"] else "ğŸŒéœ€è¦ä¸‹è¼‰")
            recommended = " [æ¨è–¦]" if option["recommended"] else ""
            print(f"{i+1}. {option['name'].upper()}{recommended}")
            print(f"   å¤§å°: {option['size_mb']}MB | {option['description']}")
            print(f"   ç‹€æ…‹: {status}")
            print()
            
        choice = input("è«‹é¸æ“‡æ¨¡å‹ (1-4): ").strip()
        try:
            idx = int(choice) - 1
            if 0 <= idx < len(options["options"]):
                selected_model = options["options"][idx]["name"]
                print(f"æ­£åœ¨å®‰è£ {selected_model} æ¨¡å‹...")
                
                def progress_callback(percent, message):
                    print(f"[{percent:3d}%] {message}")
                    
                result = guide.install_selected_model(selected_model, progress_callback)
                
                if result["success"]:
                    print(f"\\nâœ… {result['message']}")
                else:
                    print(f"\\nâŒ {result['message']}")
            else:
                print("ç„¡æ•ˆçš„é¸æ“‡")
        except ValueError:
            print("è«‹è¼¸å…¥æ•¸å­—")


if __name__ == "__main__":
    main()
`;

fs.writeFileSync(
    path.join(__dirname, '..', 'first_run_guide.py'),
    firstRunGuide,
    'utf8'
);

// 6. å‰µå»ºä½¿ç”¨èªªæ˜
const usageInstructions = `# é ç½®æ¨¡å‹ç³»çµ±ä½¿ç”¨èªªæ˜

## ğŸ¯ ç³»çµ±æ¦‚è¿°

æ–°çš„é ç½®æ¨¡å‹ç³»çµ±è§£æ±ºäº†ä»¥ä¸‹å•é¡Œï¼š
1. **ç¶²è·¯ä¾è³´**ï¼šé¦–æ¬¡ä½¿ç”¨ä¸éœ€è¦ç¶²è·¯ä¸‹è¼‰
2. **å®‰è£å¡ä½**ï¼šé ç½®æ¨¡å‹ç›´æ¥è§£å£“ï¼Œç§’é€Ÿå®‰è£
3. **é›¢ç·šä½¿ç”¨**ï¼šå®Œå…¨æ”¯æ´ç„¡ç¶²è·¯ç’°å¢ƒä½¿ç”¨

## ğŸ“¦ æ¨¡å‹åŒ…å«ç­–ç•¥

### é ç½®æ¨¡å‹ï¼ˆåŒ…å«åœ¨å®‰è£åŒ…ä¸­ï¼‰
- **tiny** (39MB) - æœ€å¿«é€Ÿï¼ŒåŸºæœ¬æº–ç¢ºåº¦
- **base** (74MB) - å¹³è¡¡é¸æ“‡ï¼Œé©åˆä¸€èˆ¬ä½¿ç”¨  
- **medium** (244MB) - æ¨è–¦æ¨¡å‹ï¼Œé«˜æº–ç¢ºåº¦

### å¯é¸ä¸‹è¼‰æ¨¡å‹
- **large** (769MB) - æœ€é«˜æº–ç¢ºåº¦ï¼Œéœ€è¦ç¶²è·¯ä¸‹è¼‰

## ğŸ”§ é–‹ç™¼è€…æ§‹å»ºæµç¨‹

### 1. æº–å‚™æ¨¡å‹æ–‡ä»¶
\`\`\`bash
# åœ¨æœ‰ç¶²è·¯çš„é–‹ç™¼ç’°å¢ƒä¸­ä¸‹è¼‰æ¨¡å‹
python model_manager.py  # è§¸ç™¼æ¨¡å‹ä¸‹è¼‰åˆ°ç·©å­˜
\`\`\`

### 2. å‰µå»ºæ¨¡å‹å®‰è£åŒ…
\`\`\`bash
# åŸ·è¡Œæ¨¡å‹æ‰“åŒ…è…³æœ¬
build_with_models.bat

# æˆ–æ‰‹å‹•åŸ·è¡Œ
python -c "from model_manager import ModelManager; m = ModelManager(); [m.create_model_package(model, 'models') for model in ['tiny', 'base', 'medium']]"
\`\`\`

### 3. æ§‹å»ºæ‡‰ç”¨ç¨‹å¼
\`\`\`bash
# æ§‹å»ºåŒ…å«é ç½®æ¨¡å‹çš„ç‰ˆæœ¬
npm run build:with-models

# æˆ–æ¨™æº–æ§‹å»ºï¼ˆå¦‚æœå·²ç¶“æº–å‚™å¥½æ¨¡å‹ï¼‰
npm run build
\`\`\`

## ğŸ® ç”¨æˆ¶ä½¿ç”¨æµç¨‹

### é¦–æ¬¡å•Ÿå‹•
1. **è‡ªå‹•æª¢æ¸¬**ï¼šç¨‹å¼æª¢æŸ¥å¯ç”¨æ¨¡å‹
2. **æ™ºèƒ½é¸æ“‡**ï¼š
   - æœ‰é ç½®åŒ… â†’ è‡ªå‹•å®‰è£é ç½®æ¨¡å‹
   - æœ‰ç¶²è·¯ â†’ æä¾›ä¸‹è¼‰é¸é …  
   - é›¢ç·šç’°å¢ƒ â†’ ä½¿ç”¨æœ€å°å¯ç”¨æ¨¡å‹

### æ¨¡å‹é¸æ“‡é‚è¼¯
\`\`\`
ç”¨æˆ¶é¸æ“‡æ¨¡å‹ â†’ æª¢æŸ¥é †åºï¼š
1. æœ¬åœ°å·²å®‰è£ â†’ ç›´æ¥ä½¿ç”¨
2. æœ‰é ç½®åŒ… â†’ è§£å£“å®‰è£ï¼ˆç§’ç´šå®Œæˆï¼‰
3. æœ‰ç¶²è·¯ â†’ ä¸‹è¼‰å®‰è£
4. éƒ½æ²’æœ‰ â†’ é™ç´šåˆ° tiny æ¨¡å‹
\`\`\`

## ğŸ“Š å®‰è£åŒ…å¤§å°å°æ¯”

### ä¸å«æ¨¡å‹ç‰ˆæœ¬
- **å¤§å°**ï¼š~150MB
- **é¦–æ¬¡ä½¿ç”¨**ï¼šéœ€è¦ç¶²è·¯ä¸‹è¼‰æ¨¡å‹
- **å„ªé»**ï¼šå®‰è£åŒ…è¼ƒå°

### å«é ç½®æ¨¡å‹ç‰ˆæœ¬  
- **å¤§å°**ï¼š~500MB (tiny+base+medium)
- **é¦–æ¬¡ä½¿ç”¨**ï¼šç«‹å³å¯ç”¨ï¼Œç„¡éœ€ç¶²è·¯
- **å„ªé»**ï¼šå®Œå…¨é›¢ç·šï¼Œå®‰è£å³ç”¨

## âš™ï¸ æŠ€è¡“å¯¦ç¾

### æ¨¡å‹ç®¡ç†å™¨ (model_manager.py)
- **check_local_model()**: æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§
- **install_bundled_model()**: å®‰è£é ç½®æ¨¡å‹  
- **download_model_if_needed()**: æ™ºèƒ½æ¨¡å‹ç²å–

### å®‰è£åŒ…çµæ§‹
\`\`\`
SRT GO - AI å­—å¹•ç”Ÿæˆå·¥å…·-2.0.0-Setup.exe
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ mini_python/          # Python é‹è¡Œç’°å¢ƒ
â”‚   â”œâ”€â”€ python/               # æ‡‰ç”¨ç¨‹å¼è…³æœ¬
â”‚   â””â”€â”€ models/               # é ç½®æ¨¡å‹åŒ…
â”‚       â”œâ”€â”€ whisper-tiny-model.zip
â”‚       â”œâ”€â”€ whisper-base-model.zip
â”‚       â””â”€â”€ whisper-medium-model.zip
\`\`\`

## ğŸ”„ é¦–æ¬¡é‹è¡Œåš®å°

ç•¶ç”¨æˆ¶é¦–æ¬¡å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼æ™‚ï¼š
1. **æª¢æ¸¬ç’°å¢ƒ**ï¼šæª¢æŸ¥ç¶²è·¯ã€æœ¬åœ°æ¨¡å‹ç‹€æ…‹
2. **é¡¯ç¤ºé¸é …**ï¼šå±•ç¤ºå¯ç”¨çš„æ¨¡å‹é¸æ“‡
3. **æ™ºèƒ½æ¨è–¦**ï¼šæ ¹æ“šç’°å¢ƒæ¨è–¦æœ€ä½³æ¨¡å‹
4. **å¿«é€Ÿå®‰è£**ï¼šå„ªå…ˆä½¿ç”¨é ç½®æ¨¡å‹ï¼Œç§’ç´šå®Œæˆ

## ğŸ’¡ ç”¨æˆ¶é«”é©—æå‡

### ä¹‹å‰ï¼ˆæœƒå¡ä½ï¼‰
\`\`\`
å•Ÿå‹•ç¨‹å¼ â†’ é¸æ“‡æª”æ¡ˆ â†’ é–‹å§‹è™•ç† â†’ å¡åœ¨5%ï¼ˆä¸‹è¼‰æ¨¡å‹ï¼‰â†’ è¶…æ™‚å¤±æ•—
\`\`\`

### ç¾åœ¨ï¼ˆé †æš¢é«”é©—ï¼‰
\`\`\`
å®‰è£ç¨‹å¼ â†’ é¦–æ¬¡å•Ÿå‹• â†’ è‡ªå‹•å®‰è£æ¨¡å‹(3ç§’) â†’ é¸æ“‡æª”æ¡ˆ â†’ ç«‹å³é–‹å§‹è™•ç†
\`\`\`

é€™å€‹ç³»çµ±ç¢ºä¿ç”¨æˆ¶åœ¨ä»»ä½•ç’°å¢ƒä¸‹éƒ½èƒ½é †åˆ©ä½¿ç”¨æ‡‰ç”¨ç¨‹å¼ï¼Œå¾¹åº•è§£æ±ºäº†æ¨¡å‹ä¸‹è¼‰å¡ä½çš„å•é¡Œã€‚
`;

fs.writeFileSync(
    path.join(__dirname, 'PREBUILT_MODELS_GUIDE.md'),
    usageInstructions,
    'utf8'
);

console.log('\nğŸ¯ é ç½®æ¨¡å‹ç³»çµ±è¨­è¨ˆå®Œæˆï¼');
console.log('ğŸ“ å‰µå»ºçš„æ–‡ä»¶ï¼š');
console.log('  - model_manager.py (æ¨¡å‹ç®¡ç†å™¨)');
console.log('  - first_run_guide.py (é¦–æ¬¡é‹è¡Œåš®å°)'); 
console.log('  - build_with_models.bat (æ§‹å»ºè…³æœ¬)');
console.log('  - PREBUILT_MODELS_GUIDE.md (ä½¿ç”¨èªªæ˜)');
console.log('  - å·²æ›´æ–° package.json é…ç½®');

console.log('\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œï¼š');
console.log('1. åœ¨æœ‰ç¶²è·¯çš„ç’°å¢ƒä¸‹å…ˆä¸‹è¼‰æ¨¡å‹åˆ°ç·©å­˜');
console.log('2. åŸ·è¡Œ build_with_models.bat å‰µå»ºæ¨¡å‹åŒ…');  
console.log('3. é‹è¡Œ npm run build:with-models æ§‹å»ºå®Œæ•´å®‰è£åŒ…');
console.log('4. æ–°çš„å®‰è£åŒ…å°‡åŒ…å«é ç½®æ¨¡å‹ï¼Œå¾¹åº•è§£æ±ºå¡ä½å•é¡Œ');

// 7. å‰µå»ºæ¸¬è©¦è…³æœ¬
const testScript = `@echo off
echo ğŸ§ª æ¸¬è©¦é ç½®æ¨¡å‹ç³»çµ±...
echo.

echo ğŸ“‹ æ¸¬è©¦æ­¥é©Ÿï¼š
echo 1. æª¢æŸ¥æ¨¡å‹ç®¡ç†å™¨
python ../model_manager.py

echo.
echo 2. æ¸¬è©¦é¦–æ¬¡é‹è¡Œåš®å°
python ../first_run_guide.py list

echo.
echo âœ… æ¸¬è©¦å®Œæˆï¼
pause
`;

fs.writeFileSync(
    path.join(__dirname, 'test_model_system.bat'),
    testScript
);

console.log('\nğŸ§ª æ¸¬è©¦è…³æœ¬ï¼štest_model_system.bat');
console.log('ğŸ“– è©³ç´°èªªæ˜ï¼šPREBUILT_MODELS_GUIDE.md');