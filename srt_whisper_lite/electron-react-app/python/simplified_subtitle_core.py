#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆå­—å¹•ç”Ÿæˆæ ¸å¿ƒ
ç§»é™¤è¤‡é›œåŠŸèƒ½ï¼Œå°ˆæ³¨æ–¼ç©©å®šçš„åŸºæœ¬å­—å¹•ç”Ÿæˆ
"""

import os
import sys
import logging
from pathlib import Path
from typing import Optional, Callable
import tempfile
import numpy as np

logger = logging.getLogger(__name__)



# æ·»åŠ ç¶²è·¯é€£æ¥æª¢æŸ¥åŠŸèƒ½
def check_network_and_cache():
    """æª¢æŸ¥ç¶²è·¯é€£æ¥å’Œæ¨¡å‹ç·©å­˜ç‹€æ…‹"""
    import urllib.request
    import os
    
    # æª¢æŸ¥ç¶²è·¯
    try:
        urllib.request.urlopen('https://huggingface.co', timeout=5)
        has_internet = True
    except:
        has_internet = False
    
    # æª¢æŸ¥æœ¬åœ°ç·©å­˜
    cache_dir = os.path.join(os.path.expanduser("~"), ".cache", "huggingface", "hub")
    has_cache = os.path.exists(cache_dir) and len(os.listdir(cache_dir)) > 0
    
    return has_internet, has_cache

class SimplifiedSubtitleCore:
    """ç°¡åŒ–ç‰ˆå­—å¹•ç”Ÿæˆæ ¸å¿ƒ"""
    
    def __init__(self, model_size=None, device=None, compute_type=None, performance_mode="auto"):
        # å°å…¥é…ç½®ç®¡ç†å™¨
        try:
            from config_manager import get_config_manager
            self.config = get_config_manager()
        except ImportError:
            self.config = None
            logger.warning("é…ç½®ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜èªåƒæ•¸")
        
        # æ™ºèƒ½æ¨¡å‹é¸æ“‡ - æ ¹æ“šç”¨æˆ¶é…ç½®æ±ºå®šæ¨¡å‹
        self.model_size = model_size or "large-v3"  # é»˜èªä½¿ç”¨ LARGE V3ï¼Œä½†å…è¨±é…ç½®è¦†è“‹
        self.device = device or (self.config.get("model.device") if self.config else "auto")
        self.compute_type = compute_type or (self.config.get("model.compute_type") if self.config else "auto")
        self.performance_mode = performance_mode  # æ–°å¢æ€§èƒ½æ¨¡å¼åƒæ•¸
        
        self.model = None
        self.initialized = False
        
        # åªæ”¯æ´ LARGE æ¨¡å‹ - å°ˆæ¥­ç‰ˆ
        self.supported_models = ["large"]
        
        # æ¨¡å‹é¡¯ç¤ºåç¨±æ˜ å°„
        self.model_display_names = {
            "base": "Base",
            "medium": "Medium", 
            "large": "Large"
        }
        
        # æ¨¡å‹ç‰¹å®šçš„å„ªåŒ–åƒæ•¸ï¼ˆç°¡åŒ–ï¼‰
        self.model_params = {
            "base": {"beam_size": 4, "best_of": 4, "temperature": [0.0, 0.2, 0.4, 0.6]},
            "medium": {"beam_size": 6, "best_of": 6, "temperature": [0.0, 0.2, 0.4, 0.6, 0.8]},
            "large": {"beam_size": 8, "best_of": 8, "temperature": [0.0, 0.2, 0.4, 0.6, 0.8]}
        }
        
    def initialize(self, progress_callback: Optional[Callable] = None) -> bool:
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            if progress_callback:
                if progress_callback(5, "æ­£åœ¨è¼‰å…¥ AI æ¨¡å‹...") == False:
                    return False
            
            from faster_whisper import WhisperModel
            
            # æ ¹æ“šæ€§èƒ½æ¨¡å¼é¸æ“‡é©ç•¶çš„æ¨¡å‹ç®¡ç†å™¨
            using_fp16_optimization = False
            model_manager = None
            
            if self.performance_mode == "gpu":
                # å¼·åˆ¶ä½¿ç”¨GPUæ¨¡å¼
                try:
                    from large_v3_fp16_performance_manager import get_fp16_performance_manager
                    model_manager = get_fp16_performance_manager()
                    # å¼·åˆ¶è¨­å‚™å’Œè¨ˆç®—é¡å‹
                    self.device = "cuda"
                    self.compute_type = "float16"
                    using_fp16_optimization = True
                    logger.info("ç”¨æˆ¶é¸æ“‡GPUæ¨¡å¼ - å¼·åˆ¶ä½¿ç”¨CUDA Float16")
                except ImportError:
                    logger.warning("FP16ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°è‡ªå‹•æ¨¡å¼")
                    
            elif self.performance_mode == "cpu":
                # å¼·åˆ¶ä½¿ç”¨CPUæ¨¡å¼
                try:
                    from large_v3_int8_model_manager import LargeV3INT8ModelManager
                    model_manager = LargeV3INT8ModelManager()
                    # å¼·åˆ¶è¨­å‚™å’Œè¨ˆç®—é¡å‹
                    self.device = "cpu"
                    self.compute_type = "int8"
                    using_fp16_optimization = False
                    logger.info("ç”¨æˆ¶é¸æ“‡CPUæ¨¡å¼ - å¼·åˆ¶ä½¿ç”¨CPU INT8")
                except ImportError:
                    logger.warning("INT8ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°è‡ªå‹•æ¨¡å¼")
            
            # è‡ªå‹•æ¨¡å¼æˆ–å›é€€æƒ…æ³
            if model_manager is None:
                # å„ªå…ˆä½¿ç”¨FP16æ€§èƒ½å„ªåŒ–é…ç½®ï¼ˆç”Ÿç”¢ç´š50%æ€§èƒ½æå‡ï¼‰
                try:
                    from large_v3_fp16_performance_manager import get_fp16_performance_manager
                    model_manager = get_fp16_performance_manager()
                    using_fp16_optimization = True
                    logger.info("è‡ªå‹•æ¨¡å¼ - ä½¿ç”¨FP16æ€§èƒ½å„ªåŒ–é…ç½® (RTFé æœŸ: 0.135)")
                except ImportError:
                    # å›é€€åˆ°INT8ç‰ˆæœ¬
                    from large_v3_int8_model_manager import LargeV3INT8ModelManager
                    model_manager = LargeV3INT8ModelManager()
                    using_fp16_optimization = False
                    logger.info("è‡ªå‹•æ¨¡å¼ - å›é€€åˆ°INT8é…ç½®")
            
            # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å¤§å°å’Œè¨­ç½®
            logger.info(f"è¼‰å…¥æ¨¡å‹: {self.model_size}, è¨­å‚™: {self.device}, è¨ˆç®—é¡å‹: {self.compute_type}")
            
            # æ·»åŠ æ¨¡å‹ä¸‹è¼‰è¶…æ™‚å’Œé‡è©¦æ©Ÿåˆ¶
            import os
            import time
            from pathlib import Path
            
            # æª¢æŸ¥æœ¬åœ°æ¨¡å‹ç·©å­˜
            cache_dir = os.path.join(os.path.expanduser("~"), ".cache", "huggingface", "hub")
            local_model_exists = False
            
            if os.path.exists(cache_dir):
                # æª¢æŸ¥æ˜¯å¦æœ‰æœ¬åœ° large æ¨¡å‹
                for item in os.listdir(cache_dir):
                    if "whisper-large" in item.lower():
                        local_model_exists = True
                        break
            
            logger.info(f"æœ¬åœ°æ¨¡å‹ç·©å­˜æª¢æŸ¥: {'å­˜åœ¨' if local_model_exists else 'ä¸å­˜åœ¨'}")
            
            # æ·»åŠ ç¶²è·¯é€£æ¥æª¢æŸ¥
            def check_internet_connection():
                try:
                    import urllib.request
                    urllib.request.urlopen('https://huggingface.co', timeout=10)
                    return True
                except:
                    return False
            
            has_internet = check_internet_connection()
            logger.info(f"ç¶²è·¯é€£æ¥ç‹€æ…‹: {'å¯ç”¨' if has_internet else 'ä¸å¯ç”¨'}")
            
            # æ™ºèƒ½é¸æ“‡æ¨¡å‹ä¸‹è¼‰ç­–ç•¥
            download_timeout = 300  # 5åˆ†é˜è¶…æ™‚
            max_download_retries = 2
            
            for download_attempt in range(max_download_retries + 1):
                try:
                    if progress_callback:
                        if download_attempt == 0:
                            progress_callback(5, "æ­£åœ¨åˆå§‹åŒ– AI æ¨¡å‹...")
                        else:
                            progress_callback(5, f"æ¨¡å‹åˆå§‹åŒ–é‡è©¦ {download_attempt}/{max_download_retries}...")
                    
                    start_time = time.time()
                    
                    # å¼·åˆ¶ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹ï¼Œä¸é€²è¡Œé™ç´š
                    actual_model_size = self.model_size
                    if not has_internet and not local_model_exists:
                        logger.warning(f"ç„¡ç¶²è·¯é€£æ¥ä¸”ç„¡æœ¬åœ° {self.model_size} æ¨¡å‹")
                        if progress_callback:
                            progress_callback(8, f"éœ€è¦ä¸‹è¼‰ {self.model_size} æ¨¡å‹...")
                        # ä¸é™ç´šï¼Œä¿æŒåŸæ¨¡å‹å¤§å°
                    
                    # ä½¿ç”¨ LARGE å°ˆç”¨æ¨¡å‹ç®¡ç†å™¨
                    def model_progress(percent, message):
                        if progress_callback:
                            progress_callback(5 + (percent // 5), message)
                    
                    success, model_path = model_manager.ensure_model_ready()
                    
                    if not success:
                        logger.error("ç„¡æ³•ç²å–æ¨¡å‹")
                        return False
                    
                    # å‰µå»ºæ¨¡å‹å¯¦ä¾‹ - æ ¹æ“šç®¡ç†å™¨é¡å‹ä½¿ç”¨é…ç½®
                    if using_fp16_optimization:
                        model_config = model_manager.get_optimized_whisper_config()
                        logger.info("æ‡‰ç”¨FP16å„ªåŒ–é…ç½®ï¼Œé æœŸæ€§èƒ½æå‡50%")
                    else:
                        model_config = model_manager.get_faster_whisper_config()
                        logger.info("ä½¿ç”¨INT8é…ç½®")
                    
                    # æ™ºèƒ½é…ç½®è¦†è“‹ - ç¢ºä¿è¨­å‚™å’Œè¨ˆç®—é¡å‹çš„ä¸€è‡´æ€§
                    if self.device and self.device != "auto":
                        if using_fp16_optimization:
                            # å°æ–¼FP16å„ªåŒ–ï¼Œåªåœ¨ç”¨æˆ¶æ˜ç¢ºè¦æ±‚ä¸”é…ç½®ä¸€è‡´æ™‚è¦†è“‹
                            if self.device == "cpu" and model_config["compute_type"] == "float16":
                                logger.warning("ç”¨æˆ¶é¸æ“‡CPUä½†æª¢æ¸¬åˆ°float16ï¼Œè‡ªå‹•èª¿æ•´ç‚ºint8ä»¥ç¢ºä¿å…¼å®¹æ€§")
                                model_config["compute_type"] = "int8"
                                model_config["device"] = "cpu"
                            elif self.device == "cuda" and model_config["compute_type"] == "int8":
                                logger.info("ç”¨æˆ¶é¸æ“‡CUDAï¼Œä¿æŒfloat16é…ç½®")
                                model_config["compute_type"] = "float16" 
                                model_config["device"] = "cuda"
                            else:
                                model_config["device"] = self.device
                        else:
                            model_config["device"] = self.device
                    
                    # æ¨¡å‹å„ªåŒ–é…ç½®æ‡‰ç”¨
                    if using_fp16_optimization:
                        # FP16å„ªåŒ–é…ç½®å·²åœ¨model_configä¸­è¨­å®šï¼Œä¿æŒåŸå§‹é…ç½®
                        logger.info(f"FP16å„ªåŒ– - è¨­å‚™: {model_config['device']}, è¨ˆç®—é¡å‹: {model_config['compute_type']}, ç·šç¨‹: {model_config['cpu_threads']}")
                    else:
                        # INT8 æ¨¡å‹æœ€ä½³åŒ–é…ç½®
                        if hasattr(model_manager, 'model_variant') and "int8" in model_manager.model_variant:
                            model_config["compute_type"] = "int8"  # å¼·åˆ¶ä½¿ç”¨ INT8
                            if self.device == "cuda":
                                model_config["compute_type"] = "int8_float16"  # GPU ä¸Šä½¿ç”¨æ··åˆç²¾åº¦
                    
                    # æ§‹å»ºWhisperModelåƒæ•¸
                    whisper_kwargs = {
                        "device": model_config["device"],
                        "compute_type": model_config["compute_type"],
                        "download_root": model_config.get("download_root"),
                        "local_files_only": not has_internet,  # ç„¡ç¶²è·¯æ™‚åƒ…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                        "num_workers": self.config.get("model.num_workers", 4) if self.config and self.device == "cuda" else 2
                    }
                    
                    # Large V3 ç‰¹æ®Šè™•ç†ï¼šå¼·åˆ¶ä½¿ç”¨æ¨™æº–æ¨¡å‹é¿å…ç‰¹å¾µå½¢ç‹€éŒ¯èª¤
                    model_path_or_name = model_config["model_size_or_path"]
                    if "large-v3" in str(model_path_or_name).lower():
                        logger.info("æª¢æ¸¬åˆ° Large V3 æ¨¡å‹ï¼Œä½¿ç”¨æ¨™æº– 'large-v3' é¿å…ç‰¹å¾µå½¢ç‹€å•é¡Œ...")
                        # å¼·åˆ¶ä½¿ç”¨æ¨™æº–çš„ large-v3 æ¨¡å‹ï¼Œé¿å… turbo ç‰ˆæœ¬çš„ç‰¹å¾µå½¢ç‹€ä¸åŒ¹é…
                        whisper_kwargs['download_root'] = model_config.get("download_root")
                        self.model = WhisperModel(
                            "large-v3",
                            **whisper_kwargs
                        )
                    else:
                        # éLarge V3æ¨¡å‹ï¼Œæ­£å¸¸è¼‰å…¥
                        self.model = WhisperModel(
                            model_path_or_name,
                            **whisper_kwargs
                        )
                    
                    elapsed_time = time.time() - start_time
                    logger.info(f"æ¨¡å‹è¼‰å…¥æˆåŠŸï¼Œè€—æ™‚: {elapsed_time:.1f}ç§’")
                    
                    if progress_callback:
                        progress_callback(20, "AI æ¨¡å‹è¼‰å…¥å®Œæˆ")
                    
                    break  # æˆåŠŸè¼‰å…¥ï¼Œè·³å‡ºé‡è©¦å¾ªç’°
                    
                except Exception as model_error:
                    elapsed_time = time.time() - start_time
                    logger.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•— (å˜—è©¦ {download_attempt + 1}/{max_download_retries + 1}): {model_error}")
                    
                    if download_attempt == max_download_retries:
                        # ä¸å†é™ç´šåˆ° tiny æ¨¡å‹ï¼Œç›´æ¥å¤±æ•—
                        logger.error(f"ç„¡æ³•è¼‰å…¥ {self.model_size} æ¨¡å‹ï¼Œæ‰€æœ‰é‡è©¦å·²å¤±æ•—")
                        if progress_callback:
                            progress_callback(0, f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(model_error)[:50]}...")
                        return False
                    else:
                        # ç­‰å¾…å¾Œé‡è©¦
                        wait_time = (download_attempt + 1) * 5
                        logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                        time.sleep(wait_time)
                        
                        if progress_callback:
                            progress_callback(3, f"æ¨¡å‹è¼‰å…¥é‡è©¦ä¸­...({download_attempt + 1}/{max_download_retries})")
            
            if progress_callback:
                if progress_callback(20, "AI æ¨¡å‹è¼‰å…¥å®Œæˆ") == False:
                    return False
            
            self.initialized = True
            logger.info("ç°¡åŒ–ç‰ˆå­—å¹•ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±æ•—: {e}")
            if progress_callback:
                progress_callback(0, f"åˆå§‹åŒ–å¤±æ•—: {e}")
            return False
    
    def generate_subtitle(self, 
                         input_file: str,
                         output_file: str,
                         language: Optional[str] = None,
                         output_language: Optional[str] = None,
                         format: str = "srt",
                         progress_callback: Optional[Callable] = None) -> bool:
        """ç”Ÿæˆå­—å¹•ï¼ˆç°¡åŒ–ç‰ˆï¼Œå«æ€§èƒ½ç›£æ§ï¼‰"""
        
        if not self.initialized:
            logger.error("æ¨¡å‹æœªåˆå§‹åŒ–")
            return False
        
        # æ€§èƒ½ç›£æ§ - é–‹å§‹è¨ˆæ™‚
        import time
        processing_start_time = time.time()
        audio_duration = 0
        
        try:
            # æª¢æŸ¥è¼¸å…¥æ–‡ä»¶
            if not os.path.exists(input_file):
                logger.error(f"è¼¸å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
                return False
            
            if progress_callback:
                if progress_callback(25, "é–‹å§‹è™•ç†éŸ³é »æ–‡ä»¶...") == False:
                    return False
            
            logger.info(f"é–‹å§‹è½‰éŒ„: {input_file} (æ€§èƒ½ç›£æ§å·²å•Ÿç”¨)")
            
            # ç²å–æ¨¡å‹ç‰¹å®šçš„å„ªåŒ–åƒæ•¸
            model_params = self.model_params.get(self.model_size, self.model_params["medium"])
            
            # å„ªåŒ–çš„è½‰éŒ„åƒæ•¸ - æå‡æº–ç¢ºåº¦å’Œèªæ„æ–·å¥ï¼ŒåŠ å…¥é‡è©¦æ©Ÿåˆ¶
            max_retries = 3
            retry_count = 0
            last_error = None
            
            # èªè¨€ä»£ç¢¼æ˜ å°„ï¼ˆWhisper åªæ”¯æ´åŸºæœ¬èªè¨€ä»£ç¢¼ï¼‰
            whisper_language = language
            if language == 'zh-TW' or language == 'zh-CN':
                whisper_language = 'zh'
            elif language == 'auto':
                whisper_language = None
            
            while retry_count < max_retries:
                try:
                    segments, info = self.model.transcribe(
                        input_file,
                        language=whisper_language,
                        task="transcribe",
                        beam_size=model_params["beam_size"],     # å‹•æ…‹beam_size
                        best_of=model_params["best_of"],         # å‹•æ…‹best_of
                        temperature=model_params["temperature"], # å¤šæº«åº¦ç­–ç•¥
                        compression_ratio_threshold=2.4,         # ä½¿ç”¨ srt_final-orign çš„å„ªåŒ–å€¼
                        log_prob_threshold=-1.0,                 # ä½¿ç”¨ srt_final-orign çš„å„ªåŒ–å€¼
                        no_speech_threshold=0.6,                 # ä½¿ç”¨ srt_final-orign çš„å„ªåŒ–å€¼
                        condition_on_previous_text=False,        # æ”¹ç‚º Falseï¼Œæé«˜ç¨ç«‹æ€§
                        initial_prompt=None,
                        prefix=None,
                        suppress_blank=True,
                        suppress_tokens=[-1],
                        without_timestamps=False,
                        max_initial_timestamp=1.0,
                        word_timestamps=True,                    # å•Ÿç”¨è©ç´šæ™‚é–“æˆ³ï¼Œç”¨æ–¼ç²¾ç¢ºæ™‚é–“è»¸
                        prepend_punctuations="\"'([{-",
                        append_punctuations="\"'.ã€‚,ï¼Œ!ï¼?ï¼Ÿ:ï¼š\")]}ã€",
                        vad_filter=True,
                        vad_parameters={
                            # æ™ºèƒ½VADåƒæ•¸ - æ ¹æ“šæ¨¡å¼èª¿æ•´
                            "threshold": getattr(self, 'vad_threshold', 0.35),  # ä½¿ç”¨é…ç½®çš„é–¾å€¼
                            "min_speech_duration_ms": 250,  # æœ€çŸ­èªéŸ³æŒçºŒæ™‚é–“
                            "max_speech_duration_s": 20,  # é™åˆ¶å–®å€‹ç‰‡æ®µæœ€å¤§é•·åº¦
                            "min_silence_duration_ms": 1000,  # èª¿æ•´ç‚º1ç§’éœéŸ³åˆ†æ®µ
                            "speech_pad_ms": 100  # æ·»åŠ å°‘é‡æ™‚é–“å¡«å……ä»¥æå‡æº–ç¢ºæ€§
                        }
                    )
                    break  # æˆåŠŸå‰‡è·³å‡ºé‡è©¦å¾ªç’°
                    
                except RuntimeError as e:
                    retry_count += 1
                    last_error = e
                    logger.warning(f"è½‰éŒ„å¤±æ•— (ç¬¬ {retry_count}/{max_retries} æ¬¡é‡è©¦): {e}")
                    
                    if retry_count < max_retries:
                        if progress_callback:
                            progress_callback(25, f"è½‰éŒ„å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦ ({retry_count}/{max_retries})...")
                        # é‡è©¦å‰çŸ­æš«ç­‰å¾…
                        import time
                        time.sleep(1)
                    else:
                        raise e
            
            if progress_callback:
                if progress_callback(60, f"è­˜åˆ¥èªè¨€: {info.language}, è™•ç†ä¸­...") == False:
                    return False
            
            # è¨˜éŒ„èªè¨€æª¢æ¸¬ä¿¡å¿ƒåº¦å’ŒéŸ³é »æ™‚é•·ï¼ˆç”¨æ–¼æ€§èƒ½ç›£æ§ï¼‰
            language_probability = getattr(info, 'language_probability', 1.0)
            audio_duration = info.duration  # è¨˜éŒ„éŸ³é »æ™‚é•·ç”¨æ–¼RTFè¨ˆç®—
            logger.info(f"æª¢æ¸¬åˆ°èªè¨€: {info.language} (ä¿¡å¿ƒåº¦: {language_probability:.2%}), æ™‚é•·: {info.duration:.1f}ç§’")
            
            # å¦‚æœä¿¡å¿ƒåº¦éä½ï¼Œç™¼å‡ºè­¦å‘Š
            if language_probability < 0.8:
                logger.warning(f"èªè¨€æª¢æ¸¬ä¿¡å¿ƒåº¦è¼ƒä½ ({language_probability:.2%})ï¼Œå»ºè­°æ‰‹å‹•æŒ‡å®šèªè¨€")
                if progress_callback:
                    progress_callback(60, f"èªè¨€æª¢æ¸¬ä¿¡å¿ƒåº¦è¼ƒä½ï¼Œç¹¼çºŒè™•ç†...")
            
            # æ”¶é›†è½‰éŒ„çµæœ - ä½¿ç”¨æ‰¹æ¬¡è™•ç†å„ªåŒ–è¨˜æ†¶é«”
            result_segments = []
            segment_count = 0
            batch_size = 100  # æ¯æ‰¹è™•ç†100å€‹æ®µè½
            segment_buffer = []
            
            for segment in segments:
                if progress_callback and segment_count % 10 == 0:
                    progress = 60 + int((segment_count / 100) * 25)  # 60-85%
                    if progress_callback(min(progress, 85), f"è™•ç†æ®µè½ {segment_count + 1}...") == False:
                        return False
                
                # æ¸…ç†æ–‡æœ¬
                text = segment.text.strip()
                if text:  # åªä¿ç•™éç©ºæ–‡æœ¬
                    # ä½¿ç”¨è©ç´šæ™‚é–“æˆ³ä¾†ç²å¾—æ›´ç²¾ç¢ºçš„æ™‚é–“è»¸
                    segment_start = segment.start
                    segment_end = segment.end
                    
                    # å¦‚æœæœ‰è©ç´šæ™‚é–“æˆ³ï¼Œä½¿ç”¨æœ€å¾Œä¸€å€‹è©çš„çµæŸæ™‚é–“ä½œç‚ºæ®µè½çµæŸæ™‚é–“
                    if hasattr(segment, 'words') and segment.words:
                        words_data = []
                        for word in segment.words:
                            words_data.append({
                                'start': word.start,
                                'end': word.end,
                                'word': word.word,
                                'probability': getattr(word, 'probability', 1.0)
                            })
                        
                        # ä½¿ç”¨è©ç´šæ™‚é–“æˆ³ä¾†èª¿æ•´æ®µè½æ™‚é–“è»¸
                        if words_data:
                            segment_start = min(segment_start, words_data[0]['start'])
                            segment_end = max(segment_end, words_data[-1]['end'])
                    
                    # åœ¨çµæŸæ™‚é–“å¾Œå»¶çºŒ0.1ç§’ï¼Œæä¾›æ›´å¥½çš„é–±è®€é«”é©—
                    segment_end += 0.1
                    
                    segment_data = {
                        'start': segment_start,
                        'end': segment_end,
                        'text': text,
                        'no_speech_prob': getattr(segment, 'no_speech_prob', 0.0),
                        'avg_logprob': getattr(segment, 'avg_logprob', 0.0)
                    }
                    
                    # å¦‚æœæœ‰è©ç´šæ™‚é–“æˆ³ï¼Œæ·»åŠ åˆ°æ®µè½æ•¸æ“šä¸­
                    if hasattr(segment, 'words') and segment.words:
                        segment_data['words'] = words_data
                    
                    segment_buffer.append(segment_data)
                    
                    # æ‰¹æ¬¡è™•ç†ä»¥å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨
                    if len(segment_buffer) >= batch_size:
                        result_segments.extend(segment_buffer)
                        segment_buffer = []  # æ¸…ç©ºç·©è¡å€
                        
                        # å¼·åˆ¶åƒåœ¾å›æ”¶ä»¥é‡‹æ”¾è¨˜æ†¶é«”
                        import gc
                        gc.collect()
                
                segment_count += 1
            
            # è™•ç†å‰©é¤˜çš„æ®µè½
            if segment_buffer:
                result_segments.extend(segment_buffer)
            
            if not result_segments:
                logger.error("æ²’æœ‰ç²å¾—ä»»ä½•è½‰éŒ„çµæœ")
                if progress_callback:
                    progress_callback(0, "è½‰éŒ„å¤±æ•—ï¼šæ²’æœ‰è­˜åˆ¥åˆ°èªéŸ³å…§å®¹")
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºéœéŸ³æ–‡ä»¶
                try:
                    import wave
                    import numpy as np
                    
                    # ç°¡å–®æª¢æŸ¥éŸ³é »èƒ½é‡
                    with wave.open(input_file, 'rb') as wav_file:
                        frames = wav_file.readframes(wav_file.getnframes())
                        audio_data = np.frombuffer(frames, dtype=np.int16)
                        energy = np.mean(np.abs(audio_data))
                        
                        if energy < 100:  # é–¾å€¼å¯èª¿æ•´
                            logger.info("æª¢æ¸¬åˆ°éœéŸ³æ–‡ä»¶")
                            if progress_callback:
                                progress_callback(0, "æ–‡ä»¶ä¼¼ä¹æ˜¯éœéŸ³çš„ï¼Œæ²’æœ‰å¯è­˜åˆ¥çš„èªéŸ³å…§å®¹")
                except:
                    pass  # å¿½ç•¥æª¢æŸ¥éŒ¯èª¤
                    
                return False
            
            if progress_callback:
                if progress_callback(85, f"ç²å¾— {len(result_segments)} å€‹å­—å¹•æ®µè½ï¼Œæ­£åœ¨å„ªåŒ–èªæ„æ–·å¥...") == False:
                    return False
            
            logger.info(f"è½‰éŒ„å®Œæˆï¼Œå…± {len(result_segments)} å€‹æ®µè½")
            
            # æ·»åŠ  srt_final-orign é¢¨æ ¼çš„ç†è§£åº¦åˆ†æ
            self._analyze_subtitle_quality(result_segments, progress_callback)
            
            # èªæ„æ–·å¥å„ªåŒ–
            try:
                from semantic_processor import SemanticSegmentProcessor
                
                # ç²å–èªè¨€ä»£ç¢¼
                detected_language = info.language if hasattr(info, 'language') else language
                
                # å„ªåŒ–èªæ„æ–·å¥ï¼Œç¢ºä¿æ¯è¡Œåªé¡¯ç¤ºé©ç•¶é•·åº¦çš„æ–‡å­—ï¼Œä¸¦å‚³éæ¨¡å‹å¤§å°å’ŒéŸ³é »æ–‡ä»¶è·¯å¾‘
                logger.info(f"é–‹å§‹èªæ„æ–·å¥è™•ç†ï¼Œä½¿ç”¨ {self.model_size} æ¨¡å‹å„ªåŒ–å­—å¹•åˆ†å‰²")
                processor = SemanticSegmentProcessor(detected_language, self.model_size)
                processor.audio_file = input_file  # å‚³ééŸ³é »æ–‡ä»¶è·¯å¾‘ä¾›å‰ªæ˜ å°é½Šä½¿ç”¨
                result_segments = processor.process_segments(result_segments)
                
                if progress_callback:
                    if progress_callback(92, f"èªæ„å„ªåŒ–å®Œæˆï¼Œå…± {len(result_segments)} å€‹æ®µè½") == False:
                        return False
                
                logger.info(f"èªæ„æ–·å¥å„ªåŒ–å®Œæˆï¼Œå„ªåŒ–å¾Œå…± {len(result_segments)} å€‹æ®µè½")
                
            except ImportError:
                logger.warning("èªæ„è™•ç†å™¨ä¸å¯ç”¨ï¼Œè·³éå„ªåŒ–æ­¥é©Ÿ")
            except Exception as e:
                logger.warning(f"èªæ„æ–·å¥å„ªåŒ–å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹çµæœ: {e}")
            
            # å¢å¼·å‹è¼•é‡ç´šèªéŸ³æª¢æ¸¬ v2.0 - æ•´åˆå…§å®¹é¡å‹è‡ªå‹•æª¢æ¸¬ï¼ˆé è¨­å•Ÿç”¨ï¼‰
            if hasattr(self, 'enable_adaptive_voice_detection') and getattr(self, 'enable_adaptive_voice_detection', True):
                try:
                    from enhanced_lightweight_voice_detector import EnhancedLightweightVoiceDetector
                    
                    if progress_callback:
                        if progress_callback(88, "å•Ÿå‹•å¢å¼·å‹èªéŸ³æª¢æ¸¬ç³»çµ± v2.0...") == False:
                            return False
                    
                    logger.info("ğŸ¯ å•Ÿå‹•å¢å¼·å‹è¼•é‡ç´šèªéŸ³æª¢æ¸¬ç³»çµ± v2.0 - è‡ªå‹•å…§å®¹é¡å‹æª¢æ¸¬")
                    voice_detector = EnhancedLightweightVoiceDetector()
                    result_segments = voice_detector.detect_voice_segments(result_segments, input_file)
                    
                    # è¨˜éŒ„æª¢æ¸¬æ‘˜è¦
                    summary = voice_detector.get_detection_summary()
                    logger.info(f"Content type detected: {summary['content_type_detected']}")
                    logger.info(f"Applied specialized thresholds for {summary['content_type_detected']}")
                    
                    if progress_callback:
                        if progress_callback(92, f"å¢å¼·å‹èªéŸ³æª¢æ¸¬å®Œæˆï¼Œå…± {len(result_segments)} å€‹æ®µè½") == False:
                            return False
                    
                    logger.info(f"âœ… å¢å¼·å‹èªéŸ³æª¢æ¸¬å®Œæˆï¼Œæœ€çµ‚ {len(result_segments)} å€‹æ®µè½")
                    
                except ImportError:
                    # å‚™ç”¨æ©Ÿåˆ¶1ï¼šå˜—è©¦åŸºç¤ç‰ˆè¼•é‡ç´šæª¢æ¸¬å™¨
                    try:
                        from lightweight_voice_detector import LightweightVoiceDetector
                        
                        if progress_callback:
                            if progress_callback(88, "å•Ÿå‹•åŸºç¤ç‰ˆèªéŸ³æª¢æ¸¬ç³»çµ±...") == False:
                                return False
                        
                        logger.info("ğŸ¯ å•Ÿå‹•è¼•é‡ç´šèªéŸ³æª¢æ¸¬ç³»çµ± (åŸºç¤ç‰ˆ) - ç„¡ä¾è³´ï¼Œç´”éŸ³é »ç‰¹å¾µé©…å‹•")
                        voice_detector = LightweightVoiceDetector()
                        result_segments = voice_detector.detect_voice_segments(result_segments, input_file)
                        
                        if progress_callback:
                            if progress_callback(92, f"åŸºç¤ç‰ˆèªéŸ³æª¢æ¸¬å®Œæˆï¼Œå…± {len(result_segments)} å€‹æ®µè½") == False:
                                return False
                        
                        logger.info(f"âœ… åŸºç¤ç‰ˆèªéŸ³æª¢æ¸¬å®Œæˆï¼Œæœ€çµ‚ {len(result_segments)} å€‹æ®µè½")
                        
                    except ImportError:
                        logger.warning("æ‰€æœ‰è¼•é‡ç´šèªéŸ³æª¢æ¸¬å™¨ä¸å¯ç”¨ï¼Œè·³éèªéŸ³æª¢æ¸¬æ­¥é©Ÿ")
                    except Exception as e2:
                        logger.warning(f"åŸºç¤ç‰ˆèªéŸ³æª¢æ¸¬å¤±æ•—: {e2}")
                        
                except Exception as e:
                    logger.warning(f"å¢å¼·å‹èªéŸ³æª¢æ¸¬å¤±æ•—ï¼Œå˜—è©¦å‚™ç”¨æ–¹æ¡ˆ: {e}")
                    # å‚™ç”¨æ©Ÿåˆ¶ï¼šå˜—è©¦åŸºç¤ç‰ˆæª¢æ¸¬å™¨
                    try:
                        from lightweight_voice_detector import LightweightVoiceDetector
                        logger.info("ğŸ”„ å‚™ç”¨æ©Ÿåˆ¶ï¼šå•Ÿå‹•åŸºç¤ç‰ˆè¼•é‡ç´šæª¢æ¸¬å™¨")
                        voice_detector = LightweightVoiceDetector()
                        result_segments = voice_detector.detect_voice_segments(result_segments, input_file)
                        logger.info("âœ… å‚™ç”¨èªéŸ³æª¢æ¸¬å®Œæˆ")
                    except Exception as fallback_error:
                        logger.warning(f"å‚™ç”¨èªéŸ³æª¢æ¸¬ä¹Ÿå¤±æ•—: {fallback_error}")
                        # æœ€çµ‚å‚™ç”¨ï¼šå˜—è©¦è‡ªé©æ‡‰æª¢æ¸¬å™¨
                        try:
                            from adaptive_voice_detector import AdaptiveVoiceDetector
                            logger.info("ğŸ”„ æœ€çµ‚å‚™ç”¨ï¼šå•Ÿå‹•è‡ªé©æ‡‰èªéŸ³æª¢æ¸¬å™¨")
                            voice_detector = AdaptiveVoiceDetector()
                            result_segments = voice_detector.detect_voice_segments(result_segments, input_file)
                            logger.info("âœ… æœ€çµ‚å‚™ç”¨æª¢æ¸¬å®Œæˆ")
                        except Exception as final_error:
                            logger.warning(f"æ‰€æœ‰èªéŸ³æª¢æ¸¬å™¨éƒ½å¤±æ•—: {final_error}")
            
            # æ™ºèƒ½é–“å¥æª¢æ¸¬ - æª¢æŸ¥æ˜¯å¦å•Ÿç”¨ï¼ˆå‘å¾Œå…¼å®¹ï¼Œä½†ä¸å†æ˜¯é è¨­ï¼‰
            elif hasattr(self, 'enable_interlude_detection') and getattr(self, 'enable_interlude_detection', False):
                try:
                    from intelligent_interlude_filter import IntelligentInterludeFilter
                    
                    if progress_callback:
                        if progress_callback(88, "å•Ÿå‹•å‚³çµ±æ™ºèƒ½é–“å¥æª¢æ¸¬ç³»çµ±...") == False:
                            return False
                    
                    logger.info("å•Ÿå‹•å‚³çµ±æ™ºèƒ½é–“å¥æª¢æ¸¬èˆ‡ä¿®æ­£ç³»çµ±")
                    interlude_filter = IntelligentInterludeFilter()
                    result_segments = interlude_filter.detect_and_fix_interludes(result_segments, input_file)
                    
                    if progress_callback:
                        if progress_callback(92, f"æ™ºèƒ½é–“å¥æª¢æ¸¬å®Œæˆï¼Œå…± {len(result_segments)} å€‹æ®µè½") == False:
                            return False
                    
                    logger.info(f"æ™ºèƒ½é–“å¥æª¢æ¸¬å®Œæˆï¼Œæœ€çµ‚ {len(result_segments)} å€‹æ®µè½")
                    
                except ImportError:
                    logger.warning("æ™ºèƒ½é–“å¥æª¢æ¸¬å™¨ä¸å¯ç”¨ï¼Œè·³éé–“å¥æª¢æ¸¬æ­¥é©Ÿ")
                except Exception as e:
                    logger.warning(f"æ™ºèƒ½é–“å¥æª¢æ¸¬å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹çµæœ: {e}")
            
            # å‚³çµ±SubEasy 5å±¤æ¿¾æ³¢ç³»çµ± - æª¢æŸ¥æ˜¯å¦å•Ÿç”¨ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            elif hasattr(self, 'enable_subeasy') and getattr(self, 'enable_subeasy', False):
                try:
                    from subeasy_multilayer_filter import IntelligentMultiLayerFilter
                    
                    if progress_callback:
                        if progress_callback(88, "å•Ÿå‹•å‚³çµ±SubEasy 5å±¤æ¿¾æ³¢ç³»çµ±...") == False:
                            return False
                    
                    logger.info("å•Ÿå‹•å‚³çµ±SubEasyæ™ºèƒ½5å±¤æ¿¾æ³¢ç³»çµ±")
                    subeasy_filter = IntelligentMultiLayerFilter()
                    result_segments = subeasy_filter.apply_multilayer_filter(result_segments, input_file)
                    
                    if progress_callback:
                        if progress_callback(92, f"SubEasyæ¿¾æ³¢å®Œæˆï¼Œå…± {len(result_segments)} å€‹æ®µè½") == False:
                            return False
                    
                    logger.info(f"SubEasy 5å±¤æ¿¾æ³¢å®Œæˆï¼Œæœ€çµ‚ {len(result_segments)} å€‹æ®µè½")
                    
                except ImportError:
                    logger.warning("SubEasyæ¿¾æ³¢å™¨ä¸å¯ç”¨ï¼Œè·³é5å±¤æ¿¾æ³¢æ­¥é©Ÿ")
                except Exception as e:
                    logger.warning(f"SubEasyæ¿¾æ³¢å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹çµæœ: {e}")
            
            # è·³éå¾Œè™•ç†å„ªåŒ–ä»¥ä¿æŒç²¾ç¢ºçš„è©ç´šæ™‚é–“æˆ³
            if progress_callback:
                if progress_callback(93, "ä¿æŒåŸå§‹æ™‚é–“æˆ³ï¼Œè·³éå¾Œè™•ç†...") == False:
                    return False
            
            logger.info(f"ä¿æŒåŸå§‹è©ç´šæ™‚é–“æˆ³ï¼Œè·³éå¾Œè™•ç†å„ªåŒ–ï¼Œæœ€çµ‚ {len(result_segments)} å€‹æ®µè½")
            
            # å¦‚æœéœ€è¦ç¿»è­¯åˆ°å…¶ä»–èªè¨€ï¼Œä½¿ç”¨ Whisper é‡æ–°è™•ç†
            logger.info(f"æª¢æŸ¥ç¿»è­¯æ¢ä»¶ - output_language: {output_language}")
            if output_language and output_language != 'same':
                logger.info(f"å•Ÿå‹•ç¿»è­¯æµç¨‹ï¼Œç›®æ¨™èªè¨€: {output_language}")
                if progress_callback:
                    if progress_callback(95, f"æ­£åœ¨ç”Ÿæˆ {output_language} å­—å¹•...") == False:
                        return False
                try:
                    result_segments = self._generate_translated_subtitle(input_file, output_language, model_params, result_segments)
                    logger.info(f"å¤šèªè¨€å­—å¹•ç”Ÿæˆå®Œæˆï¼Œç›®æ¨™èªè¨€: {output_language}")
                except Exception as e:
                    logger.warning(f"å¤šèªè¨€å­—å¹•ç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬: {e}")
            else:
                logger.info(f"è·³éç¿»è­¯æ­¥é©Ÿ - output_language: {output_language}")
            
            if progress_callback:
                if progress_callback(97, "æ­£åœ¨ä¿å­˜å­—å¹•æ–‡ä»¶...") == False:
                    return False
            
            # ä¿å­˜å­—å¹•
            success = self._save_subtitle(result_segments, output_file, format)
            
            if success:
                # æ€§èƒ½ç›£æ§ - è¨ˆç®—ä¸¦å ±å‘ŠRTF
                processing_time = time.time() - processing_start_time
                
                # ä½¿ç”¨FP16æ€§èƒ½ç®¡ç†å™¨é€²è¡Œæ€§èƒ½é©—è­‰ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                try:
                    if hasattr(self, 'model') and hasattr(self.model, '__dict__'):
                        # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨FP16å„ªåŒ–
                        from large_v3_fp16_performance_manager import validate_processing_performance
                        performance_result = validate_processing_performance(processing_time, audio_duration)
                        
                        logger.info(f"æ€§èƒ½ç›£æ§å ±å‘Š:")
                        logger.info(f"  è™•ç†æ™‚é–“: {processing_time:.1f}ç§’")
                        logger.info(f"  éŸ³é »æ™‚é•·: {audio_duration:.1f}ç§’") 
                        logger.info(f"  RTF: {performance_result['current_rtf']:.3f}")
                        logger.info(f"  æ€§èƒ½ç­‰ç´š: {performance_result['performance_tier']}")
                        logger.info(f"  ç›¸æ¯”åŸºæº–æ”¹å–„: {performance_result['improvement_percent']:.1f}%")
                        logger.info(f"  ç‹€æ…‹: {performance_result['status']}")
                        
                        # å¦‚æœæ€§èƒ½ä½æ–¼é æœŸï¼Œè¨˜éŒ„è­¦å‘Š
                        if performance_result['current_rtf'] > 0.2:
                            logger.warning(f"RTF {performance_result['current_rtf']:.3f} é«˜æ–¼æœ€ä½³ç›®æ¨™ 0.2")
                            
                except ImportError:
                    # åŸºæœ¬æ€§èƒ½å ±å‘Šï¼ˆæ²’æœ‰FP16ç®¡ç†å™¨æ™‚ï¼‰
                    rtf = processing_time / audio_duration if audio_duration > 0 else float('inf')
                    logger.info(f"è™•ç†å®Œæˆ - æ™‚é–“: {processing_time:.1f}ç§’, RTF: {rtf:.3f}")
                
                if progress_callback:
                    progress_callback(100, "å­—å¹•ç”Ÿæˆå®Œæˆï¼")
                logger.info(f"å­—å¹•ä¿å­˜æˆåŠŸ: {output_file}")
                return True
            else:
                logger.error("å­—å¹•ä¿å­˜å¤±æ•—")
                if progress_callback:
                    progress_callback(0, "å­—å¹•ä¿å­˜å¤±æ•—")
                return False
                
        except MemoryError as e:
            logger.error(f"è¨˜æ†¶é«”ä¸è¶³: {e}")
            if progress_callback:
                progress_callback(0, "éŒ¯èª¤ï¼šè¨˜æ†¶é«”ä¸è¶³ï¼Œè«‹å˜—è©¦ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹æˆ–è™•ç†è¼ƒçŸ­çš„æ–‡ä»¶")
            return False
        except FileNotFoundError as e:
            logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
            if progress_callback:
                progress_callback(0, f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {input_file}")
            return False
        except PermissionError as e:
            logger.error(f"æ¬Šé™éŒ¯èª¤: {e}")
            if progress_callback:
                progress_callback(0, "éŒ¯èª¤ï¼šæ²’æœ‰æ¬Šé™è¨ªå•æ–‡ä»¶ï¼Œè«‹æª¢æŸ¥æ–‡ä»¶æ¬Šé™")
            return False
        except Exception as e:
            error_type = type(e).__name__
            logger.error(f"å­—å¹•ç”Ÿæˆå¤±æ•— ({error_type}): {e}")
            if progress_callback:
                # æä¾›æ›´å‹å¥½çš„éŒ¯èª¤ä¿¡æ¯
                if "CUDA" in str(e) or "GPU" in str(e):
                    progress_callback(0, "éŒ¯èª¤ï¼šGPU è™•ç†å¤±æ•—ï¼Œè«‹å˜—è©¦ä½¿ç”¨ CPU æ¨¡å¼")
                elif "codec" in str(e).lower() or "decode" in str(e).lower():
                    progress_callback(0, "éŒ¯èª¤ï¼šç„¡æ³•è§£ç¢¼éŸ³é »æ–‡ä»¶ï¼Œè«‹æª¢æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æ´")
                elif "model" in str(e).lower():
                    progress_callback(0, "éŒ¯èª¤ï¼šæ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´")
                else:
                    progress_callback(0, f"ç”Ÿæˆå¤±æ•—: {str(e)}")
            return False
    
    def _generate_translated_subtitle(self, input_file: str, target_language: str, model_params: dict, existing_segments: list = None) -> list:
        """ä½¿ç”¨ Whisper ç”Ÿæˆç›®æ¨™èªè¨€å­—å¹•ä¸¦é€²è¡Œç¹ç°¡è½‰æ›"""
        try:
            # å¦‚æœç›®æ¨™èªè¨€æ˜¯è‹±æ–‡ï¼Œä½¿ç”¨ Whisper çš„ç¿»è­¯ä»»å‹™
            if target_language == 'en':
                task = "translate"
                language = None  # è‡ªå‹•æª¢æ¸¬åŸèªè¨€
                logger.info("ä½¿ç”¨ Whisper ç¿»è­¯ä»»å‹™ç”Ÿæˆè‹±æ–‡å­—å¹•")
                
                # ä½¿ç”¨ Whisper è™•ç†éŸ³é »
                segments, info = self.model.transcribe(
                    input_file,
                    task=task,
                    language=language,
                    beam_size=model_params["beam_size"],
                    best_of=model_params["best_of"],
                    temperature=model_params["temperature"],
                    compression_ratio_threshold=2.0,
                    log_prob_threshold=-0.7,
                    no_speech_threshold=0.4,
                    condition_on_previous_text=True,
                    suppress_blank=True,
                    suppress_tokens=[-1],
                    word_timestamps=True,
                    vad_filter=True,
                    vad_parameters={
                        "threshold": 0.3,
                        "min_speech_duration_ms": 150,
                        "max_speech_duration_s": float("inf"),
                        "min_silence_duration_ms": 800,
                        "speech_pad_ms": 250
                    }
                )
                
                # æ”¶é›†è™•ç†å¾Œçš„æ®µè½
                processed_segments = []
                for segment in segments:
                    text = segment.text.strip()
                    if text:
                        segment_data = {
                            'start': segment.start,
                            'end': segment.end,
                            'text': text
                        }
                        
                        # å¦‚æœæœ‰è©ç´šæ™‚é–“æˆ³ï¼Œæ·»åŠ åˆ°æ®µè½æ•¸æ“šä¸­
                        if hasattr(segment, 'words') and segment.words:
                            segment_data['words'] = [
                                {
                                    'start': word.start,
                                    'end': word.end,
                                    'word': word.word,
                                    'probability': getattr(word, 'probability', 1.0)
                                } for word in segment.words
                            ]
                        
                        processed_segments.append(segment_data)
                
                logger.info(f"Whisper è‹±æ–‡ç¿»è­¯å®Œæˆï¼Œå…± {len(processed_segments)} å€‹æ®µè½")
                return processed_segments
                
            # å°æ–¼ä¸­æ–‡ç¹ç°¡è½‰æ›ï¼Œå…ˆç”Ÿæˆç¹é«”ï¼Œç„¶å¾Œè½‰æ›
            elif target_language in ['zh-TW', 'zh-CN']:
                # å¦‚æœæœ‰ç¾æœ‰æ®µè½ï¼Œç›´æ¥é‡ç”¨ä¸¦é€²è¡Œè½‰æ›
                if existing_segments:
                    logger.info(f"é‡ç”¨ç¾æœ‰æ®µè½é€²è¡Œ {target_language} è½‰æ›ï¼Œä¿ç•™æ™‚é–“æˆ³ä¿®æ­£")
                    processed_segments = []
                    for segment in existing_segments:
                        text = segment.get('text', '').strip()
                        if text:
                            # é€²è¡Œç¹ç°¡è½‰æ›
                            if target_language == 'zh-CN':
                                text = self._convert_to_simplified(text)
                            elif target_language == 'zh-TW':
                                text = self._convert_to_traditional(text)
                            
                            # ä¿ç•™åŸå§‹æ®µè½çš„æ‰€æœ‰ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¿®æ­£çš„æ™‚é–“æˆ³
                            segment_data = segment.copy()
                            segment_data['text'] = text
                            processed_segments.append(segment_data)
                    
                    logger.info(f"ä¸­æ–‡å­—å¹•è½‰æ›å®Œæˆï¼Œä¿ç•™ {len(processed_segments)} å€‹æ®µè½çš„æ™‚é–“æˆ³ä¿®æ­£")
                    return processed_segments
                else:
                    # æ²’æœ‰ç¾æœ‰æ®µè½æ™‚ï¼Œé‡æ–°è½‰éŒ„
                    segments, info = self.model.transcribe(
                        input_file,
                        task="transcribe",
                        language='zh',
                        beam_size=model_params["beam_size"],
                        best_of=model_params["best_of"],
                        temperature=model_params["temperature"],
                        compression_ratio_threshold=2.0,
                        log_prob_threshold=-0.7,
                        no_speech_threshold=0.4,
                        condition_on_previous_text=True,
                        suppress_blank=True,
                        suppress_tokens=[-1],
                        word_timestamps=True,
                        vad_filter=True,
                        vad_parameters={
                            "threshold": 0.3,
                            "min_speech_duration_ms": 150,
                            "max_speech_duration_s": float("inf"),
                            "min_silence_duration_ms": 800,
                            "speech_pad_ms": 250
                        }
                    )
                    
                    # æ”¶é›†æ®µè½ä¸¦é€²è¡Œç¹ç°¡è½‰æ›
                    processed_segments = []
                    for segment in segments:
                        text = segment.text.strip()
                        if text:
                            # é€²è¡Œç¹ç°¡è½‰æ›
                            if target_language == 'zh-CN':
                                text = self._convert_to_simplified(text)
                            elif target_language == 'zh-TW':
                                text = self._convert_to_traditional(text)
                            
                            segment_data = {
                                'start': segment.start,
                                'end': segment.end,
                                'text': text
                            }
                        
                        # å¦‚æœæœ‰è©ç´šæ™‚é–“æˆ³ï¼Œæ·»åŠ åˆ°æ®µè½æ•¸æ“šä¸­
                        if hasattr(segment, 'words') and segment.words:
                            segment_data['words'] = [
                                {
                                    'start': word.start,
                                    'end': word.end,
                                    'word': word.word,
                                    'probability': getattr(word, 'probability', 1.0)
                                } for word in segment.words
                            ]
                        
                        processed_segments.append(segment_data)
                
                logger.info(f"ä¸­æ–‡å­—å¹•ç”Ÿæˆä¸¦è½‰æ›å®Œæˆï¼Œå…± {len(processed_segments)} å€‹æ®µè½")
                return processed_segments
            
            # å°æ–¼å…¶ä»–èªè¨€ï¼Œä¿æŒåŸæœ‰é‚è¼¯
            else:
                # Whisper èªè¨€ä»£ç¢¼æ˜ å°„
                whisper_lang_map = {
                    'ja': 'ja', 
                    'ko': 'ko',
                    'es': 'es',
                    'fr': 'fr',
                    'de': 'de',
                    'it': 'it',
                    'pt': 'pt',
                    'ru': 'ru',
                    'ar': 'ar'
                }
                
                whisper_target_lang = whisper_lang_map.get(target_language, 'en')
                
                # ä½¿ç”¨è½‰éŒ„ä»»å‹™ä¸¦æŒ‡å®šç›®æ¨™èªè¨€
                segments, info = self.model.transcribe(
                    input_file,
                    task="transcribe",
                    language=whisper_target_lang,
                    beam_size=model_params["beam_size"],
                    best_of=model_params["best_of"],
                    temperature=model_params["temperature"],
                    compression_ratio_threshold=2.0,
                    log_prob_threshold=-0.7,
                    no_speech_threshold=0.4,
                    condition_on_previous_text=True,
                    suppress_blank=True,
                    suppress_tokens=[-1],
                    word_timestamps=True,
                    vad_filter=True,
                    vad_parameters={
                        "threshold": 0.3,
                        "min_speech_duration_ms": 150,
                        "max_speech_duration_s": float("inf"),
                        "min_silence_duration_ms": 800,
                        "speech_pad_ms": 250
                    }
                )
                
                # æ”¶é›†è™•ç†å¾Œçš„æ®µè½
                processed_segments = []
                for segment in segments:
                    text = segment.text.strip()
                    if text:
                        segment_data = {
                            'start': segment.start,
                            'end': segment.end,
                            'text': text
                        }
                        
                        # å¦‚æœæœ‰è©ç´šæ™‚é–“æˆ³ï¼Œæ·»åŠ åˆ°æ®µè½æ•¸æ“šä¸­
                        if hasattr(segment, 'words') and segment.words:
                            segment_data['words'] = [
                                {
                                    'start': word.start,
                                    'end': word.end,
                                    'word': word.word,
                                    'probability': getattr(word, 'probability', 1.0)
                                } for word in segment.words
                            ]
                        
                        processed_segments.append(segment_data)
                
                logger.info(f"Whisper å¤šèªè¨€è™•ç†å®Œæˆï¼Œå…± {len(processed_segments)} å€‹æ®µè½")
                return processed_segments
            
        except Exception as e:
            logger.error(f"Whisper å¤šèªè¨€è™•ç†å¤±æ•—: {e}")
            raise e
    
    def _convert_to_simplified(self, text: str) -> str:
        """Convert text to Simplified Chinese (handles mixed traditional/simplified text)"""
        try:
            # Try using opencc first (if available)
            try:
                import opencc
                # Use t2s converter which handles mixed text well
                converter = opencc.OpenCC('t2s')  # Traditional to Simplified
                simplified_text = converter.convert(text)
                
                logger.debug(f"ç°¡é«”è½‰æ›: '{text}' -> '{simplified_text}'")
                return simplified_text
            except ImportError:
                # Fallback to basic character mapping
                logger.info("OpenCC ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºæœ¬å­—ç¬¦æ˜ å°„é€²è¡Œç°¡é«”è½‰æ›")
                return self._basic_traditional_to_simplified(text)
        except Exception as e:
            logger.warning(f"ç°¡é«”è½‰æ›å¤±æ•—ï¼Œè¿”å›åŸæ–‡: {e}")
            return text
    
    def _convert_to_traditional(self, text: str) -> str:
        """Convert text to Traditional Chinese (handles mixed simplified/traditional text)"""
        try:
            # Try using opencc first (if available)
            try:
                import opencc
                # First normalize any traditional to simplified, then convert to traditional
                # This ensures consistent conversion of mixed text
                t2s_converter = opencc.OpenCC('t2s')  # Traditional to Simplified first
                s2t_converter = opencc.OpenCC('s2t')  # Then Simplified to Traditional
                
                normalized_text = t2s_converter.convert(text)  # Normalize to simplified first
                traditional_text = s2t_converter.convert(normalized_text)  # Convert to traditional
                
                logger.debug(f"ä¸­æ–‡è½‰æ›: '{text}' -> è¦ç¯„åŒ–: '{normalized_text}' -> ç¹é«”: '{traditional_text}'")
                return traditional_text
            except ImportError:
                # Fallback to basic character mapping with normalization
                logger.info("OpenCC ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºæœ¬å­—ç¬¦æ˜ å°„é€²è¡Œç¹é«”è½‰æ›")
                return self._basic_convert_to_traditional_robust(text)
        except Exception as e:
            logger.warning(f"ç¹é«”è½‰æ›å¤±æ•—ï¼Œè¿”å›åŸæ–‡: {e}")
            return text
    
    def _basic_traditional_to_simplified(self, text: str) -> str:
        """Basic Traditional to Simplified Chinese conversion using common character mappings"""
        # Common Traditional to Simplified mappings
        t2s_map = {
            'å€‹': 'ä¸ª', 'ä¾†': 'æ¥', 'å°': 'å¯¹', 'æœƒ': 'ä¼š', 'æ™‚': 'æ—¶', 'åœ‹': 'å›½',
            'å­¸': 'å­¦', 'èªª': 'è¯´', 'é–‹': 'å¼€', 'é—œ': 'å…³', 'é–€': 'é—¨', 'å•': 'é—®',
            'é¡Œ': 'é¢˜', 'ç¾': 'ç°', 'ç™¼': 'å‘', 'å¾Œ': 'å', 'é•·': 'é•¿', 'ç¶“': 'ç»',
            'é': 'è¿‡', 'é‚„': 'è¿˜', 'æ²’': 'æ²¡', 'è¦‹': 'è§', 'è½': 'å¬', 'è¦º': 'è§‰',
            'æ‡‰': 'åº”', 'è©²': 'è¯¥', 'é»': 'ç‚¹', 'ç·š': 'çº¿', 'é‚Š': 'è¾¹', 'é–“': 'é—´',
            'å…§': 'å†…', 'ç¶²': 'ç½‘', 'é›»': 'ç”µ', 'è©±': 'è¯', 'æ©Ÿ': 'æœº', 'è»Š': 'è½¦',
            'å‹•': 'åŠ¨', 'é‹': 'è¿', 'é€²': 'è¿›', 'é ': 'è¿œ', 'å ´': 'åœº', 'åœ’': 'å›­',
            'æ¥­': 'ä¸š', 'å‹™': 'åŠ¡', 'å“¡': 'å‘˜', 'å“¡': 'å‘˜', 'ç´š': 'çº§', 'åƒ¹': 'ä»·',
            'è²·': 'ä¹°', 'è³£': 'å–', 'éŒ¢': 'é’±', 'éŠ€': 'é“¶', 'è¡Œ': 'è¡Œ', 'è™•': 'å¤„',
            'è¾¦': 'åŠ', 'ç¸½': 'æ€»', 'é¸': 'é€‰', 'æ“‡': 'æ‹©', 'æ±º': 'å†³', 'è­°': 'è®®',
            'è¨': 'è®¨', 'è«–': 'è®º', 'èª': 'è®¤', 'è­˜': 'è¯†', 'è¨˜': 'è®°', 'éŒ„': 'å½•',
            'æ›¸': 'ä¹¦', 'å ±': 'æŠ¥', 'ç´™': 'çº¸', 'é›œ': 'æ‚', 'èªŒ': 'å¿—', 'å»£': 'å¹¿',
            'å‘Š': 'å‘Š', 'è¦–': 'è§†', 'è²': 'å£°', 'éŸ¿': 'å“', 'æ¨‚': 'ä¹', 'æ­Œ': 'æ­Œ',
            'åŠ‡': 'å‰§', 'æˆ²': 'æˆ', 'å½±': 'å½±', 'ç•«': 'ç”»', 'åœ–': 'å›¾', 'æ¨™': 'æ ‡',
            'æº–': 'å‡†', 'è¦': 'è§„', 'å‰‡': 'åˆ™', 'æ³•': 'æ³•', 'å¾‹': 'å¾‹', 'æ¢': 'æ¡',
            'ç´„': 'çº¦', 'éš›': 'é™…', 'é–“': 'é—´', 'ä¿‚': 'ç³»', 'é—œ': 'å…³', 'è¯': 'è”',
            'çµ': 'ç»“', 'æ§‹': 'æ„', 'å»º': 'å»º', 'è¨­': 'è®¾', 'è¨ˆ': 'è®¡', 'åŠƒ': 'åˆ’',
            'ç¨®': 'ç§', 'é¡': 'ç±»', 'æ¨£': 'æ ·', 'è®Š': 'å˜', 'åŒ–': 'åŒ–', 'çµ±': 'ç»Ÿ',
            'å‚³': 'ä¼ ', 'è¼¸': 'è¾“', 'å°': 'å¯¼', 'é ˜': 'é¢†', 'å¸¶': 'å¸¦', 'éšŠ': 'é˜Ÿ',
            'åœ˜': 'å›¢', 'çµ„': 'ç»„', 'ç¹”': 'ç»‡', 'åƒ': 'å‚', 'èˆ‡': 'ä¸', 'å”': 'å',
            'èª¿': 'è°ƒ', 'ç¯€': 'èŠ‚', 'åˆ¶': 'åˆ¶', 'é€ ': 'é€ ', 'ç”¢': 'äº§', 'å“': 'å“',
            'è³ª': 'è´¨', 'é‡': 'é‡', 'æ•¸': 'æ•°', 'æ“š': 'æ®', 'è³‡': 'èµ„', 'æ–™': 'æ–™',
            'è¨Š': 'è®¯', 'æ¯': 'æ¯', 'å…§': 'å†…', 'å®¹': 'å®¹', 'æ ¼': 'æ ¼', 'å¼': 'å¼',
            'æª”': 'æ¡£', 'æ¡ˆ': 'æ¡ˆ', 'å¤¾': 'å¤¹', 'å±¤': 'å±‚', 'ç´š': 'çº§', 'åˆ¥': 'åˆ«',
            'é¡': 'ç±»', 'é …': 'é¡¹', 'ç›®': 'ç›®', 'å–®': 'å•', 'é …': 'é¡¹', 'æ¢': 'æ¡',
            'ä¾‹': 'ä¾‹', 'æ¨£': 'æ ·', 'æœ¬': 'æœ¬', 'ç‰ˆ': 'ç‰ˆ', 'è™Ÿ': 'å·', 'ç¢¼': 'ç ',
            'ç·¨': 'ç¼–', 'è¼¯': 'è¾‘', 'è£½': 'åˆ¶', 'ä½œ': 'ä½œ', 'å‰µ': 'åˆ›', 'é€ ': 'é€ ',
            'è¨­': 'è®¾', 'è¨ˆ': 'è®¡', 'ç•«': 'ç”»', 'åŠƒ': 'åˆ’', 'å‚™': 'å¤‡', 'æº–': 'å‡†',
            'ç¢º': 'ç¡®', 'èª': 'è®¤', 'è­‰': 'è¯', 'å¯¦': 'å®', 'ç¾': 'ç°', 'é”': 'è¾¾',
            'åˆ°': 'åˆ°', 'ç²': 'è·', 'å¾—': 'å¾—', 'å–': 'å–', 'çµ¦': 'ç»™', 'èˆ‡': 'ä¸',
            'ä¾›': 'ä¾›', 'æ': 'æ', 'äº¤': 'äº¤', 'ä»˜': 'ä»˜', 'æ”¶': 'æ”¶', 'ç´': 'çº³',
            'æ¥': 'æ¥', 'å—': 'å—', 'è™•': 'å¤„', 'ç†': 'ç†', 'è¾¦': 'åŠ', 'äº‹': 'äº‹',
            'é …': 'é¡¹', 'å‹™': 'åŠ¡', 'æœ': 'æœ', 'å‹™': 'åŠ¡', 'æ¥­': 'ä¸š', 'è·': 'èŒ',
            'æ¥­': 'ä¸š', 'å°ˆ': 'ä¸“', 'æ¥­': 'ä¸š', 'èª²': 'è¯¾', 'ç¨‹': 'ç¨‹', 'è¨“': 'è®­',
            'ç·´': 'ç»ƒ', 'ç¿’': 'ä¹ ', 'å­¸': 'å­¦', 'ç¿’': 'ä¹ ', 'æ•™': 'æ•™', 'è‚²': 'è‚²',
            'å¸«': 'å¸ˆ', 'è³‡': 'èµ„', 'è¨Š': 'è®¯', 'æ¯': 'æ¯', 'çŸ¥': 'çŸ¥', 'è­˜': 'è¯†',
            'ç¶“': 'ç»', 'é©—': 'éªŒ', 'æŠ€': 'æŠ€', 'è¡“': 'æœ¯', 'èƒ½': 'èƒ½', 'åŠ›': 'åŠ›',
            'æ°£': 'æ°”', 'è³ª': 'è´¨', 'å€‹': 'ä¸ª', 'æ€§': 'æ€§', 'ç‰¹': 'ç‰¹', 'è‰²': 'è‰²'
        }
        
        result = text
        for trad, simp in t2s_map.items():
            result = result.replace(trad, simp)
        
        return result
    
    def _basic_simplified_to_traditional(self, text: str) -> str:
        """Basic Simplified to Traditional Chinese conversion using common character mappings"""
        # Common Simplified to Traditional mappings (reverse of above)
        s2t_map = {
            'ä¸ª': 'å€‹', 'æ¥': 'ä¾†', 'å¯¹': 'å°', 'ä¼š': 'æœƒ', 'æ—¶': 'æ™‚', 'å›½': 'åœ‹',
            'å­¦': 'å­¸', 'è¯´': 'èªª', 'å¼€': 'é–‹', 'å…³': 'é—œ', 'é—¨': 'é–€', 'é—®': 'å•',
            'é¢˜': 'é¡Œ', 'ç°': 'ç¾', 'å‘': 'ç™¼', 'å': 'å¾Œ', 'é•¿': 'é•·', 'ç»': 'ç¶“',
            'è¿‡': 'é', 'è¿˜': 'é‚„', 'æ²¡': 'æ²’', 'è§': 'è¦‹', 'å¬': 'è½', 'è§‰': 'è¦º',
            'åº”': 'æ‡‰', 'è¯¥': 'è©²', 'ç‚¹': 'é»', 'çº¿': 'ç·š', 'è¾¹': 'é‚Š', 'é—´': 'é–“',
            'å†…': 'å…§', 'ç½‘': 'ç¶²', 'ç”µ': 'é›»', 'è¯': 'è©±', 'æœº': 'æ©Ÿ', 'è½¦': 'è»Š',
            'åŠ¨': 'å‹•', 'è¿': 'é‹', 'è¿›': 'é€²', 'è¿œ': 'é ', 'åœº': 'å ´', 'å›­': 'åœ’',
            'ä¸š': 'æ¥­', 'åŠ¡': 'å‹™', 'å‘˜': 'å“¡', 'çº§': 'ç´š', 'ä»·': 'åƒ¹',
            'ä¹°': 'è²·', 'å–': 'è³£', 'é’±': 'éŒ¢', 'é“¶': 'éŠ€', 'å¤„': 'è™•',
            'åŠ': 'è¾¦', 'æ€»': 'ç¸½', 'é€‰': 'é¸', 'æ‹©': 'æ“‡', 'å†³': 'æ±º', 'è®®': 'è­°',
            'è®¨': 'è¨', 'è®º': 'è«–', 'è®¤': 'èª', 'è¯†': 'è­˜', 'è®°': 'è¨˜', 'å½•': 'éŒ„',
            'ä¹¦': 'æ›¸', 'æŠ¥': 'å ±', 'çº¸': 'ç´™', 'æ‚': 'é›œ', 'å¿—': 'èªŒ', 'å¹¿': 'å»£',
            'è§†': 'è¦–', 'å£°': 'è²', 'å“': 'éŸ¿', 'ä¹': 'æ¨‚',
            'å‰§': 'åŠ‡', 'æˆ': 'æˆ²', 'ç”»': 'ç•«', 'å›¾': 'åœ–', 'æ ‡': 'æ¨™',
            'å‡†': 'æº–', 'è§„': 'è¦', 'åˆ™': 'å‰‡', 'æ¡': 'æ¢',
            'çº¦': 'ç´„', 'é™…': 'éš›', 'ç³»': 'ä¿‚', 'è”': 'è¯',
            'ç»“': 'çµ', 'æ„': 'æ§‹', 'è®¾': 'è¨­', 'è®¡': 'è¨ˆ', 'åˆ’': 'åŠƒ',
            'ç§': 'ç¨®', 'ç±»': 'é¡', 'æ ·': 'æ¨£', 'å˜': 'è®Š', 'ç»Ÿ': 'çµ±',
            'ä¼ ': 'å‚³', 'è¾“': 'è¼¸', 'å¯¼': 'å°', 'é¢†': 'é ˜', 'å¸¦': 'å¸¶', 'é˜Ÿ': 'éšŠ',
            'å›¢': 'åœ˜', 'ç»„': 'çµ„', 'ç»‡': 'ç¹”', 'å‚': 'åƒ', 'ä¸': 'èˆ‡', 'å': 'å”',
            'è°ƒ': 'èª¿', 'èŠ‚': 'ç¯€', 'åˆ¶': 'åˆ¶', 'äº§': 'ç”¢',
            'è´¨': 'è³ª', 'æ•°': 'æ•¸', 'æ®': 'æ“š', 'èµ„': 'è³‡',
            'è®¯': 'è¨Š', 'æ¡£': 'æª”', 'å¤¹': 'å¤¾', 'å±‚': 'å±¤', 'åˆ«': 'åˆ¥',
            'é¡¹': 'é …', 'å•': 'å–®', 'æ¡': 'æ¢',
            'å·': 'è™Ÿ', 'ç ': 'ç¢¼',
            'ç¼–': 'ç·¨', 'è¾‘': 'è¼¯', 'åˆ¶': 'è£½', 'åˆ›': 'å‰µ',
            'è®¾': 'è¨­', 'è®¡': 'è¨ˆ', 'ç”»': 'ç•«', 'åˆ’': 'åŠƒ', 'å¤‡': 'å‚™', 'å‡†': 'æº–',
            'ç¡®': 'ç¢º', 'è®¤': 'èª', 'è¯': 'è­‰', 'å®': 'å¯¦', 'ç°': 'ç¾', 'è¾¾': 'é”',
            'è·': 'ç²', 'ç»™': 'çµ¦',
            'çº³': 'ç´', 'å¤„': 'è™•', 'åŠ': 'è¾¦', 'é¡¹': 'é …', 'åŠ¡': 'å‹™',
            'èŒ': 'è·', 'ä¸“': 'å°ˆ', 'è¯¾': 'èª²', 'è®­': 'è¨“',
            'ç»ƒ': 'ç·´', 'ä¹ ': 'ç¿’', 'å¸ˆ': 'å¸«', 'èµ„': 'è³‡', 'è®¯': 'è¨Š', 'è¯†': 'è­˜',
            'ç»': 'ç¶“', 'éªŒ': 'é©—', 'æœ¯': 'è¡“',
            'æ°”': 'æ°£', 'è´¨': 'è³ª', 'ä¸ª': 'å€‹'
        }
        
        result = text
        for simp, trad in s2t_map.items():
            result = result.replace(simp, trad)
        
        return result
    
    def _basic_convert_to_traditional_robust(self, text: str) -> str:
        """Robust basic conversion to Traditional Chinese with normalization"""
        # Step 1: First normalize any traditional to simplified using reverse mapping
        normalized_text = text
        
        # Traditional to Simplified normalization mapping (for mixed text handling)
        t2s_normalize = {
            'å€‹': 'ä¸ª', 'ä¾†': 'æ¥', 'å°': 'å¯¹', 'æœƒ': 'ä¼š', 'æ™‚': 'æ—¶', 'åœ‹': 'å›½',
            'å­¸': 'å­¦', 'èªª': 'è¯´', 'é–‹': 'å¼€', 'é—œ': 'å…³', 'é–€': 'é—¨', 'å•': 'é—®',
            'é¡Œ': 'é¢˜', 'ç¾': 'ç°', 'ç™¼': 'å‘', 'å¾Œ': 'å', 'é•·': 'é•¿', 'ç¶“': 'ç»',
            'é': 'è¿‡', 'é‚„': 'è¿˜', 'æ²’': 'æ²¡', 'è¦‹': 'è§', 'è½': 'å¬', 'è¦º': 'è§‰',
            'æ‡‰': 'åº”', 'è©²': 'è¯¥', 'é»': 'ç‚¹', 'ç·š': 'çº¿', 'é‚Š': 'è¾¹', 'é–“': 'é—´',
            'å…§': 'å†…', 'ç¶²': 'ç½‘', 'é›»': 'ç”µ', 'è©±': 'è¯', 'æ©Ÿ': 'æœº', 'è»Š': 'è½¦',
            'å‹•': 'åŠ¨', 'é‹': 'è¿', 'é€²': 'è¿›', 'é ': 'è¿œ', 'å ´': 'åœº', 'åœ’': 'å›­',
            'æ¥­': 'ä¸š', 'å‹™': 'åŠ¡', 'å“¡': 'å‘˜', 'ç´š': 'çº§', 'åƒ¹': 'ä»·', 'è²·': 'ä¹°', 
            'è³£': 'å–', 'éŒ¢': 'é’±', 'éŠ€': 'é“¶', 'è™•': 'å¤„', 'è¾¦': 'åŠ', 'ç¸½': 'æ€»', 
            'é¸': 'é€‰', 'æ“‡': 'æ‹©', 'æ±º': 'å†³', 'è­°': 'è®®', 'è¨': 'è®¨', 'è«–': 'è®º', 
            'èª': 'è®¤', 'è­˜': 'è¯†', 'è¨˜': 'è®°', 'éŒ„': 'å½•', 'æ›¸': 'ä¹¦', 'å ±': 'æŠ¥', 
            'ç´™': 'çº¸', 'é›œ': 'æ‚', 'èªŒ': 'å¿—', 'å»£': 'å¹¿', 'è¦–': 'è§†', 'è²': 'å£°', 
            'éŸ¿': 'å“', 'æ¨‚': 'ä¹', 'åŠ‡': 'å‰§', 'æˆ²': 'æˆ', 'ç•«': 'ç”»', 'åœ–': 'å›¾', 
            'æ¨™': 'æ ‡', 'æº–': 'å‡†', 'è¦': 'è§„', 'å‰‡': 'åˆ™', 'æ¢': 'æ¡', 'ç´„': 'çº¦', 
            'éš›': 'é™…', 'ä¿‚': 'ç³»', 'é—œ': 'å…³', 'è¯': 'è”', 'çµ': 'ç»“', 'æ§‹': 'æ„', 
            'è¨­': 'è®¾', 'è¨ˆ': 'è®¡', 'åŠƒ': 'åˆ’', 'ç¨®': 'ç§', 'é¡': 'ç±»', 'æ¨£': 'æ ·', 
            'è®Š': 'å˜', 'çµ±': 'ç»Ÿ', 'å‚³': 'ä¼ ', 'è¼¸': 'è¾“', 'å°': 'å¯¼', 'é ˜': 'é¢†', 
            'å¸¶': 'å¸¦', 'éšŠ': 'é˜Ÿ', 'åœ˜': 'å›¢', 'çµ„': 'ç»„', 'ç¹”': 'ç»‡', 'åƒ': 'å‚', 
            'èˆ‡': 'ä¸', 'å”': 'å', 'èª¿': 'è°ƒ', 'ç¯€': 'èŠ‚', 'ç”¢': 'äº§', 'è³ª': 'è´¨', 
            'æ•¸': 'æ•°', 'æ“š': 'æ®', 'è³‡': 'èµ„', 'è¨Š': 'è®¯', 'æª”': 'æ¡£', 'å¤¾': 'å¤¹', 
            'å±¤': 'å±‚', 'åˆ¥': 'åˆ«', 'é …': 'é¡¹', 'å–®': 'å•', 'è™Ÿ': 'å·', 'ç¢¼': 'ç ', 
            'ç·¨': 'ç¼–', 'è¼¯': 'è¾‘', 'è£½': 'åˆ¶', 'å‰µ': 'åˆ›', 'è¨­': 'è®¾', 'ç•«': 'ç”»', 
            'åŠƒ': 'åˆ’', 'å‚™': 'å¤‡', 'ç¢º': 'ç¡®', 'è­‰': 'è¯', 'å¯¦': 'å®', 'ç¾': 'ç°', 
            'é”': 'è¾¾', 'ç²': 'è·', 'çµ¦': 'ç»™', 'ç´': 'çº³', 'è·': 'èŒ', 'å°ˆ': 'ä¸“', 
            'èª²': 'è¯¾', 'è¨“': 'è®­', 'ç·´': 'ç»ƒ', 'ç¿’': 'ä¹ ', 'å¸«': 'å¸ˆ', 'ç¶“': 'ç»', 
            'é©—': 'éªŒ', 'è¡“': 'æœ¯', 'æ°£': 'æ°”'
        }
        
        # Normalize traditional characters to simplified
        for trad, simp in t2s_normalize.items():
            normalized_text = normalized_text.replace(trad, simp)
        
        # Step 2: Convert simplified to traditional
        result = self._basic_simplified_to_traditional(normalized_text)
        
        logger.debug(f"åŸºæœ¬ç¹é«”è½‰æ›: '{text}' -> è¦ç¯„åŒ–: '{normalized_text}' -> ç¹é«”: '{result}'")
        return result
    
    def _save_subtitle(self, segments: list, output_file: str, format: str) -> bool:
        """ä¿å­˜å­—å¹•æ–‡ä»¶"""
        try:
            from subtitle_formatter import SubtitleFormatter
            return SubtitleFormatter.save_subtitle(segments, output_file, format)
        except Exception as e:
            logger.error(f"ä¿å­˜å­—å¹•å¤±æ•—: {e}")
            return False
    
    def get_supported_formats(self) -> list:
        """ç²å–æ”¯æ´çš„æ ¼å¼"""
        return ["srt", "vtt", "txt"]
    
    def get_supported_models(self) -> list:
        """ç²å–æ”¯æ´çš„æ¨¡å‹"""
        return self.supported_models
    
    def change_model(self, model_size: str, device: str = None, compute_type: str = None) -> bool:
        """å‹•æ…‹æ›´æ›æ¨¡å‹"""
        if model_size not in self.supported_models:
            logger.error(f"ä¸æ”¯æ´çš„æ¨¡å‹å¤§å°: {model_size}")
            return False
        
        # æ¸…ç†èˆŠæ¨¡å‹
        self.cleanup()
        
        # è¨­å®šæ–°åƒæ•¸
        self.model_size = model_size
        if device:
            self.device = device
        if compute_type:
            self.compute_type = compute_type
        
        logger.info(f"åˆ‡æ›åˆ°æ¨¡å‹: {self.model_size}")
        return True
    
    def get_model_info(self) -> dict:
        """ç²å–ç•¶å‰æ¨¡å‹è³‡è¨Š"""
        return {
            "model_size": self.model_size,
            "device": self.device,
            "compute_type": self.compute_type,
            "initialized": self.initialized,
            "parameters": self.model_params.get(self.model_size, {})
        }
    
    def _analyze_subtitle_quality(self, segments: list, progress_callback: Optional[Callable] = None):
        """åˆ†æå­—å¹•è³ªé‡ï¼Œæ¡ç”¨ srt_final-orign çš„å„ªç§€åˆ†ææ–¹æ³•"""
        try:
            if not segments:
                return
            
            # èªéŸ³ç†è§£åº¦åˆ†æ
            understanding_levels = {'high': 0, 'medium': 0, 'low': 0}
            content_issues = []  # éçŸ­å¥å­å’Œå¡«å……è©
            suspicious_issues = []  # èªæ„ç•°å¸¸ç­‰å¯ç–‘å…§å®¹
            pure_uncertainty = []  # æ’é™¤å…§å®¹å•é¡Œå¾Œï¼Œç´”ç²¹çš„æ¨¡å‹ä¸ç¢ºå®š
            all_confidences = []
            
            for i, segment in enumerate(segments):
                text = segment.get('text', '').strip()
                start_time = segment.get('start', 0.0)
                end_time = segment.get('end', 0.0)
                
                # ç²å–ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰è©ç´šè³‡æ–™ï¼‰
                avg_logprob = -0.3  # é è¨­å€¼
                if 'words' in segment and segment['words']:
                    # è¨ˆç®—å¹³å‡å°æ•¸æ¦‚ç‡
                    probabilities = [word.get('probability', 0.8) for word in segment['words']]
                    if probabilities:
                        avg_prob = sum(probabilities) / len(probabilities)
                        avg_logprob = np.log(max(avg_prob, 0.01))  # é¿å… log(0)
                
                # åˆ¤æ–·ç†è§£åº¦ç­‰ç´šï¼ˆæ¡ç”¨ srt_final-orign çš„æ¨™æº–ï¼‰
                if avg_logprob > -0.3:
                    understanding_level = 'high'
                elif avg_logprob > -0.5:
                    understanding_level = 'medium'
                else:
                    understanding_level = 'low'
                
                # å…§å®¹å•é¡Œæª¢æ¸¬
                has_content_issue = False
                issue_type = ""
                
                # æª¢æ¸¬éçŸ­çš„å¥å­
                if len(text) < 3:
                    has_content_issue = True
                    issue_type = "å¥å­éçŸ­"
                
                # æª¢æ¸¬å¸¸è¦‹çš„å¡«å……è©æˆ–å™ªéŸ³
                noise_words = ['å—¯', 'å•Š', 'å‘ƒ', 'é‚£å€‹', 'é€™å€‹', 'å°±æ˜¯', 'ç„¶å¾Œ', 'æ‰€ä»¥']
                if any(word in text for word in noise_words):
                    has_content_issue = True
                    issue_type = "åŒ…å«å¡«å……è©"
                
                # å¯ç–‘å…§å®¹æª¢æ¸¬
                has_suspicious_content = False
                suspicious_reasons = []
                confidence_score = 1.0
                
                if not has_content_issue:
                    # è©å½™é »ç‡åˆ†æ
                    rare_words = ['è…³è†œ', 'è†œéƒ½å¾ˆ', 'éƒ½å¾ˆé€æ˜', 'è†œéƒ½', 'éƒ½å¾ˆ', 'æ·’æ·‹é‹', 'æ·’æ·‹', 'æ·‹é‹']
                    if any(word in text for word in rare_words):
                        has_suspicious_content = True
                        suspicious_reasons.append("åŒ…å«ç½•è¦‹è©å½™")
                        confidence_score *= 0.7
                    
                    # èªç¾©ä¸€è‡´æ€§æª¢æ¸¬
                    if 'éƒ½å¾ˆ' in text and len(text) < 12:
                        if any(char in text for char in ['è†œ', 'é€', 'æ˜']):
                            has_suspicious_content = True
                            suspicious_reasons.append("èªç¾©æ­é…ç•°å¸¸")
                            confidence_score *= 0.6
                    
                    # é‡è¤‡æ¨¡å¼æª¢æ¸¬
                    if len(text) > 3:
                        char_count = {}
                        for char in text:
                            char_count[char] = char_count.get(char, 0) + 1
                        max_repeat = max(char_count.values())
                        if max_repeat > len(text) * 0.4:
                            has_suspicious_content = True
                            suspicious_reasons.append("å­—ç¬¦é‡è¤‡éå¤š")
                            confidence_score *= 0.5
                    
                    # ç¶œåˆåˆç†æ€§åˆ¤æ–·
                    if confidence_score < 0.6:
                        has_suspicious_content = True
                        if "ç¶œåˆåˆ†æ•¸éä½" not in suspicious_reasons:
                            suspicious_reasons.append(f"ç¶œåˆåˆ†æ•¸éä½({confidence_score:.2f})")
                
                # åˆ†é¡å•é¡Œç‰‡æ®µ
                if has_content_issue:
                    content_issues.append({
                        "id": i + 1,
                        "text": text,
                        "avg_logprob": avg_logprob,
                        "understanding_level": understanding_level,
                        "issue_type": issue_type,
                        "start": start_time,
                        "end": end_time
                    })
                elif has_suspicious_content:
                    suspicious_issues.append({
                        "id": i + 1,
                        "text": text,
                        "avg_logprob": avg_logprob,
                        "understanding_level": understanding_level,
                        "issue_type": f"å¯ç–‘å…§å®¹({', '.join(suspicious_reasons)})",
                        "start": start_time,
                        "end": end_time
                    })
                elif understanding_level == 'low':
                    pure_uncertainty.append({
                        "id": i + 1,
                        "text": text,
                        "avg_logprob": avg_logprob,
                        "understanding_level": understanding_level,
                        "start": start_time,
                        "end": end_time
                    })
                
                understanding_levels[understanding_level] += 1
                all_confidences.append(avg_logprob)
            
            # é¡¯ç¤ºç†è§£åº¦çµ±è¨ˆä¿¡æ¯
            if all_confidences:
                min_conf = min(all_confidences)
                max_conf = max(all_confidences)
                avg_conf = sum(all_confidences) / len(all_confidences)
                logger.info("=== èªéŸ³ç†è§£åº¦åˆ†æ ===")
                logger.info(f"ç†è§£åº¦çµ±è¨ˆ: é«˜ç†è§£åº¦={understanding_levels['high']}å€‹, ä¸­ç†è§£åº¦={understanding_levels['medium']}å€‹, ä½ç†è§£åº¦={understanding_levels['low']}å€‹")
                logger.info(f"avg_logprobç¯„åœ: {min_conf:.3f} ~ {max_conf:.3f}, å¹³å‡å€¼={avg_conf:.3f}")
            
            # é¡¯ç¤ºå„ç¨®å•é¡Œç‰‡æ®µ
            logger.warning("=== å­—å¹•å“è³ªåˆ†æå ±å‘Š ===")
            
            # é¡¯ç¤ºå…§å®¹å•é¡Œ
            if content_issues:
                logger.warning(f"ç™¼ç¾ {len(content_issues)} å€‹å…§å®¹å•é¡Œç‰‡æ®µ")
                logger.warning("å…§å®¹å•é¡Œå‰5å€‹:")
                for i, seg in enumerate(content_issues[:5]):
                    start_time = self._format_time(seg["start"])
                    end_time = self._format_time(seg["end"])
                    logger.warning(f"  {i+1}. [{start_time} --> {end_time}] å•é¡Œ: {seg['issue_type']}")
                    logger.warning(f"     è­˜åˆ¥çµæœ: {seg['text']}")
            else:
                logger.info("æ²’æœ‰ç™¼ç¾å…§å®¹å•é¡Œç‰‡æ®µ")
            
            # é¡¯ç¤ºå¯ç–‘å…§å®¹
            if suspicious_issues:
                logger.warning(f"ç™¼ç¾ {len(suspicious_issues)} å€‹å¯ç–‘å…§å®¹ç‰‡æ®µ")
                logger.warning("å¯ç–‘å…§å®¹å‰5å€‹:")
                for i, seg in enumerate(suspicious_issues[:5]):
                    start_time = self._format_time(seg["start"])
                    end_time = self._format_time(seg["end"])
                    logger.warning(f"  {i+1}. [{start_time} --> {end_time}] å•é¡Œ: {seg['issue_type']}")
                    logger.warning(f"     è­˜åˆ¥çµæœ: {seg['text']}")
            else:
                logger.info("æ²’æœ‰ç™¼ç¾å¯ç–‘å…§å®¹ç‰‡æ®µ")
            
            # é¡¯ç¤ºç´”ç²¹çš„æ¨¡å‹ä¸ç¢ºå®šç‰‡æ®µ
            if pure_uncertainty:
                logger.warning(f"ç™¼ç¾ {len(pure_uncertainty)} å€‹ç´”ç²¹çš„æ¨¡å‹ä¸ç¢ºå®šç‰‡æ®µ")
                logger.warning("æ¨¡å‹æœ€ä¸ç¢ºå®šçš„å‰5å¥:")
                
                # æŒ‰avg_logprobæ’åºï¼Œé¡¯ç¤ºå‰5å€‹
                pure_uncertainty.sort(key=lambda x: x["avg_logprob"])
                for i, seg in enumerate(pure_uncertainty[:5]):
                    start_time = self._format_time(seg["start"])
                    end_time = self._format_time(seg["end"])
                    logger.warning(f"  {i+1}. [{start_time} --> {end_time}]")
                    logger.warning(f"     ç†è§£åº¦: {seg['understanding_level']} (avg_logprob: {seg['avg_logprob']:.3f})")
                    logger.warning(f"     è­˜åˆ¥çµæœ: {seg['text']}")
            else:
                logger.info("æ²’æœ‰ç™¼ç¾ç´”ç²¹çš„æ¨¡å‹ä¸ç¢ºå®šç‰‡æ®µ")
                
        except Exception as e:
            logger.error(f"å­—å¹•å“è³ªåˆ†æå¤±æ•—: {e}")
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ™‚é–“ç‚ºSRTæ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

    def cleanup(self):
        """æ¸…ç†è³‡æº"""
        if self.model:
            # Faster-Whisper æœƒè‡ªå‹•ç®¡ç†è³‡æº
            self.model = None
        self.initialized = False


def test_simple_generation():
    """æ¸¬è©¦ç°¡åŒ–ç‰ˆå­—å¹•ç”Ÿæˆ"""
    print("=== æ¸¬è©¦ç°¡åŒ–ç‰ˆå­—å¹•ç”Ÿæˆ ===")
    
    # å‰µå»ºæ¸¬è©¦éŸ³é »
    try:
        import numpy as np
        import soundfile as sf
        
        # å‰µå»ºç°¡å–®çš„æ¸¬è©¦éŸ³é »
        duration = 3.0
        sample_rate = 16000
        t = np.linspace(0, duration, int(sample_rate * duration))
        
        # å‰µå»ºåŒ…å«å¤šå€‹é »ç‡çš„éŸ³é »ï¼ˆæ¨¡æ“¬èªéŸ³ï¼‰
        audio = 0.3 * (
            np.sin(2 * np.pi * 220 * t) +  # ä½é »
            0.5 * np.sin(2 * np.pi * 440 * t) +  # ä¸­é »
            0.3 * np.sin(2 * np.pi * 880 * t)   # é«˜é »
        )
        
        test_file = "simple_test.wav"
        sf.write(test_file, audio, sample_rate)
        print(f"[OK] å‰µå»ºæ¸¬è©¦éŸ³é »: {test_file}")
        
        # æ¸¬è©¦å­—å¹•ç”Ÿæˆ
        core = SimplifiedSubtitleCore()
        
        def progress_callback(value, message):
            print(f"[{value:3d}%] {message}")
        
        print("[INFO] åˆå§‹åŒ–æ¨¡å‹...")
        if core.initialize(progress_callback):
            print("[INFO] é–‹å§‹ç”Ÿæˆå­—å¹•...")
            output_file = "simple_test.srt"
            
            success = core.generate_subtitle(
                test_file,
                output_file,
                language=None,
                format="srt",
                progress_callback=progress_callback
            )
            
            if success and os.path.exists(output_file):
                print(f"[OK] å­—å¹•ç”ŸæˆæˆåŠŸ: {output_file}")
                
                # é¡¯ç¤ºçµæœ
                with open(output_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    print("å­—å¹•å…§å®¹é è¦½:")
                    print("-" * 40)
                    print(content[:300] + "..." if len(content) > 300 else content)
                    print("-" * 40)
                
                # æ¸…ç†æ¸¬è©¦æ–‡ä»¶
                os.remove(test_file)
                os.remove(output_file)
                
                return True
            else:
                print("[ERROR] å­—å¹•ç”Ÿæˆå¤±æ•—")
                return False
        else:
            print("[ERROR] æ¨¡å‹åˆå§‹åŒ–å¤±æ•—")
            return False
            
    except ImportError:
        print("[WARNING] ç¼ºå°‘æ¸¬è©¦ä¾è³´ï¼Œè·³éæ¸¬è©¦")
        return True
    except Exception as e:
        print(f"[ERROR] æ¸¬è©¦å¤±æ•—: {e}")
        return False


def main():
    """ä¸»å‡½æ•¸ - æ”¯æ´å‘½ä»¤è¡Œå’ŒElectronèª¿ç”¨"""
    import argparse
    import json
    
    parser = argparse.ArgumentParser(description='ç°¡åŒ–ç‰ˆå­—å¹•ç”Ÿæˆå·¥å…·')
    parser.add_argument('--files', type=str, help='JSONæ ¼å¼çš„æª”æ¡ˆåˆ—è¡¨')
    parser.add_argument('--settings', type=str, help='JSONæ ¼å¼çš„è¨­å®š')
    parser.add_argument('--corrections', type=str, help='JSONæ ¼å¼çš„ä¿®æ­£è¦å‰‡')
    parser.add_argument('--test', action='store_true', help='é‹è¡Œæ¸¬è©¦æ¨¡å¼')
    
    args = parser.parse_args()
    
    # è¨­å®šæ—¥èªŒ
    logging.basicConfig(level=logging.INFO, format='%(message)s')
    
    if args.test:
        # æ¸¬è©¦æ¨¡å¼
        if test_simple_generation():
            print("\n[SUCCESS] Simplified subtitle generation test passed")
            return 0
        else:
            print("\n[FAILED] Simplified subtitle generation test failed")
            return 1
    
    if not args.files or not args.settings:
        print("Error: File list and settings are required")
        return 1
    
    try:
        # è§£æåƒæ•¸
        files = json.loads(args.files)
        settings = json.loads(args.settings)
        corrections = json.loads(args.corrections) if args.corrections else []
        
        # å‰µå»ºå­—å¹•ç”Ÿæˆå™¨
        generator = SimplifiedSubtitleCore(
            model_size=settings.get('model', 'medium'),
            device='auto'
        )
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        print(f"PROGRESS:{json.dumps({'percent': 0, 'filename': '', 'status': 'initializing', 'message': 'æ­£åœ¨åˆå§‹åŒ–AIæ¨¡å‹...'})}")
        if not generator.initialize():
            print(f"PROGRESS:{json.dumps({'percent': 0, 'filename': '', 'status': 'error', 'message': 'æ¨¡å‹åˆå§‹åŒ–å¤±æ•—'})}")
            return 1
        
        # è™•ç†æ¯å€‹æª”æ¡ˆ
        total_files = len(files)
        for i, file_path in enumerate(files):
            if not os.path.exists(file_path):
                print(f"PROGRESS:{json.dumps({'percent': (i/total_files)*100, 'filename': file_path, 'status': 'error', 'message': 'æª”æ¡ˆä¸å­˜åœ¨'})}")
                continue
            
            try:
                print(f"PROGRESS:{json.dumps({'percent': (i/total_files)*100, 'filename': os.path.basename(file_path), 'status': 'processing'})}")
                
                # ç”Ÿæˆå­—å¹• - æ§‹å»ºè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
                input_path = Path(file_path)
                output_dir = settings.get('customDir', '') or str(input_path.parent)
                output_format = settings.get('outputFormat', 'srt')
                output_file = os.path.join(output_dir, f"{input_path.stem}.{output_format}")
                
                # ç”Ÿæˆå­—å¹•
                output_lang = settings.get('outputLanguage', 'same')
                result = generator.generate_subtitle(
                    input_file=file_path,
                    output_file=output_file,
                    language=settings.get('language', None) if settings.get('language') != 'auto' else None,
                    output_language=output_lang if output_lang != 'same' else None,
                    format=output_format,
                    progress_callback=None
                )
                
                if result:
                    print(f"PROGRESS:{json.dumps({'percent': ((i+1)/total_files)*100, 'filename': os.path.basename(file_path), 'status': 'completed'})}")
                else:
                    print(f"PROGRESS:{json.dumps({'percent': ((i+1)/total_files)*100, 'filename': os.path.basename(file_path), 'status': 'error', 'message': 'ç”Ÿæˆå¤±æ•—'})}")
                    
            except Exception as e:
                print(f"PROGRESS:{json.dumps({'percent': ((i+1)/total_files)*100, 'filename': os.path.basename(file_path), 'status': 'error', 'message': str(e)})}")
        
        print("Processing completed successfully")
        return 0
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return 1


if __name__ == "__main__":
    sys.exit(main())