#!/usr/bin/env python3
"""
Whisper Large V3 Turbo INT8 Model Manager
ä½¿ç”¨ INT8 é‡åŒ–ç‰ˆæœ¬ï¼Œå¤§å°ç´„ 1GBï¼Œæœ€é©åˆ NSIS æ‰“åŒ…
é€Ÿåº¦æ¯” FP16 å¿« 3.5 å€ï¼Œç²¾åº¦æå¤±æ¥µå°
"""

import os
import logging
import requests
import shutil
import hashlib
from pathlib import Path
from typing import Tuple, Dict, Any, Optional
from tqdm import tqdm
import time

logger = logging.getLogger(__name__)

class LargeV3INT8ModelManager:
    """Large V3 Turbo INT8 æ¨¡å‹ç®¡ç†å™¨ - æœ€å„ªåŒ–æ‰“åŒ…ç‰ˆæœ¬"""
    
    def __init__(self):
        # ä½¿ç”¨ Large V3 Turbo INT8 ç‰ˆæœ¬
        self.model_name = "large-v3-turbo"
        self.model_variant = "int8"
        self.model_full_name = f"{self.model_name}-{self.model_variant}"
        
        # Hugging Face ä¸‹è¼‰ URL - Zoont çš„ INT8 ç‰ˆæœ¬
        self.model_repo = "Zoont/faster-whisper-large-v3-turbo-int8-ct2"
        self.base_url = f"https://huggingface.co/{self.model_repo}/resolve/main"
        
        # å¿…è¦æ–‡ä»¶åˆ—è¡¨åŠå…¶é æœŸå¤§å°ï¼ˆä¼°è¨ˆå€¼ï¼‰
        self.required_files = {
            "model.bin": {
                "url": f"{self.base_url}/model.bin",
                "min_size": 500_000_000,  # è‡³å°‘ 500MB
                "max_size": 1_500_000_000  # æœ€å¤š 1.5GB
            },
            "config.json": {
                "url": f"{self.base_url}/config.json",
                "min_size": 100,
                "max_size": 10_000
            },
            "tokenizer.json": {
                "url": f"{self.base_url}/tokenizer.json",
                "min_size": 1000,
                "max_size": 10_000_000
            },
            "vocabulary.txt": {
                "url": f"{self.base_url}/vocabulary.txt",
                "min_size": 1000,
                "max_size": 1_000_000
            },
            "preprocessor_config.json": {
                "url": f"{self.base_url}/preprocessor_config.json",
                "min_size": 100,
                "max_size": 10_000
            }
        }
        
        # å‚™ç”¨ä¸‹è¼‰æºï¼ˆå¦‚æœä¸»æºå¤±æ•—ï¼‰
        self.backup_repos = [
            "mukowaty/faster-whisper-int8",  # é€šç”¨ INT8 ç‰ˆæœ¬
            "Systran/faster-whisper-large-v3"  # æ¨™æº–ç‰ˆï¼ˆè¼ƒå¤§ï¼‰
        ]
        
        # è·¯å¾‘è¨­å®š
        self.app_models_dir = Path(__file__).parent.parent / "models"
        self.model_dir = self.app_models_dir / self.model_full_name
        self.cache_dir = Path.home() / ".cache" / "whisper" / self.model_full_name
        self.temp_dir = self.app_models_dir / "temp"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.app_models_dir.mkdir(parents=True, exist_ok=True)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Large V3 Turbo INT8 Model Manager åˆå§‹åŒ–:")
        logger.info(f"  - æ¨¡å‹: {self.model_full_name}")
        logger.info(f"  - æ¨¡å‹ç›®éŒ„: {self.model_dir}")
        logger.info(f"  - å¿«å–ç›®éŒ„: {self.cache_dir}")
        logger.info(f"  - ä¾†æº: {self.model_repo}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹ä¿¡æ¯"""
        available = self.check_model_availability()
        
        return {
            "name": self.model_full_name,
            "variant": "INT8 é‡åŒ–ç‰ˆï¼ˆè¶…å¿«é€Ÿï¼‰",
            "available": available,
            "status_text": "å·²å®‰è£" if available else "éœ€è¦ä¸‹è¼‰",
            "estimated_size": "~1 GB",
            "actual_size": self._format_size(self._get_model_size()) if available else "0 MB",
            "path": str(self.model_dir) if available else None,
            "performance": "é€Ÿåº¦æœ€å¿«ï¼ˆæ¯” FP16 å¿« 3.5 å€ï¼‰",
            "accuracy": "ç²¾åº¦å„ªç§€ï¼ˆèˆ‡ FP16 ç›¸å·® < 1%ï¼‰"
        }
    
    def check_model_availability(self) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        # æª¢æŸ¥æœ¬åœ°æ¨¡å‹ç›®éŒ„
        if self._validate_model(self.model_dir):
            logger.info(f"âœ… æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {self.model_dir}")
            return True
        
        # æª¢æŸ¥å¿«å–ç›®éŒ„
        if self._validate_model(self.cache_dir):
            logger.info(f"æ‰¾åˆ°å¿«å–æ¨¡å‹: {self.cache_dir}")
            # è¤‡è£½åˆ°æ‡‰ç”¨ç›®éŒ„
            if self._copy_model_files(self.cache_dir, self.model_dir):
                return True
        
        # æª¢æŸ¥ HuggingFace å¿«å–
        hf_cache_patterns = [
            Path.home() / ".cache" / "huggingface" / "hub" / f"models--{self.model_repo.replace('/', '--')}",
            Path.home() / ".cache" / "huggingface" / "hub" / "models--Zoont--faster-whisper-large-v3-turbo-int8-ct2"
        ]
        
        for hf_cache_path in hf_cache_patterns:
            if hf_cache_path.exists():
                logger.info(f"æ‰¾åˆ° HuggingFace å¿«å–: {hf_cache_path}")
                snapshots = hf_cache_path / "snapshots"
                if snapshots.exists():
                    for snapshot_dir in snapshots.iterdir():
                        if self._validate_model(snapshot_dir):
                            if self._copy_model_files(snapshot_dir, self.model_dir):
                                return True
        
        logger.info("æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œéœ€è¦ä¸‹è¼‰")
        return False
    
    def _validate_model(self, model_path: Path) -> bool:
        """é©—è­‰æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´"""
        if not model_path.exists():
            return False
        
        # æª¢æŸ¥å¿…è¦æ–‡ä»¶
        essential_files = ["model.bin", "config.json"]
        for file_name in essential_files:
            file_path = model_path / file_name
            if not file_path.exists():
                return False
            
            # æª¢æŸ¥æ–‡ä»¶å¤§å°
            if file_name == "model.bin":
                size_bytes = file_path.stat().st_size
                expected = self.required_files.get("model.bin", {})
                min_size = expected.get("min_size", 500_000_000)
                max_size = expected.get("max_size", 1_500_000_000)
                
                if size_bytes < min_size or size_bytes > max_size:
                    size_gb = size_bytes / (1024**3)
                    logger.warning(f"æ¨¡å‹å¤§å°å¯èƒ½ç•°å¸¸: {size_gb:.2f}GB (é æœŸ: 0.5-1.5GB)")
                    # INT8 æ¨¡å‹æ‡‰è©²åœ¨ 0.5-1.5GB ä¹‹é–“
        
        return True
    
    def _copy_model_files(self, source: Path, target: Path) -> bool:
        """è¤‡è£½æ¨¡å‹æ–‡ä»¶"""
        try:
            target.mkdir(parents=True, exist_ok=True)
            
            copied_count = 0
            for file_name in self.required_files.keys():
                source_file = source / file_name
                if source_file.exists():
                    target_file = target / file_name
                    if not target_file.exists() or target_file.stat().st_size != source_file.stat().st_size:
                        logger.info(f"  è¤‡è£½: {file_name}")
                        shutil.copy2(source_file, target_file)
                        copied_count += 1
            
            if copied_count > 0:
                logger.info(f"âœ… è¤‡è£½äº† {copied_count} å€‹æ–‡ä»¶")
            
            return self._validate_model(target)
        except Exception as e:
            logger.error(f"âŒ è¤‡è£½æ¨¡å‹æ–‡ä»¶å¤±æ•—: {e}")
            return False
    
    def download_model(self, progress_callback: Optional[callable] = None) -> Tuple[bool, str]:
        """ä¸‹è¼‰ Large V3 Turbo INT8 æ¨¡å‹ï¼ˆæ”¯æ´æ–·é»çºŒå‚³ï¼‰"""
        try:
            self.model_dir.mkdir(parents=True, exist_ok=True)
            self.temp_dir.mkdir(parents=True, exist_ok=True)
            
            total_files = len(self.required_files)
            completed_files = 0
            
            for file_name, file_info in self.required_files.items():
                target_file = self.model_dir / file_name
                temp_file = self.temp_dir / f"{file_name}.download"
                
                # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰æ•ˆ
                if target_file.exists():
                    file_size = target_file.stat().st_size
                    if file_info["min_size"] <= file_size <= file_info["max_size"]:
                        logger.info(f"  âœ“ å·²å­˜åœ¨: {file_name} ({self._format_size(file_size)})")
                        completed_files += 1
                        if progress_callback:
                            progress_callback(completed_files / total_files, f"å·²å­˜åœ¨ {file_name}")
                        continue
                
                # ä¸‹è¼‰æ–‡ä»¶ï¼ˆæ”¯æ´æ–·é»çºŒå‚³ï¼‰
                success = self._download_file_with_resume(
                    url=file_info["url"],
                    target_path=target_file,
                    temp_path=temp_file,
                    expected_size_range=(file_info["min_size"], file_info["max_size"]),
                    progress_callback=lambda p, m: progress_callback(
                        (completed_files + p) / total_files, m
                    ) if progress_callback else None
                )
                
                if not success:
                    logger.error(f"âŒ ä¸‹è¼‰å¤±æ•—: {file_name}")
                    return False, f"ç„¡æ³•ä¸‹è¼‰ {file_name}"
                
                completed_files += 1
                logger.info(f"  âœ… å®Œæˆ: {file_name}")
            
            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir, ignore_errors=True)
            
            # é©—è­‰æ‰€æœ‰æ–‡ä»¶
            if self._validate_model(self.model_dir):
                total_size = self._get_model_size()
                logger.info(f"âœ… Large V3 Turbo INT8 æ¨¡å‹ä¸‹è¼‰æˆåŠŸ")
                logger.info(f"   ç¸½å¤§å°: {self._format_size(total_size)}")
                return True, str(self.model_dir)
            else:
                logger.error("âŒ æ¨¡å‹é©—è­‰å¤±æ•—")
                return False, "æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´"
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è¼‰éç¨‹å‡ºéŒ¯: {e}")
            return False, str(e)
    
    def _download_file_with_resume(
        self,
        url: str,
        target_path: Path,
        temp_path: Path,
        expected_size_range: Tuple[int, int],
        progress_callback: Optional[callable] = None,
        max_retries: int = 3
    ) -> bool:
        """ä¸‹è¼‰æ–‡ä»¶ï¼ˆæ”¯æ´æ–·é»çºŒå‚³å’Œé‡è©¦ï¼‰"""
        file_name = target_path.name
        
        for attempt in range(max_retries):
            try:
                # æª¢æŸ¥è‡¨æ™‚æ–‡ä»¶
                resume_pos = 0
                if temp_path.exists():
                    resume_pos = temp_path.stat().st_size
                    logger.info(f"  çºŒå‚³: {file_name} (å¾ {self._format_size(resume_pos)} é–‹å§‹)")
                else:
                    logger.info(f"  ä¸‹è¼‰: {file_name}")
                
                # è¨­ç½®è«‹æ±‚é ­
                headers = {}
                if resume_pos > 0:
                    headers['Range'] = f'bytes={resume_pos}-'
                
                # ç™¼é€è«‹æ±‚
                response = requests.get(url, headers=headers, stream=True, timeout=30)
                
                # æª¢æŸ¥æ˜¯å¦æ”¯æ´æ–·é»çºŒå‚³
                if resume_pos > 0 and response.status_code != 206:
                    logger.warning("ä¼ºæœå™¨ä¸æ”¯æ´æ–·é»çºŒå‚³ï¼Œé‡æ–°ä¸‹è¼‰")
                    resume_pos = 0
                    temp_path.unlink(missing_ok=True)
                    response = requests.get(url, stream=True, timeout=30)
                
                response.raise_for_status()
                
                # ç²å–æ–‡ä»¶ç¸½å¤§å°
                content_length = response.headers.get('content-length')
                if content_length:
                    total_size = int(content_length) + resume_pos
                else:
                    total_size = None
                
                # ä¸‹è¼‰æ–‡ä»¶
                chunk_size = 8192 * 4  # 32KB chunks
                mode = 'ab' if resume_pos > 0 else 'wb'
                
                with open(temp_path, mode) as f:
                    if total_size:
                        with tqdm(
                            total=total_size,
                            initial=resume_pos,
                            unit='B',
                            unit_scale=True,
                            desc=file_name
                        ) as pbar:
                            for chunk in response.iter_content(chunk_size=chunk_size):
                                if chunk:
                                    f.write(chunk)
                                    pbar.update(len(chunk))
                                    
                                    if progress_callback:
                                        progress = pbar.n / total_size
                                        progress_callback(progress, f"ä¸‹è¼‰ {file_name}...")
                    else:
                        # æ²’æœ‰å…§å®¹é•·åº¦ï¼Œç„¡æ³•é¡¯ç¤ºé€²åº¦
                        downloaded = resume_pos
                        for chunk in response.iter_content(chunk_size=chunk_size):
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)
                                
                                if progress_callback and downloaded % (1024 * 1024) == 0:  # æ¯ MB æ›´æ–°ä¸€æ¬¡
                                    progress_callback(0.5, f"ä¸‹è¼‰ {file_name}... {self._format_size(downloaded)}")
                
                # é©—è­‰æ–‡ä»¶å¤§å°
                final_size = temp_path.stat().st_size
                min_size, max_size = expected_size_range
                
                if final_size < min_size:
                    logger.error(f"æ–‡ä»¶å¤ªå°: {self._format_size(final_size)} < {self._format_size(min_size)}")
                    temp_path.unlink(missing_ok=True)
                    if attempt < max_retries - 1:
                        logger.info(f"é‡è©¦ {attempt + 2}/{max_retries}...")
                        time.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿
                        continue
                    return False
                
                if final_size > max_size:
                    logger.warning(f"æ–‡ä»¶è¼ƒå¤§: {self._format_size(final_size)} > {self._format_size(max_size)}")
                
                # ç§»å‹•åˆ°ç›®æ¨™ä½ç½®
                shutil.move(str(temp_path), str(target_path))
                logger.info(f"  âœ“ ä¿å­˜: {file_name} ({self._format_size(final_size)})")
                return True
                
            except requests.exceptions.RequestException as e:
                logger.error(f"ä¸‹è¼‰éŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿
                    continue
                return False
            
            except Exception as e:
                logger.error(f"æ„å¤–éŒ¯èª¤: {e}")
                return False
        
        return False
    
    def get_model_path(self) -> Tuple[bool, str]:
        """ç²å–æ¨¡å‹è·¯å¾‘"""
        if self.check_model_availability():
            logger.info(f"ä½¿ç”¨ Large V3 Turbo INT8 æ¨¡å‹: {self.model_dir}")
            return True, str(self.model_dir)
        else:
            logger.warning("æ¨¡å‹ä¸å¯ç”¨ï¼Œéœ€è¦å…ˆä¸‹è¼‰")
            return False, ""
    
    def _get_model_size(self) -> int:
        """ç²å–æ¨¡å‹ç¸½å¤§å°ï¼ˆå­—ç¯€ï¼‰"""
        try:
            if self.model_dir.exists():
                total_size = 0
                for file_path in self.model_dir.glob('*'):
                    if file_path.is_file():
                        total_size += file_path.stat().st_size
                return total_size
        except Exception as e:
            logger.debug(f"ç„¡æ³•ç²å–æ¨¡å‹å¤§å°: {e}")
        
        return 0
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"
    
    def prepare_model(self) -> Tuple[bool, str]:
        """æº–å‚™æ¨¡å‹ï¼ˆç¢ºä¿å¯ç”¨ï¼‰"""
        logger.info("ğŸ”„ æº–å‚™ Large V3 Turbo INT8 æ¨¡å‹...")
        
        if self.check_model_availability():
            size = self._format_size(self._get_model_size())
            logger.info(f"âœ… æ¨¡å‹å·²å°±ç·’: {self.model_dir}")
            logger.info(f"   å¤§å°: {size}")
            logger.info(f"   é¡å‹: INT8 é‡åŒ–ï¼ˆè¶…å¿«é€Ÿï¼‰")
            return True, str(self.model_dir)
        else:
            logger.info("ğŸ“¥ éœ€è¦ä¸‹è¼‰æ¨¡å‹...")
            return self.download_model()
    
    def ensure_model_ready(self) -> Tuple[bool, str]:
        """ç¢ºä¿æ¨¡å‹å·²æº–å‚™å¥½ï¼Œå¦‚æœéœ€è¦å‰‡ä¸‹è¼‰"""
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¶“å¯ç”¨
        if self.check_model_availability():
            success, model_path = self.get_model_path()
            return success, model_path
        
        # å˜—è©¦ä¸‹è¼‰æ¨¡å‹
        logger.info("æ¨¡å‹ä¸å¯ç”¨ï¼Œå˜—è©¦ä¸‹è¼‰...")
        success, message = self.download_model()
        
        if success:
            return self.get_model_path()
        else:
            # ä¸‹è¼‰å¤±æ•—ï¼Œè¿”å›æ¨™æº–æ¨¡å‹åç¨±ä½œç‚ºå‚™ç”¨
            logger.warning(f"INT8 æ¨¡å‹ä¸‹è¼‰å¤±æ•—: {message}")
            return True, "large-v3"  # å‚™ç”¨åˆ°æ¨™æº–æ¨¡å‹

    def get_faster_whisper_config(self) -> Dict[str, Any]:
        """ç²å– faster-whisper çš„é…ç½®åƒæ•¸"""
        return {
            "model_size_or_path": str(self.model_dir) if self.check_model_availability() else self.model_repo,
            "device": "cpu",  # INT8 åœ¨ CPU ä¸Šæ•ˆæœæœ€ä½³
            "compute_type": "int8",  # ä½¿ç”¨ INT8 è¨ˆç®—
            "num_workers": 1,
            "download_root": str(self.cache_dir),
            "local_files_only": False,
            # Large V3 å°ˆç”¨é…ç½®
            "feature_size": 128,  # Large V3 éœ€è¦128å€‹melé »è­œå¸¶
            "n_mels": 128  # è¨­ç½®melé »è­œå¸¶æ•¸é‡
        }
    
    def cleanup_cache(self):
        """æ¸…ç†å¿«å–å’Œè‡¨æ™‚æ–‡ä»¶"""
        try:
            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir, ignore_errors=True)
                logger.info("âœ… æ¸…ç†è‡¨æ™‚æ–‡ä»¶")
            
            # å¯é¸ï¼šæ¸…ç†å¿«å–ç›®éŒ„
            # if self.cache_dir.exists():
            #     shutil.rmtree(self.cache_dir, ignore_errors=True)
            #     logger.info("âœ… æ¸…ç†å¿«å–ç›®éŒ„")
            
        except Exception as e:
            logger.error(f"æ¸…ç†å¤±æ•—: {e}")