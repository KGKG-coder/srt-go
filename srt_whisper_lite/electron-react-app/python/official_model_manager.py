#!/usr/bin/env python3
"""
Official Whisper Large V3 Turbo CT2 Model Manager
æ ¹æ“šæ±ºç­–è¦æ±‚é…ç½®ï¼š
- ä¸»æºï¼šHF zzxxcc0805/my-whisper-large-v3-turbo-ct2
- å‚™æºï¼šGitHub Releases ZIP
- SHA256ï¼šA30872B8826A4F77B973CDDA325E182E520A4C965BC53DFEEAD33BBCE049F828
- å¤§å°ï¼š1492336108 bytes
- GPU: cuda+float16 / CPU: cpu+int8
"""

import os
import sys
import logging
import requests
import shutil
import hashlib
import zipfile
from pathlib import Path
from typing import Tuple, Dict, Any, Optional
from tqdm import tqdm
import time

logger = logging.getLogger(__name__)

class OfficialModelManager:
    """å®˜æ–¹æŒ‡å®šæ¨¡å‹ç®¡ç†å™¨ - å®Œå…¨ç¬¦åˆæ±ºç­–è¦æ±‚"""
    
    def __init__(self):
        # å®˜æ–¹æŒ‡å®šæ¨¡å‹é…ç½®
        self.model_name = "whisper-large-v3-turbo-ct2"
        self.model_repo = "zzxxcc0805/my-whisper-large-v3-turbo-ct2"
        
        # å®˜æ–¹æŒ‡å®šå‚™æºé…ç½®
        self.backup_url = "https://github.com/zzxxcc0805/whisper-mirrors/releases/download/ct2-large-v3-turbo-2025-08-18-r1/whisper-large-v3-turbo-ct2.zip"
        self.expected_sha256 = "A30872B8826A4F77B973CDDA325E182E520A4C965BC53DFEEAD33BBCE049F828"
        self.expected_size = 1492336108  # 1,492,336,108 bytes
        
        # è·¯å¾‘é…ç½®
        self.app_models_dir = Path(__file__).parent.parent / "models"
        self.model_dir = self.app_models_dir / self.model_name
        self.cache_dir = Path.home() / ".cache" / "whisper" / self.model_name
        self.temp_dir = self.app_models_dir / "temp"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.app_models_dir.mkdir(parents=True, exist_ok=True)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Official Model Manager åˆå§‹åŒ–:")
        logger.info(f"  - æ¨¡å‹: {self.model_name}")
        logger.info(f"  - HFæº: {self.model_repo}")
        logger.info(f"  - å‚™æº: {self.backup_url}")
        logger.info(f"  - SHA256: {self.expected_sha256[:16]}...")
        logger.info(f"  - å¤§å°: {self._format_size(self.expected_size)}")
        logger.info(f"  - æ¨¡å‹ç›®éŒ„: {self.model_dir}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹ä¿¡æ¯"""
        available = self.check_model_availability()
        
        return {
            "name": self.model_name,
            "variant": "Large V3 Turbo CT2",
            "available": available,
            "status_text": "å·²å®‰è£" if available else "éœ€è¦ä¸‹è¼‰",
            "expected_size": self._format_size(self.expected_size),
            "actual_size": self._format_size(self._get_model_size()) if available else "0 MB",
            "path": str(self.model_dir) if available else None,
            "sha256": self.expected_sha256[:16] + "...",
            "sources": ["HuggingFace Hub", "GitHub Mirror"],
            "device_strategy": "GPU: cuda+float16 / CPU: cpu+int8"
        }
    
    def check_model_availability(self) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        # æª¢æŸ¥æœ¬åœ°æ¨¡å‹ç›®éŒ„
        if self._validate_model(self.model_dir):
            logger.info(f"âœ… æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {self.model_dir}")
            return True
        
        # æª¢æŸ¥å¿«å–ç›®éŒ„
        if self._validate_model(self.cache_dir):
            logger.info(f"æ‰¾åˆ°å¿«å–æ¨¡å‹: {self.cache_dir}")
            # è¤‡è£½åˆ°æ‡‰ç”¨ç›®éŒ„
            if self._copy_model_files(self.cache_dir, self.model_dir):
                return True
        
        # æª¢æŸ¥ HuggingFace å¿«å–
        hf_cache_patterns = [
            Path.home() / ".cache" / "huggingface" / "hub" / f"models--{self.model_repo.replace('/', '--')}",
            Path.home() / ".cache" / "huggingface" / "transformers" / "models" / self.model_repo
        ]
        
        for hf_cache_path in hf_cache_patterns:
            if hf_cache_path.exists():
                logger.info(f"æ‰¾åˆ° HuggingFace å¿«å–: {hf_cache_path}")
                snapshots = hf_cache_path / "snapshots"
                if snapshots.exists():
                    for snapshot_dir in snapshots.iterdir():
                        if self._validate_model(snapshot_dir):
                            if self._copy_model_files(snapshot_dir, self.model_dir):
                                return True
        
        logger.info("æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œéœ€è¦ä¸‹è¼‰")
        return False
    
    def _validate_model(self, model_path: Path) -> bool:
        """é©—è­‰æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´"""
        if not model_path.exists():
            return False
        
        # æª¢æŸ¥å¿…è¦æ–‡ä»¶
        essential_files = ["model.bin", "config.json"]
        for file_name in essential_files:
            file_path = model_path / file_name
            if not file_path.exists():
                return False
        
        return True
    
    def _copy_model_files(self, source: Path, target: Path) -> bool:
        """è¤‡è£½æ¨¡å‹æ–‡ä»¶"""
        try:
            target.mkdir(parents=True, exist_ok=True)
            
            for source_file in source.iterdir():
                if source_file.is_file():
                    target_file = target / source_file.name
                    if not target_file.exists() or target_file.stat().st_size != source_file.stat().st_size:
                        logger.info(f"  è¤‡è£½: {source_file.name}")
                        shutil.copy2(source_file, target_file)
            
            return self._validate_model(target)
        except Exception as e:
            logger.error(f"âŒ è¤‡è£½æ¨¡å‹æ–‡ä»¶å¤±æ•—: {e}")
            return False
    
    def download_model(self, progress_callback: Optional[callable] = None) -> Tuple[bool, str]:
        """ä¸‹è¼‰æ¨¡å‹ï¼ˆä¸»æºâ†’å‚™æºç­–ç•¥ï¼‰"""
        try:
            # å˜—è©¦ HuggingFace Hub
            logger.info("ğŸ“¥ å˜—è©¦å¾ HuggingFace Hub ä¸‹è¼‰...")
            if progress_callback:
                progress_callback(0.1, "checking", "æª¢æŸ¥ HuggingFace Hub...")
            
            success, message = self._download_from_huggingface(progress_callback)
            if success:
                return True, message
            
            # å›é€€åˆ° GitHub Mirror
            logger.info("ğŸ“¥ å›é€€åˆ° GitHub Mirror...")
            if progress_callback:
                progress_callback(0.1, "downloading", "åˆ‡æ›åˆ° GitHub Mirror...")
            
            success, message = self._download_from_github_mirror(progress_callback)
            if success:
                return True, message
            
            # æ‰€æœ‰æºéƒ½å¤±æ•—
            error_msg = "æ‰€æœ‰ä¸‹è¼‰æºéƒ½å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–ä½¿ç”¨é›¢ç·šå®‰è£åŒ…"
            logger.error(f"âŒ {error_msg}")
            return False, error_msg
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è¼‰éç¨‹å‡ºéŒ¯: {e}")
            return False, str(e)
    
    def _download_from_huggingface(self, progress_callback: Optional[callable] = None) -> Tuple[bool, str]:
        """å¾ HuggingFace Hub ä¸‹è¼‰"""
        try:
            # ä½¿ç”¨ faster-whisper çš„æ¨™æº–ä¸‹è¼‰æ–¹å¼
            from faster_whisper import WhisperModel
            
            if progress_callback:
                progress_callback(0.2, "downloading", "å¾ HuggingFace ä¸‹è¼‰æ¨¡å‹...")
            
            # å‰µå»ºæ¨¡å‹å¯¦ä¾‹ï¼Œæœƒè‡ªå‹•ä¸‹è¼‰
            model = WhisperModel(
                self.model_repo,
                device="cpu",  # å…ˆç”¨CPUè¼‰å…¥æª¢æŸ¥
                compute_type="int8",
                download_root=str(self.cache_dir.parent)
            )
            
            # æª¢æŸ¥ä¸‹è¼‰æ˜¯å¦æˆåŠŸ
            if self.check_model_availability():
                if progress_callback:
                    progress_callback(1.0, "done", "HuggingFace ä¸‹è¼‰å®Œæˆ")
                return True, f"å¾ HuggingFace Hub ä¸‹è¼‰æˆåŠŸ: {self.model_dir}"
            else:
                return False, "HuggingFace ä¸‹è¼‰å¤±æ•—ï¼šæ¨¡å‹é©—è­‰æœªé€šé"
                
        except Exception as e:
            logger.warning(f"HuggingFace ä¸‹è¼‰å¤±æ•—: {e}")
            return False, f"HuggingFace ä¸‹è¼‰å¤±æ•—: {e}"
    
    def _download_from_github_mirror(self, progress_callback: Optional[callable] = None) -> Tuple[bool, str]:
        """å¾ GitHub Mirror ä¸‹è¼‰ZIPæ–‡ä»¶"""
        try:
            self.temp_dir.mkdir(parents=True, exist_ok=True)
            zip_file = self.temp_dir / "model.zip"
            
            if progress_callback:
                progress_callback(0.2, "downloading", "å¾ GitHub Mirror ä¸‹è¼‰...")
            
            # ä¸‹è¼‰ZIPæ–‡ä»¶
            success = self._download_file_with_resume(
                url=self.backup_url,
                target_path=zip_file,
                expected_size=self.expected_size,
                progress_callback=lambda p, s: progress_callback(
                    0.2 + p * 0.6, "downloading", f"ä¸‹è¼‰ä¸­... {s}"
                ) if progress_callback else None
            )
            
            if not success:
                return False, "GitHub Mirror ä¸‹è¼‰å¤±æ•—"
            
            # é©—è­‰ SHA256
            if progress_callback:
                progress_callback(0.8, "verifying", "é©—è­‰æ–‡ä»¶å®Œæ•´æ€§...")
            
            if not self._verify_sha256(zip_file):
                zip_file.unlink(missing_ok=True)
                return False, "SHA256 é©—è­‰å¤±æ•—"
            
            # è§£å£“ç¸®
            if progress_callback:
                progress_callback(0.9, "unpacking", "è§£å£“ç¸®æ¨¡å‹...")
            
            if not self._extract_zip(zip_file):
                return False, "è§£å£“ç¸®å¤±æ•—"
            
            # æ¸…ç†
            zip_file.unlink(missing_ok=True)
            self.temp_dir.rmdir() if self.temp_dir.exists() else None
            
            if progress_callback:
                progress_callback(1.0, "done", "GitHub Mirror ä¸‹è¼‰å®Œæˆ")
            
            return True, f"å¾ GitHub Mirror ä¸‹è¼‰æˆåŠŸ: {self.model_dir}"
            
        except Exception as e:
            logger.error(f"GitHub Mirror ä¸‹è¼‰å¤±æ•—: {e}")
            return False, f"GitHub Mirror ä¸‹è¼‰å¤±æ•—: {e}"
    
    def _download_file_with_resume(
        self,
        url: str,
        target_path: Path,
        expected_size: int,
        progress_callback: Optional[callable] = None,
        max_retries: int = 3
    ) -> bool:
        """ä¸‹è¼‰æ–‡ä»¶ï¼ˆæ”¯æ´æ–·é»çºŒå‚³ï¼‰"""
        for attempt in range(max_retries):
            try:
                # æª¢æŸ¥å·²ä¸‹è¼‰éƒ¨åˆ†
                resume_pos = 0
                if target_path.exists():
                    resume_pos = target_path.stat().st_size
                    if resume_pos == expected_size:
                        logger.info(f"æ–‡ä»¶å·²å®Œæ•´ä¸‹è¼‰: {target_path}")
                        return True
                
                # è¨­ç½®è«‹æ±‚é ­
                headers = {}
                if resume_pos > 0:
                    headers['Range'] = f'bytes={resume_pos}-'
                    logger.info(f"çºŒå‚³ä¸‹è¼‰ï¼Œå¾ {self._format_size(resume_pos)} é–‹å§‹")
                
                # ä¸‹è¼‰
                response = requests.get(url, headers=headers, stream=True, timeout=30)
                response.raise_for_status()
                
                # ç²å–å…§å®¹é•·åº¦
                content_length = response.headers.get('content-length')
                total_size = int(content_length) + resume_pos if content_length else expected_size
                
                # å¯«å…¥æ–‡ä»¶
                mode = 'ab' if resume_pos > 0 else 'wb'
                chunk_size = 8192 * 8  # 64KB chunks
                
                with open(target_path, mode) as f:
                    downloaded = resume_pos
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            
                            if progress_callback:
                                progress = downloaded / total_size
                                progress_callback(progress, f"å·²ä¸‹è¼‰: {self._format_size(downloaded)} / {self._format_size(total_size)}")
                
                # é©—è­‰å¤§å°
                final_size = target_path.stat().st_size
                if abs(final_size - expected_size) > 1024:  # å…è¨±1KBèª¤å·®
                    logger.warning(f"æ–‡ä»¶å¤§å°ä¸ç¬¦: {final_size} vs {expected_size}")
                
                return True
                
            except Exception as e:
                logger.error(f"ä¸‹è¼‰éŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                    continue
                return False
        
        return False
    
    def _verify_sha256(self, file_path: Path) -> bool:
        """é©—è­‰ SHA256"""
        try:
            sha256_hash = hashlib.sha256()
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(chunk)
            
            calculated = sha256_hash.hexdigest().upper()
            expected = self.expected_sha256.upper()
            
            if calculated == expected:
                logger.info("âœ… SHA256 é©—è­‰é€šé")
                return True
            else:
                logger.error(f"âŒ SHA256 ä¸ç¬¦: {calculated} != {expected}")
                return False
                
        except Exception as e:
            logger.error(f"SHA256 é©—è­‰å¤±æ•—: {e}")
            return False
    
    def _extract_zip(self, zip_file: Path) -> bool:
        """è§£å£“ç¸®ZIPæ–‡ä»¶"""
        try:
            with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                zip_ref.extractall(self.model_dir)
            
            logger.info(f"âœ… è§£å£“ç¸®å®Œæˆ: {self.model_dir}")
            return self._validate_model(self.model_dir)
            
        except Exception as e:
            logger.error(f"è§£å£“ç¸®å¤±æ•—: {e}")
            return False
    
    def get_device_strategy(self) -> Dict[str, Any]:
        """ç²å–è¨­å‚™ç­–ç•¥é…ç½®"""
        try:
            import torch
            has_cuda = torch.cuda.is_available()
        except:
            try:
                import subprocess
                result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
                has_cuda = result.returncode == 0
            except:
                has_cuda = False
        
        if has_cuda:
            return {
                "device": "cuda",
                "compute_type": "float16",
                "strategy": "GPUåŠ é€Ÿ",
                "description": "ä½¿ç”¨CUDA GPU + Float16ç²¾åº¦"
            }
        else:
            return {
                "device": "cpu", 
                "compute_type": "int8",
                "strategy": "CPUå„ªåŒ–",
                "description": "ä½¿ç”¨CPU + INT8é‡åŒ–"
            }
    
    def get_whisper_model_params(self) -> Dict[str, Any]:
        """ç²å– faster-whisper çš„é…ç½®åƒæ•¸"""
        device_config = self.get_device_strategy()
        
        return {
            "model_size_or_path": str(self.model_dir) if self.check_model_availability() else self.model_repo,
            "device": device_config["device"],
            "compute_type": device_config["compute_type"],
            "num_workers": 1,
            "download_root": str(self.cache_dir.parent),
            "local_files_only": False
        }
    
    def ensure_model_ready(self) -> Tuple[bool, str]:
        """ç¢ºä¿æ¨¡å‹æº–å‚™å°±ç·’"""
        logger.info("ğŸ”„ æº–å‚™å®˜æ–¹æŒ‡å®šæ¨¡å‹...")
        
        if self.check_model_availability():
            size = self._format_size(self._get_model_size())
            device_config = self.get_device_strategy()
            logger.info(f"âœ… æ¨¡å‹å·²å°±ç·’: {self.model_dir}")
            logger.info(f"   å¤§å°: {size}")
            logger.info(f"   ç­–ç•¥: {device_config['strategy']}")
            return True, str(self.model_dir)
        else:
            logger.info("ğŸ“¥ éœ€è¦ä¸‹è¼‰æ¨¡å‹...")
            return self.download_model()
    
    def _get_model_size(self) -> int:
        """ç²å–æ¨¡å‹ç¸½å¤§å°ï¼ˆå­—ç¯€ï¼‰"""
        try:
            if self.model_dir.exists():
                total_size = 0
                for file_path in self.model_dir.rglob('*'):
                    if file_path.is_file():
                        total_size += file_path.stat().st_size
                return total_size
        except Exception as e:
            logger.debug(f"ç„¡æ³•ç²å–æ¨¡å‹å¤§å°: {e}")
        
        return 0
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"