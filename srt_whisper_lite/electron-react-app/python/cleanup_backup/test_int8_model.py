#!/usr/bin/env python3
"""
æ¸¬è©¦ Large V3 Turbo INT8 æ¨¡å‹ç®¡ç†å™¨
é©—è­‰ä¸‹è¼‰ã€è¼‰å…¥å’Œè½‰éŒ„åŠŸèƒ½
"""

import sys
import logging
from pathlib import Path
import time

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_int8_model_manager():
    """æ¸¬è©¦ INT8 æ¨¡å‹ç®¡ç†å™¨"""
    try:
        print("=" * 70)
        print("ğŸš€ é–‹å§‹æ¸¬è©¦ Large V3 Turbo INT8 æ¨¡å‹ç®¡ç†å™¨")
        print("=" * 70)
        
        # å°å…¥æ¨¡å‹ç®¡ç†å™¨
        from large_v3_int8_model_manager import LargeV3INT8ModelManager
        
        # å‰µå»ºç®¡ç†å™¨å¯¦ä¾‹
        print("\nğŸ“¦ 1. å‰µå»ºæ¨¡å‹ç®¡ç†å™¨...")
        model_manager = LargeV3INT8ModelManager()
        
        # ç²å–æ¨¡å‹ä¿¡æ¯
        print("\nğŸ“Š 2. æ¨¡å‹ä¿¡æ¯:")
        print("-" * 50)
        model_info = model_manager.get_model_info()
        for key, value in model_info.items():
            print(f"  {key:20}: {value}")
        print("-" * 50)
        
        # æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§
        print("\nğŸ” 3. æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§...")
        available = model_manager.check_model_availability()
        if available:
            print("  âœ… æ¨¡å‹å·²å¯ç”¨ï¼Œç„¡éœ€ä¸‹è¼‰")
        else:
            print("  âš ï¸ æ¨¡å‹ä¸å¯ç”¨ï¼Œéœ€è¦ä¸‹è¼‰")
            print("\n" + "=" * 50)
            print("  ğŸ“¥ æ¨¡å‹ä¸‹è¼‰èªªæ˜:")
            print("  - å¤§å°: ç´„ 1GB (INT8 é‡åŒ–ç‰ˆ)")
            print("  - ä¾†æº: Hugging Face")
            print("  - é€Ÿåº¦: å–æ±ºæ–¼ç¶²è·¯é€£æ¥")
            print("=" * 50)
            
            # è©¢å•æ˜¯å¦ä¸‹è¼‰
            response = input("\næ˜¯å¦ä¸‹è¼‰æ¨¡å‹ï¼Ÿ(y/n): ").strip().lower()
            if response == 'y':
                print("\nğŸ“¥ 4. é–‹å§‹ä¸‹è¼‰æ¨¡å‹...")
                print("  æç¤º: æ”¯æ´æ–·é»çºŒå‚³ï¼Œä¸­æ–·å¾Œå¯ç¹¼çºŒ")
                
                # å®šç¾©é€²åº¦å›èª¿
                def progress_callback(progress, message):
                    bar_length = 40
                    filled = int(bar_length * progress)
                    bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
                    print(f"\r  [{bar}] {progress*100:.1f}% - {message}", end='', flush=True)
                
                start_time = time.time()
                success, path = model_manager.download_model(progress_callback)
                elapsed = time.time() - start_time
                
                print()  # æ›è¡Œ
                if success:
                    print(f"\n  âœ… æ¨¡å‹ä¸‹è¼‰æˆåŠŸ!")
                    print(f"  è·¯å¾‘: {path}")
                    print(f"  è€—æ™‚: {elapsed:.1f} ç§’")
                else:
                    print(f"\n  âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—: {path}")
                    return False
            else:
                print("  è·³éä¸‹è¼‰")
                return False
        
        # æº–å‚™æ¨¡å‹
        print("\nğŸ”§ 5. æº–å‚™æ¨¡å‹...")
        success, path = model_manager.prepare_model()
        if success:
            print(f"  âœ… æ¨¡å‹æº–å‚™å®Œæˆ: {path}")
            
            # é¡¯ç¤ºæ¨¡å‹å¤§å°
            model_size = model_manager._get_model_size()
            print(f"  ğŸ“Š æ¨¡å‹å¤§å°: {model_manager._format_size(model_size)}")
        else:
            print(f"  âŒ æ¨¡å‹æº–å‚™å¤±æ•—")
            return False
        
        # ç²å– faster-whisper é…ç½®
        print("\nâš™ï¸ 6. ç²å– faster-whisper é…ç½®:")
        config = model_manager.get_faster_whisper_config()
        print("-" * 50)
        for key, value in config.items():
            print(f"  {key:20}: {value}")
        print("-" * 50)
        
        # å¯é¸ï¼šæ¸¬è©¦å¯¦éš›åŠ è¼‰æ¨¡å‹
        print("\nğŸ§ª 7. æ¸¬è©¦æ¨¡å‹åŠ è¼‰")
        response = input("æ˜¯å¦æ¸¬è©¦åŠ è¼‰æ¨¡å‹åˆ° faster-whisperï¼Ÿ(y/n): ").strip().lower()
        if response == 'y':
            try:
                from faster_whisper import WhisperModel
                
                print("\n  åŠ è¼‰æ¨¡å‹ä¸­...")
                start_time = time.time()
                
                model = WhisperModel(
                    config["model_size_or_path"],
                    device=config["device"],
                    compute_type=config["compute_type"],
                    download_root=config.get("download_root"),
                    local_files_only=False
                )
                
                elapsed = time.time() - start_time
                print(f"  âœ… æ¨¡å‹åŠ è¼‰æˆåŠŸï¼(è€—æ™‚: {elapsed:.1f}ç§’)")
                
                # ç²å–æ¨¡å‹ä¿¡æ¯
                print("\n  æ¨¡å‹åƒæ•¸:")
                print(f"    - ç·¨ç¢¼å™¨å±¤æ•¸: {model.model.num_encoder_layers if hasattr(model.model, 'num_encoder_layers') else 'N/A'}")
                print(f"    - è§£ç¢¼å™¨å±¤æ•¸: {model.model.num_decoder_layers if hasattr(model.model, 'num_decoder_layers') else 'N/A'}")
                
                # æ¸¬è©¦è½‰éŒ„ï¼ˆå¯é¸ï¼‰
                test_audio = input("\nè¼¸å…¥æ¸¬è©¦éŸ³é »æ–‡ä»¶è·¯å¾‘ï¼ˆç•™ç©ºè·³éï¼‰: ").strip()
                if test_audio and Path(test_audio).exists():
                    print("\n  é–‹å§‹è½‰éŒ„æ¸¬è©¦...")
                    start_time = time.time()
                    
                    segments, info = model.transcribe(
                        test_audio,
                        language="zh",
                        task="transcribe",
                        beam_size=5,
                        best_of=5,
                        temperature=[0.0, 0.2, 0.4, 0.6, 0.8]
                    )
                    
                    print(f"\n  æª¢æ¸¬åˆ°èªè¨€: {info.language}")
                    print(f"  èªè¨€æ¦‚ç‡: {info.language_probability:.2%}")
                    print("\n  è½‰éŒ„çµæœ:")
                    print("-" * 50)
                    
                    segment_count = 0
                    for segment in segments:
                        segment_count += 1
                        print(f"  [{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
                    
                    elapsed = time.time() - start_time
                    print("-" * 50)
                    print(f"  âœ… è½‰éŒ„å®Œæˆ!")
                    print(f"  ç‰‡æ®µæ•¸: {segment_count}")
                    print(f"  è€—æ™‚: {elapsed:.1f}ç§’")
                    
                    # è¨ˆç®—é€Ÿåº¦
                    audio_duration = info.duration if hasattr(info, 'duration') else 0
                    if audio_duration > 0:
                        speed_ratio = audio_duration / elapsed
                        print(f"  é€Ÿåº¦: {speed_ratio:.1f}x å¯¦æ™‚")
                
            except ImportError:
                print("  âš ï¸ faster-whisper æœªå®‰è£ï¼Œè·³éé›†æˆæ¸¬è©¦")
            except Exception as e:
                print(f"  âŒ åŠ è¼‰æ¨¡å‹å¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
        
        # æ¸…ç†æ¸¬è©¦
        print("\nğŸ§¹ 8. æ¸…ç†è‡¨æ™‚æ–‡ä»¶...")
        model_manager.cleanup_cache()
        print("  âœ… æ¸…ç†å®Œæˆ")
        
        print("\n" + "=" * 70)
        print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print("ğŸ“Š ç¸½çµ:")
        print(f"  - æ¨¡å‹é¡å‹: Large V3 Turbo INT8")
        print(f"  - æ¨¡å‹å¤§å°: ~1GB")
        print(f"  - é€Ÿåº¦å„ªå‹¢: æ¯” FP16 å¿« 3.5 å€")
        print(f"  - é©åˆå ´æ™¯: NSIS æ‰“åŒ…ã€å¿«é€Ÿè½‰éŒ„")
        print("=" * 70)
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_int8_model_manager()
    sys.exit(0 if success else 1)