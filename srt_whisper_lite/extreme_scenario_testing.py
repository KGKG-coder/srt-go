#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¥µé™å ´æ™¯æ¸¬è©¦ - å°‹æ‰¾VADåƒæ•¸çœŸæ­£ç™¼æ®ä½œç”¨çš„æƒ…æ³
æ¸¬è©¦é•·éŸ³é »ã€ä½å“è³ªéŒ„éŸ³ã€å¿«é€ŸèªéŸ³ç­‰æ¥µé™æƒ…æ³
"""

import sys
import json
import logging
import time
from pathlib import Path
import os

# è¨­å®šæ§åˆ¶å°ç·¨ç¢¼
if sys.platform.startswith('win'):
    os.system('chcp 65001 > NUL')
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from faster_whisper import WhisperModel
    logger.info("Faster-Whisper æ¨¡çµ„å°å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"Faster-Whisper å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

def test_extreme_vad_scenarios(audio_file, output_dir):
    """
    æ¸¬è©¦æ¥µé™VADå ´æ™¯
    """
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # æ¥µé™å ´æ™¯VADé…ç½®
    extreme_configs = [
        {
            'name': 'Large_V3_Standard',
            'model': 'large-v3',
            'description': 'æ¨™æº–é…ç½®åŸºç·š',
            'vad': {
                "threshold": 0.5,
                "min_speech_duration_ms": 250,
                "min_silence_duration_ms": 2000,
                "speech_pad_ms": 400
            }
        },
        {
            'name': 'Large_V3_Ultra_Aggressive',
            'model': 'large-v3', 
            'description': 'è¶…æ¿€é€²åˆ†å‰²',
            'vad': {
                "threshold": 0.01,
                "min_speech_duration_ms": 10,   # æ¥µçŸ­èªéŸ³
                "min_silence_duration_ms": 50,  # æ¥µçŸ­éœéŸ³
                "speech_pad_ms": 10
            }
        },
        {
            'name': 'Large_V3_Ultra_Conservative',
            'model': 'large-v3',
            'description': 'è¶…ä¿å®ˆåˆ†å‰²',
            'vad': {
                "threshold": 0.8,              # æ¥µé«˜é–¾å€¼
                "min_speech_duration_ms": 1000, # æ¥µé•·èªéŸ³
                "min_silence_duration_ms": 3000, # æ¥µé•·éœéŸ³
                "speech_pad_ms": 500
            }
        },
        {
            'name': 'Large_V2_Comparison',
            'model': 'large-v2',
            'description': 'V2å°æ¯”åŸºç·š',
            'vad': {
                "threshold": 0.15,
                "min_speech_duration_ms": 100,
                "min_silence_duration_ms": 300,
                "speech_pad_ms": 100
            }
        },
        {
            'name': 'Medium_Speed_Test',
            'model': 'medium',
            'description': 'é€Ÿåº¦æ¸¬è©¦åŸºç·š',
            'vad': {
                "threshold": 0.15,
                "min_speech_duration_ms": 100,
                "min_silence_duration_ms": 300,
                "speech_pad_ms": 100
            }
        }
    ]
    
    logger.info(f"ğŸš€ é–‹å§‹æ¥µé™å ´æ™¯VADæ¸¬è©¦")
    logger.info(f"ğŸ¯ æ¸¬è©¦æª”æ¡ˆ: {audio_file}")
    logger.info(f"ğŸ”¬ æ¸¬è©¦ {len(extreme_configs)} ç¨®æ¥µé™é…ç½®")
    
    results = []
    
    for i, config in enumerate(extreme_configs):
        logger.info(f"\n=== æ¥µé™æ¸¬è©¦ {i+1}/{len(extreme_configs)}: {config['name']} ===")
        logger.info(f"æè¿°: {config['description']}")
        logger.info(f"æ¨¡å‹: {config['model']}")
        logger.info(f"VAD: {config['vad']}")
        
        try:
            # è¨˜éŒ„é–‹å§‹æ™‚é–“
            start_time = time.time()
            
            # è¼‰å…¥æ¨¡å‹
            logger.info("è¼‰å…¥æ¨¡å‹ä¸­...")
            model = WhisperModel(config['model'], device="cpu", compute_type="int8")
            load_time = time.time() - start_time
            
            # åŸ·è¡Œè½‰éŒ„
            logger.info("é–‹å§‹è½‰éŒ„...")
            transcribe_start = time.time()
            segments, info = model.transcribe(
                audio_file,
                language=None,
                beam_size=5,
                word_timestamps=True,
                vad_filter=True,
                vad_parameters=config['vad']
            )
            
            # è™•ç†çµæœ
            segment_list = list(segments)
            transcribe_time = time.time() - transcribe_start
            total_time = time.time() - start_time
            
            # ç”Ÿæˆè©³ç´°çµ±è¨ˆ
            if segment_list:
                segment_durations = [seg.end - seg.start for seg in segment_list]
                total_speech_time = sum(segment_durations)
                avg_segment_duration = total_speech_time / len(segment_list)
                shortest_segment = min(segment_durations)
                longest_segment = max(segment_durations)
                speech_ratio = total_speech_time / info.duration
            else:
                total_speech_time = avg_segment_duration = shortest_segment = longest_segment = speech_ratio = 0
            
            # ç”ŸæˆSRT
            srt_content = generate_srt_from_segments(segment_list)
            output_file = output_path / f"{config['name']}_extreme_result.srt"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            result = {
                'success': True,
                'config_name': config['name'],
                'description': config['description'],
                'model': config['model'],
                'vad_config': config['vad'],
                
                # åŸºæœ¬çµ±è¨ˆ
                'segment_count': len(segment_list),
                'total_duration': round(info.duration, 2),
                'total_speech_time': round(total_speech_time, 2),
                'speech_ratio': round(speech_ratio, 3),
                
                # æ®µè½åˆ†æ
                'avg_segment_duration': round(avg_segment_duration, 3),
                'shortest_segment': round(shortest_segment, 3),
                'longest_segment': round(longest_segment, 3),
                'segments_per_minute': round(len(segment_list) / (info.duration / 60), 1),
                
                # èªè¨€æª¢æ¸¬
                'language': info.language,
                'language_probability': round(info.language_probability, 4),
                
                # æ€§èƒ½çµ±è¨ˆ
                'load_time': round(load_time, 2),
                'transcribe_time': round(transcribe_time, 2),
                'total_time': round(total_time, 2),
                'real_time_factor': round(transcribe_time / info.duration, 2),
                
                'output_file': str(output_file)
            }
            
            logger.info(f"âœ… {config['name']} å®Œæˆ!")
            logger.info(f"   æ®µè½: {len(segment_list)}æ®µ, è™•ç†: {transcribe_time:.1f}s, å¯¦æ™‚å€æ•¸: {result['real_time_factor']:.2f}x")
            logger.info(f"   èªéŸ³æ¯”ä¾‹: {speech_ratio:.1%}, å¹³å‡æ®µè½: {avg_segment_duration:.2f}s")
            logger.info(f"   ä¿¡å¿ƒåº¦: {info.language_probability:.3f}, æœ€çŸ­æ®µè½: {shortest_segment:.2f}s")
            
            results.append(result)
            
        except Exception as e:
            logger.error(f"âŒ {config['name']} æ¸¬è©¦å¤±æ•—: {e}")
            results.append({
                'success': False,
                'config_name': config['name'],
                'description': config['description'],
                'model': config['model'],
                'error': str(e)
            })
    
    return results

def generate_srt_from_segments(segments):
    """å¾æ®µè½ç”ŸæˆSRTæ ¼å¼"""
    def format_timestamp(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    srt_content = ""
    for i, segment in enumerate(segments, 1):
        start_time = format_timestamp(segment.start)
        end_time = format_timestamp(segment.end)
        text = segment.text.strip()
        
        srt_content += f"{i}\n{start_time} --> {end_time}\n{text}\n\n"
    
    return srt_content

def analyze_extreme_results(results):
    """åˆ†ææ¥µé™æ¸¬è©¦çµæœ"""
    
    logger.info(f"\nğŸ“Š æ¥µé™æ¸¬è©¦çµæœåˆ†æ")
    logger.info(f"{'='*80}")
    
    successful_results = [r for r in results if r.get('success', False)]
    
    if not successful_results:
        logger.error("âŒ æ²’æœ‰æˆåŠŸçš„æ¸¬è©¦çµæœ")
        return
    
    # æŒ‰æ®µè½æ•¸æ’åº
    by_segments = sorted(successful_results, key=lambda x: x['segment_count'], reverse=True)
    logger.info(f"\nğŸ† æ®µè½æ•¸æ’å (ç´°åˆ†ç¨‹åº¦):")
    for i, result in enumerate(by_segments):
        vad_desc = f"VAD:{result['vad_config']['threshold']}"
        logger.info(f"{i+1:2d}. {result['config_name']:25s}: {result['segment_count']:3d}æ®µ {vad_desc:10s} ({result['description']})")
    
    # æŒ‰è™•ç†é€Ÿåº¦æ’åº
    by_speed = sorted(successful_results, key=lambda x: x['transcribe_time'])
    logger.info(f"\nâš¡ è™•ç†é€Ÿåº¦æ’å:")
    for i, result in enumerate(by_speed):
        logger.info(f"{i+1:2d}. {result['config_name']:25s}: {result['transcribe_time']:6.1f}s (RTF:{result['real_time_factor']:5.2f}x)")
    
    # æŒ‰èªè¨€ä¿¡å¿ƒåº¦æ’åº
    by_confidence = sorted(successful_results, key=lambda x: x['language_probability'], reverse=True)
    logger.info(f"\nğŸ¯ èªè¨€ä¿¡å¿ƒåº¦æ’å:")
    for i, result in enumerate(by_confidence):
        logger.info(f"{i+1:2d}. {result['config_name']:25s}: {result['language_probability']:6.3f} ({result['language']})")
    
    # VADæ•ˆæœåˆ†æ
    logger.info(f"\nğŸ” VADåƒæ•¸æ•ˆæœåˆ†æ:")
    vad_effects = {}
    for result in successful_results:
        threshold = result['vad_config']['threshold']
        if threshold not in vad_effects:
            vad_effects[threshold] = []
        vad_effects[threshold].append(result)
    
    for threshold in sorted(vad_effects.keys()):
        results_for_threshold = vad_effects[threshold]
        segments = [r['segment_count'] for r in results_for_threshold]
        avg_segments = sum(segments) / len(segments)
        logger.info(f"   VADé–¾å€¼ {threshold:4.2f}: å¹³å‡ {avg_segments:5.1f}æ®µ (ç¯„åœ: {min(segments)}-{max(segments)})")
    
    # æª¢æŸ¥VADåƒæ•¸å·®ç•°é¡¯è‘—æ€§
    logger.info(f"\nğŸš¨ VADåƒæ•¸é¡¯è‘—æ€§æª¢æŸ¥:")
    
    # æ‰¾åˆ°ç›¸åŒæ¨¡å‹ä½†ä¸åŒVADçš„çµ„åˆ
    model_groups = {}
    for result in successful_results:
        model = result['model']
        if model not in model_groups:
            model_groups[model] = []
        model_groups[model].append(result)
    
    vad_significance_found = False
    
    for model, model_results in model_groups.items():
        if len(model_results) > 1:
            segments_by_vad = [(r['vad_config']['threshold'], r['segment_count']) for r in model_results]
            segments_by_vad.sort()
            
            min_segments = min(seg for _, seg in segments_by_vad)
            max_segments = max(seg for _, seg in segments_by_vad)
            
            if max_segments > min_segments:
                vad_significance_found = True
                logger.info(f"   {model}: VADé–¾å€¼å½±éŸ¿æ®µè½æ•¸ {min_segments}-{max_segments} (å·®ç•°: {max_segments-min_segments})")
            else:
                logger.info(f"   {model}: VADé–¾å€¼ç„¡å½±éŸ¿ (å‡ç‚º{min_segments}æ®µ)")
    
    if not vad_significance_found:
        logger.info(f"   âš ï¸ åœ¨æ­¤éŸ³é »ä¸Šï¼ŒVADåƒæ•¸èª¿æ•´ç„¡é¡¯è‘—å½±éŸ¿ï¼")
        logger.info(f"   ğŸ’¡ å»ºè­°æ¸¬è©¦æ›´è¤‡é›œçš„éŸ³é »ç’°å¢ƒ")
    
    return {
        'vad_significance': vad_significance_found,
        'results_summary': successful_results
    }

def main():
    """ä¸»å‡½æ•¸"""
    
    # ä½¿ç”¨å·²çŸ¥çš„è¤‡é›œéŸ³é »é€²è¡Œæ¥µé™æ¸¬è©¦
    test_file = "C:/Users/USER-ART0/Desktop/C0485.MP4"  # è¼ƒé•·çš„å°è©±éŸ³é »
    output_dir = "C:/Users/USER-ART0/Desktop/extreme_vad_scenario_tests"
    
    if not Path(test_file).exists():
        logger.error(f"æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        logger.info("è«‹ç¢ºä¿æœ‰å¯ç”¨çš„æ¸¬è©¦éŸ³é »æª”æ¡ˆ")
        return None
    
    logger.info(f"ğŸ¯ æ¥µé™å ´æ™¯VADæ¸¬è©¦é–‹å§‹")
    logger.info(f"æ¸¬è©¦æª”æ¡ˆ: {test_file}")
    logger.info(f"è¼¸å‡ºç›®éŒ„: {output_dir}")
    
    try:
        # åŸ·è¡Œæ¥µé™æ¸¬è©¦
        results = test_extreme_vad_scenarios(test_file, output_dir)
        
        # åˆ†æçµæœ
        analysis = analyze_extreme_results(results)
        
        # ç”Ÿæˆè©³ç´°å ±å‘Š
        report = {
            'test_metadata': {
                'test_file': str(test_file),
                'output_dir': str(output_dir),
                'total_configs': len(results),
                'successful_tests': len([r for r in results if r.get('success', False)]),
                'vad_significance_detected': analysis.get('vad_significance', False) if analysis else False,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'extreme_test_results': results,
            'analysis_summary': analysis
        }
        
        # ä¿å­˜å ±å‘Š
        report_file = Path(output_dir) / 'extreme_vad_scenario_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nâœ… æ¥µé™å ´æ™¯VADæ¸¬è©¦å®Œæˆï¼")
        logger.info(f"ğŸ“‹ è©³ç´°å ±å‘Š: {report_file}")
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ æ¥µé™æ¸¬è©¦å¤±æ•—: {e}")
        return None

if __name__ == "__main__":
    try:
        report = main()
        if report and report['test_metadata']['vad_significance_detected']:
            print(f"\nğŸ‰ æ‰¾åˆ°VADåƒæ•¸é¡¯è‘—å½±éŸ¿å ´æ™¯ï¼")
        elif report:
            print(f"\nğŸ¤” VADåƒæ•¸åœ¨æ­¤å ´æ™¯ä¸‹ä»ç„¡é¡¯è‘—å½±éŸ¿")
        else:
            print(f"\nğŸ’¥ æ¸¬è©¦å¤±æ•—ï¼")
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºå¤±æ•—: {e}")
        sys.exit(1)