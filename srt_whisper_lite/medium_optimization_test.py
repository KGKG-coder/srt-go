#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Medium æ¨¡å‹æœ€ä½³åƒæ•¸èª¿æ•™è…³æœ¬
ç›®æ¨™ï¼šåŒ¹é…æ‰‹å‹•ç·¨è¼¯çš„test1.srtå‰34æ®µçš„ç´°ç·»åˆ†å‰²é¢¨æ ¼
"""

import sys
import json
import logging
import time
from pathlib import Path
import os

# è¨­å®šæ§åˆ¶å°ç·¨ç¢¼
if sys.platform.startswith('win'):
    os.system('chcp 65001 > NUL')
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from faster_whisper import WhisperModel
    logger.info("Faster-Whisper æ¨¡çµ„å°å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"Faster-Whisper å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

# Medium æ¨¡å‹èª¿æ•™é…ç½®
MEDIUM_TEST_CONFIGS = [
    {
        "name": "Medium è¶…æ•æ„Ÿé…ç½®",
        "description": "æ¥µä½VADé–¾å€¼ï¼Œæ•æ‰æ‰€æœ‰èªéŸ³",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.05,              # æ¥µä½é–¾å€¼
            "min_speech_duration_ms": 50,   # æ¥µçŸ­èªéŸ³
            "min_silence_duration_ms": 100, # æ¥µçŸ­éœéŸ³
            "speech_pad_ms": 50             # çŸ­å¡«å……
        },
        "whisper_params": {
            "beam_size": 3,                 # è¼ƒä½beam sizeæé«˜åˆ†å‰²æ•æ„Ÿåº¦
            "word_timestamps": True,
            "condition_on_previous_text": False,  # æ¸›å°‘ä¸Šä¸‹æ–‡ä¾è³´
            "compression_ratio_threshold": 1.8,  # æ›´ä½é–¾å€¼
            "log_prob_threshold": -1.5,     # æ›´ä½é–¾å€¼
            "no_speech_threshold": 0.4      # æ›´ä½é–¾å€¼
        }
    },
    {
        "name": "Medium ç´°åˆ†é…ç½®",
        "description": "é‡å°ç´°ç·»åˆ†å‰²å„ªåŒ–",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.10,              # ä½é–¾å€¼
            "min_speech_duration_ms": 100,  # çŸ­èªéŸ³
            "min_silence_duration_ms": 150, # çŸ­éœéŸ³
            "speech_pad_ms": 75             # ä¸­ç­‰å¡«å……
        },
        "whisper_params": {
            "beam_size": 5,
            "word_timestamps": True,
            "condition_on_previous_text": True,
            "compression_ratio_threshold": 2.0,
            "log_prob_threshold": -1.2,
            "no_speech_threshold": 0.5
        }
    },
    {
        "name": "Medium å¹³è¡¡é…ç½®",
        "description": "å¹³è¡¡æº–ç¢ºæ€§èˆ‡ç´°åˆ†åº¦",
        "model": "medium",
        "vad_parameters": {
            "threshold": 0.20,              # ä¸­ç­‰é–¾å€¼
            "min_speech_duration_ms": 150,  # æ¨™æº–èªéŸ³
            "min_silence_duration_ms": 250, # æ¨™æº–éœéŸ³
            "speech_pad_ms": 100            # æ¨™æº–å¡«å……
        },
        "whisper_params": {
            "beam_size": 5,
            "word_timestamps": True,
            "condition_on_previous_text": True,
            "compression_ratio_threshold": 2.4,
            "log_prob_threshold": -1.0,
            "no_speech_threshold": 0.6
        }
    }
]

def analyze_segment_similarity(generated_segments, reference_file, max_segments=34):
    """åˆ†æèˆ‡åƒè€ƒæª”æ¡ˆçš„ç›¸ä¼¼åº¦"""
    
    # è®€å–åƒè€ƒæª”æ¡ˆå‰34æ®µ
    try:
        with open(reference_file, 'r', encoding='utf-8') as f:
            ref_content = f.read()
        
        import re
        ref_segments = []
        lines = ref_content.strip().split('\n')
        current_seg = {}
        
        for line in lines:
            line = line.strip()
            if re.match(r'^\d+$', line):
                seg_id = int(line)
                if seg_id > max_segments:
                    break
                if current_seg:
                    ref_segments.append(current_seg)
                current_seg = {'id': seg_id}
            elif '-->' in line:
                start_str, end_str = line.split(' --> ')
                def parse_time(time_str):
                    h, m, s = time_str.split(':')
                    s, ms = s.split(',')
                    return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000.0
                current_seg['start'] = parse_time(start_str)
                current_seg['end'] = parse_time(end_str)
            elif line and 'start' in current_seg and 'text' not in current_seg:
                current_seg['text'] = line
        
        if current_seg and current_seg['id'] <= max_segments:
            ref_segments.append(current_seg)
        
        logger.info(f"åƒè€ƒæª”æ¡ˆè¼‰å…¥æˆåŠŸï¼Œå‰{max_segments}æ®µå…± {len(ref_segments)} å€‹æ®µè½")
        
        # åˆ†æç›¸ä¼¼åº¦
        ref_total_time = ref_segments[-1]['end'] if ref_segments else 0
        gen_relevant_segments = [seg for seg in generated_segments if seg['start'] <= ref_total_time]
        
        similarity_metrics = {
            'reference_segments': len(ref_segments),
            'generated_segments': len(gen_relevant_segments),
            'segment_ratio': len(gen_relevant_segments) / len(ref_segments) if ref_segments else 0,
            'avg_ref_duration': sum(seg['end'] - seg['start'] for seg in ref_segments) / len(ref_segments) if ref_segments else 0,
            'avg_gen_duration': sum(seg['duration'] for seg in gen_relevant_segments) / len(gen_relevant_segments) if gen_relevant_segments else 0,
            'time_coverage': ref_total_time,
            'short_segments_ref': sum(1 for seg in ref_segments if (seg['end'] - seg['start']) < 1.0),
            'short_segments_gen': sum(1 for seg in gen_relevant_segments if seg['duration'] < 1.0)
        }
        
        # è¨ˆç®—åŒ¹é…åº¦åˆ†æ•¸ (0-100)
        segment_score = min(100, (similarity_metrics['segment_ratio'] * 100))
        duration_score = 100 - min(100, abs(similarity_metrics['avg_ref_duration'] - similarity_metrics['avg_gen_duration']) * 100)
        short_seg_score = min(100, (similarity_metrics['short_segments_gen'] / similarity_metrics['short_segments_ref'] * 100)) if similarity_metrics['short_segments_ref'] > 0 else 50
        
        overall_score = (segment_score * 0.4 + duration_score * 0.3 + short_seg_score * 0.3)
        similarity_metrics['match_score'] = round(overall_score, 1)
        
        return similarity_metrics
        
    except Exception as e:
        logger.error(f"åƒè€ƒæª”æ¡ˆåˆ†æå¤±æ•—: {e}")
        return {}

def test_medium_config(audio_file, output_file, config):
    """æ¸¬è©¦Mediumé…ç½®"""
    try:
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ¯ æ¸¬è©¦ {config['name']}")
        logger.info(f"ğŸ“ {config['description']}")
        logger.info(f"ğŸµ éŸ³é »æª”æ¡ˆ: {Path(audio_file).name}")
        logger.info(f"{'='*80}")
        
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        start_time = time.time()
        
        # è¼‰å…¥æ¨¡å‹
        logger.info(f"â³ è¼‰å…¥ {config['model']} æ¨¡å‹...")
        model_load_start = time.time()
        model = WhisperModel(
            config['model'], 
            device="cpu", 
            compute_type="int8"
        )
        model_load_time = time.time() - model_load_start
        logger.info(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ ({model_load_time:.2f}ç§’)")
        
        # åŸ·è¡Œè½‰éŒ„
        logger.info("ğŸ¤ é–‹å§‹è½‰éŒ„...")
        transcribe_start = time.time()
        
        segments, info = model.transcribe(
            audio_file,
            language=None,  # è‡ªå‹•æª¢æ¸¬
            vad_filter=True,
            vad_parameters=config['vad_parameters'],
            **config['whisper_params']
        )
        
        # è™•ç†çµæœ
        segment_list = []
        for segment in segments:
            segment_data = {
                'id': len(segment_list) + 1,
                'start': segment.start,
                'end': segment.end,
                'text': segment.text.strip(),
                'duration': segment.end - segment.start
            }
            
            # å¦‚æœæœ‰è©ç´šæ™‚é–“æˆ³
            if hasattr(segment, 'words') and segment.words:
                segment_data['word_count'] = len(segment.words)
                segment_data['words'] = [
                    {
                        'word': w.word,
                        'start': w.start,
                        'end': w.end,
                        'probability': w.probability
                    } for w in segment.words
                ]
            
            segment_list.append(segment_data)
        
        transcribe_time = time.time() - transcribe_start
        total_time = time.time() - start_time
        
        # ç”ŸæˆSRT
        srt_content = generate_srt_from_segments(segment_list)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        # åˆ†æèˆ‡åƒè€ƒæª”æ¡ˆçš„ç›¸ä¼¼åº¦
        similarity = analyze_segment_similarity(segment_list, "C:/Users/USER-ART0/Desktop/test1.srt")
        
        # åŸºæœ¬çµ±è¨ˆ
        if segment_list:
            total_speech_time = sum(seg['duration'] for seg in segment_list)
            avg_segment_duration = total_speech_time / len(segment_list)
            segments_per_second = len(segment_list) / info.duration
            speech_ratio = total_speech_time / info.duration
        else:
            total_speech_time = avg_segment_duration = segments_per_second = speech_ratio = 0
        
        # çµæœå½™ç¸½
        result = {
            'success': True,
            'config_name': config['name'],
            'model': config['model'],
            'vad_config': config['vad_parameters'],
            
            # åŸºæœ¬çµ±è¨ˆ
            'audio_duration': round(info.duration, 2),
            'segment_count': len(segment_list),
            'segments_per_second': round(segments_per_second, 3),
            'avg_segment_duration': round(avg_segment_duration, 3),
            'speech_ratio': round(speech_ratio, 3),
            
            # ç›¸ä¼¼åº¦åˆ†æ
            'similarity_analysis': similarity,
            
            # èªè¨€æª¢æ¸¬
            'language': info.language,
            'language_probability': round(info.language_probability, 4),
            
            # æ€§èƒ½çµ±è¨ˆ
            'model_load_time': round(model_load_time, 2),
            'transcribe_time': round(transcribe_time, 2),
            'total_time': round(total_time, 2),
            'real_time_factor': round(transcribe_time / info.duration, 2),
            
            # æª”æ¡ˆè³‡è¨Š
            'output_file': str(output_file),
            'first_10_segments': segment_list[:10]  # å‰10æ®µè©³æƒ…
        }
        
        # è¼¸å‡ºçµæœæ‘˜è¦
        logger.info(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
        logger.info(f"  âœ… æ®µè½æ•¸: {len(segment_list)}æ®µ")
        logger.info(f"  âœ… æ®µè½å¯†åº¦: {segments_per_second:.3f}æ®µ/ç§’")
        logger.info(f"  âœ… å¹³å‡æ®µè½æ™‚é•·: {avg_segment_duration:.3f}ç§’")
        logger.info(f"  âœ… è™•ç†é€Ÿåº¦: {result['real_time_factor']:.2f}xå¯¦æ™‚")
        logger.info(f"  âœ… èªè¨€: {info.language} (ä¿¡å¿ƒåº¦: {info.language_probability:.3f})")
        
        if similarity:
            logger.info(f"  ğŸ“ˆ èˆ‡åƒè€ƒæª”æ¡ˆåŒ¹é…åº¦: {similarity.get('match_score', 0):.1f}%")
            logger.info(f"    - æ®µè½æ•¸æ¯”ä¾‹: {similarity.get('segment_ratio', 0):.2f}")
            logger.info(f"    - å¹³å‡æ™‚é•·å·®ç•°: {abs(similarity.get('avg_ref_duration', 0) - similarity.get('avg_gen_duration', 0)):.3f}ç§’")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'config_name': config['name'],
            'error': str(e)
        }

def generate_srt_from_segments(segments):
    """å¾æ®µè½ç”ŸæˆSRTæ ¼å¼"""
    def format_timestamp(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    srt_content = ""
    for segment in segments:
        segment_id = segment.get('id', len(srt_content.split('\n\n')) + 1)
        start_time = format_timestamp(segment['start'])
        end_time = format_timestamp(segment['end'])
        text = segment['text']
        
        srt_content += f"{segment_id}\n{start_time} --> {end_time}\n{text}\n\n"
    
    return srt_content

def main():
    """ä¸»å‡½æ•¸"""
    
    # æ¸¬è©¦æª”æ¡ˆ
    test_file = "C:/Users/USER-ART0/Desktop/C0485.MP4"
    output_dir = Path("C:/Users/USER-ART0/Desktop/medium_optimization_tests")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if not Path(test_file).exists():
        logger.error(f"âŒ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨: {test_file}")
        return None
    
    logger.info(f"ğŸš€ Medium æ¨¡å‹æœ€ä½³åŒ–åƒæ•¸æ¸¬è©¦")
    logger.info(f"ğŸ“ æ¸¬è©¦æª”æ¡ˆ: {Path(test_file).name}")
    logger.info(f"ğŸ’¾ è¼¸å‡ºç›®éŒ„: {output_dir}")
    logger.info(f"ğŸ“‹ é…ç½®æ•¸é‡: {len(MEDIUM_TEST_CONFIGS)}")
    
    all_results = []
    
    for i, config in enumerate(MEDIUM_TEST_CONFIGS):
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ“ æ¸¬è©¦ {i+1}/{len(MEDIUM_TEST_CONFIGS)}")
        
        # ç”Ÿæˆè¼¸å‡ºæª”å
        config_name_safe = config['name'].replace(' ', '_').replace('ï¼š', '_')
        output_file = output_dir / f"C0485_{config_name_safe}.srt"
        
        # åŸ·è¡Œæ¸¬è©¦
        result = test_medium_config(test_file, output_file, config)
        result['test_file'] = str(test_file)
        result['config_index'] = i + 1
        
        all_results.append(result)
        
        # çŸ­æš«å»¶é²
        time.sleep(1)
    
    # åˆ†ææ‰€æœ‰çµæœ
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ“Š Medium æ¨¡å‹æ¸¬è©¦çµæœåˆ†æ")
    logger.info(f"{'='*80}")
    
    successful_results = [r for r in all_results if r.get('success', False)]
    
    if successful_results:
        # æŒ‰åŒ¹é…åº¦æ’åº
        successful_results.sort(key=lambda x: x.get('similarity_analysis', {}).get('match_score', 0), reverse=True)
        
        logger.info(f"\nğŸ† æœ€ä½³é…ç½®æ’å:")
        for i, result in enumerate(successful_results):
            match_score = result.get('similarity_analysis', {}).get('match_score', 0)
            logger.info(f"  {i+1}. {result['config_name']}: {match_score:.1f}% åŒ¹é…åº¦")
            logger.info(f"     æ®µè½æ•¸: {result['segment_count']}, å¯†åº¦: {result['segments_per_second']:.3f}æ®µ/ç§’")
            logger.info(f"     è™•ç†é€Ÿåº¦: {result['real_time_factor']:.2f}xå¯¦æ™‚")
        
        # è©³ç´°åˆ†ææœ€ä½³é…ç½®
        best_config = successful_results[0]
        logger.info(f"\nğŸ¯ æœ€ä½³é…ç½®è©³ç´°åˆ†æ: {best_config['config_name']}")
        sim = best_config.get('similarity_analysis', {})
        if sim:
            logger.info(f"  åƒè€ƒæª”æ¡ˆå‰34æ®µ: {sim.get('reference_segments', 0)} æ®µ")
            logger.info(f"  ç”Ÿæˆå°æ‡‰å€é–“: {sim.get('generated_segments', 0)} æ®µ")
            logger.info(f"  æ®µè½æ•¸æ¯”ä¾‹: {sim.get('segment_ratio', 0):.2f}")
            logger.info(f"  å¹³å‡æ™‚é•· - åƒè€ƒ: {sim.get('avg_ref_duration', 0):.3f}ç§’")
            logger.info(f"  å¹³å‡æ™‚é•· - ç”Ÿæˆ: {sim.get('avg_gen_duration', 0):.3f}ç§’")
    
    # ä¿å­˜å®Œæ•´å ±å‘Š
    report = {
        'test_metadata': {
            'test_file': test_file,
            'total_configs': len(MEDIUM_TEST_CONFIGS),
            'successful_configs': len(successful_results),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        },
        'test_results': all_results,
        'best_config': successful_results[0] if successful_results else None
    }
    
    report_file = output_dir / 'medium_optimization_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\nâœ… Medium æœ€ä½³åŒ–æ¸¬è©¦å®Œæˆï¼")
    logger.info(f"ğŸ“‹ è©³ç´°å ±å‘Šå·²ä¿å­˜: {report_file}")
    
    return report

if __name__ == "__main__":
    try:
        report = main()
        if report and report['test_metadata']['successful_configs'] > 0:
            print(f"\nğŸ‰ Medium æœ€ä½³åŒ–æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
            print(f"æˆåŠŸæ¸¬è©¦: {report['test_metadata']['successful_configs']}/{report['test_metadata']['total_configs']}")
            best = report['best_config']
            if best:
                print(f"æœ€ä½³é…ç½®: {best['config_name']} (åŒ¹é…åº¦: {best.get('similarity_analysis', {}).get('match_score', 0):.1f}%)")
        else:
            print(f"\nğŸ’¥ æ¸¬è©¦å¤±æ•—ï¼")
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºå¤±æ•—: {e}")
        sys.exit(1)